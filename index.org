#+TITLE: Agent-Rex, An Async Generator/Iterator Based FRP-Like Library for JavaScript
#+AUTHOR: Timothy Hope

* Introduction

FRP in Javascript has a long history with libraries such as RxJS, Bacon.js, Most.js, Kefir.js and many others.
These libraries often use the Observable pattern to represent streams of data that can be observed and reacted to over time.
The ergonomic of these libraries can vary significantly, with some using method chaining and others using functional combinators.
Agent-Rex takes a different approach by leveraging async generators, which are a native feature of JavaScript, to provide a more intuitive and flexible way to work with streams of data.
(Most.js has a generator-based implementation, Agent-Rex just makes async generators first-class citizens.)

For example, async generator functions allow you to use `for await...of` loops to consume streams of data in a straightforward manner.

The library is designed to be lightweight and easy to use, while still providing powerful capabilities for composing and transforming streams of data.
The entire library is implemented and documented in this literate programming document.

** Why Streams?

Consider a common UI pattern: debouncing user input while fetching autocomplete suggestions.

*Imperative approach* (callbacks, state management, manual cleanup):

#+begin_src javascript :tangle no
let timeoutId = null;
let currentController = null;

inputElement.addEventListener('input', (e) => {
  // Cancel previous debounce
  if (timeoutId) clearTimeout(timeoutId);
  // Cancel in-flight request
  if (currentController) currentController.abort();
  
  timeoutId = setTimeout(async () => {
    currentController = new AbortController();
    try {
      const results = await fetch(`/api/search?q=${e.target.value}`, {
        signal: currentController.signal
      });
      displayResults(await results.json());
    } catch (err) {
      if (err.name !== 'AbortError') console.error(err);
    }
  }, 300);
});

// Don't forget cleanup on unmount!
#+end_src

*Stream-based approach* (declarative, composable, automatic resource management):

#+begin_src javascript :tangle no
import { fromEvent, debounce, map, chain, take } from 'agent-rex';

const suggestions = pipe(
  fromEvent(inputElement, 'input'),
  debounce(300),
  map(e => e.target.value),
  chain(query => fromFetch(`/api/search?q=${query}`)),
);

for await (const results of suggestions) {
  displayResults(results);
}
#+end_src

The stream-based approach:
- *Declares intent* rather than managing state
- *Composes naturally* — add =filter=, =take=, or error handling without restructuring
- *Handles cleanup automatically* — breaking from the loop cancels pending operations
- *Is testable* — streams can be mocked with predictable timing

** Under the Hood of Async Generators

You may be familiar with the syntactic sugarof async generators and have built or consumed them with functions like this:

#+begin_src javascript :tangle no
async function* asyncGenerator() {
  yield Promise.resolve(1);
  yield await Promise.resolve(2);
  yield 3;
}
const asyncGen = asyncGenerator();
asyncGen.next().then((res) => console.log(res.value)); // 1
asyncGen.next().then((res) => console.log(res.value)); // 2
asyncGen.next().then((res) => console.log(res.value)); // 3
#+end_src

However, under the hood, async generators are built on top of Promises and iterators.
When you call an async generator function, it returns an async iterator object that conforms to the async iteration protocol.

#+begin_src typescript :tangle no
interface AsyncIterator<T> {
  next(value?: any): Promise<IteratorResult<T>>;
  return?(value?: any): Promise<IteratorResult<T>>;
  throw?(e?: any): Promise<IteratorResult<T>>;
}

interface IteratorResult<T> {
  done: boolean;
  value: T;
}
#+end_src

When a =for await...of= loop is used to consume an async generator, it repeatedly calls the =next()= method on the async iterator.
Each call to =next()= returns a Promise that resolves to an =IteratorResult= object.
The =value= property of this object contains the yielded value from the generator, and the =done= property indicates whether the generator has completed.
This mechanism allows async generators to produce values asynchronously, making them well-suited for representing streams of data that may arrive over time.
They are also lazy, meaning that values are only produced when requested, which can help with performance and resource management.

* Creating a Stream

** =just=
The =just= function creates a stream that emits a single value and then completes.
Has the alias =of=.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits a single value and then completes.
 */
export async function* just<T>(
  value: T
): AsyncGenerator<T, void, void> {
  yield value
}

export const of = just

#+end_src

*** When to Use

Use =just= when you need to lift a single value into the stream context, often for testing or as a starting point for composition.

#+begin_src text :tangle no
just(42):  42|
           ^  ^
           |  complete
           emit value
#+end_src

#+begin_src javascript :tangle no
// Provide a default value when a stream might be empty
const withDefault = pipe(
  potentiallyEmptyStream,
  continueWith(() => just('default'))
)

// Start a chain of async operations
const result = pipe(
  just(userId),
  chain(id => fetchUser(id)),
  map(user => user.name)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('just', () => {
  it('emits a single value and completes', async () => {
    const values = await collect(just(42))
    expect(values).toEqual([42])
  })
})
#+end_src

*** Rust Implementation

In Rust, we use =async_stream= for ergonomic async generators with tokio:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::Stream;

/// Creates a stream that emits a single value and then completes.
pub fn just<T: Clone>(value: T) -> impl Stream<Item = T> {
    stream! {
        yield value;
    }
}

// Alias
pub fn of<T: Clone>(value: T) -> impl Stream<Item = T> {
    just(value)
}
#+end_src

** =fromPromise=
The =fromPromise= function creates a stream from a Promise.
When the Promise resolves, the stream emits the resolved value and then completes.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream from a Promise.
 * When the Promise resolves, the stream emits the resolved value and then completes.
 */
export async function* fromPromise<T>(promise: Promise<T>): AsyncGenerator<T, void, void> {
  const value = await promise
  yield value
}

#+end_src

*** When to Use

Use =fromPromise= to integrate Promise-based APIs into stream pipelines. The stream waits for the Promise to resolve, emits the value, then completes.

#+begin_src text :tangle no
fromPromise(fetch('/api/data')):

  ---(waiting)---data|
                 ^    ^
                 |    complete
                 resolved value
#+end_src

#+begin_src javascript :tangle no
// Convert a fetch call to a stream
const userData = fromPromise(fetch('/api/user').then(r => r.json()))

// Use in a pipeline
const notifications = pipe(
  fromPromise(getNotifications()),
  chain(notifications => from(notifications)),
  filter(n => n.unread)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('fromPromise', () => {
  it('emits the resolved value', async () => {
    const values = await collect(fromPromise(Promise.resolve(42)))
    expect(values).toEqual([42])
  })

  it('waits for promise resolution', async () => {
    const delayed = new Promise<string>(r => setTimeout(() => r('delayed'), 10))
    const values = await collect(fromPromise(delayed))
    expect(values).toEqual(['delayed'])
  })

  it('propagates rejection as error', async () => {
    const failing = Promise.reject(new Error('fail'))
    await expect(collect(fromPromise(failing))).rejects.toThrow('fail')
  })
})
#+end_src

*** Rust Implementation

In Rust, futures are the equivalent of Promises:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Future, Stream};

/// Creates a stream from a Future.
/// When the Future resolves, the stream emits the value and completes.
pub fn from_future<T, F: Future<Output = T>>(future: F) -> impl Stream<Item = T> {
    stream! {
        let value = future.await;
        yield value;
    }
}
#+end_src

** =from=
The =from= function creates a stream from an iterable or async iterable.
It emits each value from the iterable in sequence.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream from an iterable or async iterable.
 * It emits each value from the iterable in sequence.
 */
export async function* from<T>(
    iterable: Iterable<T> | AsyncIterable<T>
): AsyncGenerator<T, void, void> {
  for await (const item of iterable) yield item
}

#+end_src

*** When to Use

Use =from= to convert arrays, Sets, Maps, or any iterable into an async stream. This is your primary tool for lifting collections into the stream world.

#+begin_src text :tangle no
from([1, 2, 3]):  1-2-3|
                  ^ ^ ^ ^
                  | | | complete
                  synchronous emissions
#+end_src

#+begin_src javascript :tangle no
// Process array items through a pipeline
const processed = pipe(
  from([1, 2, 3, 4, 5]),
  filter(x => x % 2 === 0),
  map(x => x * 10)
)
// yields: 20, 40

// Convert a Set to a stream
const uniqueUsers = pipe(
  from(new Set(userIds)),
  chain(id => fetchUser(id))
)

// Process file lines
const lines = from(fileContent.split('\n'))
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('from', () => {
  it('emits all values from an array', async () => {
    const values = await collect(from([1, 2, 3]))
    expect(values).toEqual([1, 2, 3])
  })

  it('handles empty arrays', async () => {
    await expectStream(from([])).toBeEmpty()
  })
})
#+end_src

*** Rust Implementation

Rust uses =futures::stream::iter= for sync iterables and =async_stream= for async:

#+begin_src rust :tangle no
use futures::stream::{self, Stream, StreamExt};
use async_stream::stream;

/// Creates a stream from an iterator.
pub fn from_iter<T, I: IntoIterator<Item = T>>(iterable: I) -> impl Stream<Item = T> {
    stream::iter(iterable)
}

/// Creates a stream from an async iterator (Stream).
pub fn from_stream<T, S: Stream<Item = T>>(s: S) -> impl Stream<Item = T> {
    s
}
#+end_src

** =periodic=
The =periodic= function creates a stream that emits at regular intervals.
To give it a value, combine it with =constant=.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits at regular intervals.
 * To give it a value, combine it with `constant`.
 */
export async function* periodic(intervalMs: number): AsyncGenerator<void, void, void> {
  while (true) {
    yield;
    await new Promise((resolve) => setTimeout(resolve, intervalMs));
  }
}

#+end_src

*** When to Use

Use =periodic= to create a heartbeat or polling stream. Combine with =constant= to give it values, or use with =take= to limit iterations.

#+begin_src text :tangle no
periodic(100):  •---•---•---•---•---... (never ends)
                ^   ^   ^   ^
                |   100ms intervals
                emits undefined
#+end_src

#+begin_src javascript :tangle no
// Poll an API every 5 seconds
const pollData = pipe(
  periodic(5000),
  chain(() => fromPromise(fetch('/api/status').then(r => r.json()))),
  take(100)  // Stop after 100 polls
)

// Emit a timestamp every second
const timestamps = pipe(
  periodic(1000),
  map(() => Date.now())
)

// Create a countdown timer
const countdown = pipe(
  periodic(1000),
  scan((n) => n - 1, 10),
  takeWhile(n => n >= 0)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('periodic', () => {
  it('emits void values at intervals', async () => {
    const values = await collect(pipe(periodic(10), take(3)))
    expect(values).toEqual([undefined, undefined, undefined])
  })
})
#+end_src

*** Rust Implementation

Using tokio's interval for periodic emissions:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::Stream;
use tokio::time::{interval, Duration};

/// Creates a stream that emits () at regular intervals.
pub fn periodic(interval_ms: u64) -> impl Stream<Item = ()> {
    stream! {
        let mut interval = interval(Duration::from_millis(interval_ms));
        loop {
            yield ();
            interval.tick().await;
        }
    }
}
#+end_src

** =empty=
The =empty= function creates a stream that immediately completes without emitting any values.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that immediately completes without emitting any values.
 */
export async function* empty(
): AsyncGenerator<never, void, void> {
  return
}

#+end_src

*** When to Use

Use =empty= when you need a stream that completes immediately without emitting values. Useful as a fallback or for conditional stream creation.

#+begin_src text :tangle no
empty():  |
          ^
          immediately complete
#+end_src

#+begin_src javascript :tangle no
// Conditional stream based on feature flag
const notifications = featureEnabled
  ? fromEvent(eventSource, 'notification')
  : empty()

// Filter that might produce nothing
const adminActions = pipe(
  actions,
  filter(a => a.requiresAdmin),
  // If no admin actions, stream completes immediately
)

// Use as recovery fallback
const safeStream = pipe(
  riskyOperation,
  recoverWith(() => empty())  // Silently complete on error
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('empty', () => {
  it('completes immediately without emitting', async () => {
    await expectStream(empty()).toBeEmpty()
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use futures::stream::{self, Stream};

/// Creates a stream that immediately completes without emitting any values.
pub fn empty<T>() -> impl Stream<Item = T> {
    stream::empty()
}
#+end_src

** =never=
The =never= function creates a stream that never emits any values and never completes.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that never emits any values and never completes.
 * Useful for representing an infinite wait or as a placeholder.
 */
export async function* never(
): AsyncGenerator<never, void, void> {
  await new Promise(() => {})
}

#+end_src

*** When to Use

Use =never= as a placeholder stream that blocks indefinitely. Useful for testing timeouts or as a "keep-alive" in merge operations.

#+begin_src text :tangle no
never():  --------... (never emits, never completes)
#+end_src

#+begin_src javascript :tangle no
// Test timeout behavior
const shouldTimeout = pipe(
  merge(never(), fromPromise(timeoutAfter(1000))),
  take(1)
)

// Keep a merge alive even if one stream completes
const combined = merge(
  eventStream,
  never()  // Prevents merge from completing when eventStream ends
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('never', () => {
  it('never emits or completes', async () => {
    // We can only test that it doesn't immediately complete
    let completed = false
    const gen = never()
    const timeout = setTimeout(() => {}, 50)
    
    // Race the never stream against a timeout
    const result = await Promise.race([
      gen.next().then(() => 'emitted'),
      new Promise<string>(r => setTimeout(() => r('timeout'), 20))
    ])
    clearTimeout(timeout)
    expect(result).toBe('timeout')
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use futures::stream::Stream;
use std::future::pending;

/// Creates a stream that never emits any values and never completes.
pub fn never<T>() -> impl Stream<Item = T> {
    async_stream::stream! {
        pending::<()>().await;
        // Never reached - the pending future never resolves
    }
}
#+end_src

** =iterate=

The =iterate= function creates a stream that emits an infinite sequence of values by repeatedly applying a function to a seed value.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits an infinite sequence of values by repeatedly applying a function to a seed value.
 */
export async function* iterate<T>(seed: T, fn: (value: T) => T): AsyncGenerator<T, void, void> {
  let current = seed;
  while (true) {
    yield current
    current = fn(current)
  }
}

#+end_src

*** When to Use

Use =iterate= to generate sequences where each value depends on the previous one. Always combine with limiting operators like =take= since it produces infinite streams.

#+begin_src text :tangle no
iterate(1, x => x * 2):

  1-2-4-8-16-32-... (infinite)
  ^ ^
  | fn(1) = 2
  seed
#+end_src

#+begin_src javascript :tangle no
// Generate Fibonacci sequence
const fibonacci = pipe(
  iterate([0, 1], ([a, b]) => [b, a + b]),
  map(([a]) => a),
  take(10)
)
// yields: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34

// Generate exponential backoff delays
const backoffDelays = pipe(
  iterate(100, d => Math.min(d * 2, 30000)),
  take(10)
)
// yields: 100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600, 30000

// Walking through a linked list
const walkList = pipe(
  iterate(headNode, node => node.next),
  takeWhile(node => node !== null)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('iterate', () => {
  it('generates values by applying function repeatedly', async () => {
    const values = await collect(pipe(iterate(1, x => x * 2), take(5)))
    expect(values).toEqual([1, 2, 4, 8, 16])
  })

  it('starts with the seed value', async () => {
    const values = await collect(pipe(iterate(10, x => x + 1), take(3)))
    expect(values).toEqual([10, 11, 12])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::Stream;

/// Creates a stream that emits an infinite sequence by repeatedly applying a function.
pub fn iterate<T: Clone, F: Fn(T) -> T>(seed: T, f: F) -> impl Stream<Item = T> {
    stream! {
        let mut current = seed;
        loop {
            yield current.clone();
            current = f(current);
        }
    }
}
#+end_src

** =unfold=

Like iterate but the function returns a tuple of ={ value: T, nextSeed: S, done: boolean }=.
The generator will emit =value= and use =nextSeed= for the next iteration.
If =done= is true, the generator will complete.
=value= is ignored when =done= is true.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits values by unfolding a seed value using a function.
 * The function returns an object containing the next value, the next seed, and a done flag
 * to indicate completion.
 */
export async function* unfold<T, S>(
  seed: S,
  fn: (seed: S) => { value: T; nextSeed: S; done: boolean }
): AsyncGenerator<T, void, void> {
  let currentSeed = seed;
  while (true) {
    const { value, nextSeed, done } = fn(currentSeed)
    if (done) return
    yield value
    currentSeed = nextSeed;
  }
}

#+end_src

*** When to Use

Use =unfold= when you need more control than =iterate= — specifically when the emitted value differs from the state, or when the sequence has a natural termination condition.

#+begin_src text :tangle no
unfold(1, n => ({ value: n, nextSeed: n+1, done: n > 3 })):

  1-2-3|
      ^
      done: true stops iteration
#+end_src

#+begin_src javascript :tangle no
// Paginated API fetching (state = page cursor, value = items)
const allPages = unfold({ cursor: null, hasMore: true }, async ({ cursor }) => {
  const response = await fetch(`/api/items?cursor=${cursor || ''}`)
  const { items, nextCursor } = await response.json()
  return {
    value: items,
    nextSeed: { cursor: nextCursor, hasMore: !!nextCursor },
    done: !nextCursor
  }
})

// Range of numbers
const range = (start, end) => unfold(start, n => ({
  value: n,
  nextSeed: n + 1,
  done: n >= end
}))
// range(1, 5) yields: 1, 2, 3, 4

// Read lines from a buffer until empty
const lines = unfold(buffer, buf => {
  const newlineIdx = buf.indexOf('\n')
  if (newlineIdx === -1) return { value: '', nextSeed: '', done: buf.length === 0 }
  return {
    value: buf.slice(0, newlineIdx),
    nextSeed: buf.slice(newlineIdx + 1),
    done: false
  }
})
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('unfold', () => {
  it('generates values until done is true', async () => {
    const values = await collect(unfold(1, n => ({
      value: n,
      nextSeed: n + 1,
      done: n > 3
    })))
    expect(values).toEqual([1, 2, 3])
  })

  it('completes immediately if first call returns done', async () => {
    const values = await collect(unfold(0, () => ({
      value: 'ignored',
      nextSeed: 0,
      done: true
    })))
    expect(values).toEqual([])
  })
})
#+end_src

*** Rust Implementation

Rust's =futures::stream::unfold= provides this natively:

#+begin_src rust :tangle no
use futures::stream::{self, Stream};

pub struct UnfoldResult<T, S> {
    pub value: T,
    pub next_seed: S,
    pub done: bool,
}

/// Creates a stream by unfolding a seed value.
pub fn unfold<T, S, F>(seed: S, f: F) -> impl Stream<Item = T>
where
    F: Fn(S) -> UnfoldResult<T, S>,
{
    stream::unfold(seed, move |state| async move {
        let result = f(state);
        if result.done {
            None
        } else {
            Some((result.value, result.next_seed))
        }
    })
}
#+end_src

** =startWith=

The =startWith= function prepends a value to the beginning of a stream.

#+begin_src typescript :tangle index.ts

/**
 * Prepends a value to the beginning of a stream.
 */
export function startWith<T>(
  value: T
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function startWith<T>(
  value: T,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function startWith<T>(
  value: T,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => startWith(value, s);
  return (async function* () {
    yield value
    yield* stream
  })();
}

#+end_src

*** When to Use

Use =startWith= to prepend an initial value to a stream. Common for providing defaults or initial state in reactive UIs.

#+begin_src text :tangle no
stream:              --1--2--3|
startWith(0):      0---1--2--3|
                   ^
                   prepended value
#+end_src

#+begin_src javascript :tangle no
// Provide initial state for a UI component
const userState = pipe(
  userUpdates,
  startWith({ name: 'Loading...', avatar: null })
)

// Ensure a stream always has at least one value
const withDefault = pipe(
  searchResults,
  startWith([])  // Start with empty array
)

// Initialize a scan with a starting emission
const counter = pipe(
  buttonClicks,
  scan((count) => count + 1, 0),
  startWith(0)  // Emit initial count before any clicks
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('startWith', () => {
  it('prepends value to stream', async () => {
    const values = await collect(startWith(0, from([1, 2, 3])))
    expect(values).toEqual([0, 1, 2, 3])
  })

  it('works with empty stream', async () => {
    const values = await collect(startWith('first', empty()))
    expect(values).toEqual(['first'])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Prepends a value to the beginning of a stream.
pub fn start_with<T: Clone, S: Stream<Item = T>>(value: T, s: S) -> impl Stream<Item = T> {
    stream! {
        yield value;
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            yield item;
        }
    }
}
#+end_src

** =concat=

The =concat= function concatenates multiple streams into a single stream.

#+begin_src typescript :tangle index.ts

/**
 * Concatenates multiple streams into a single stream.
 */
export async function* concat<T>(
  ...streams: AsyncIterable<T>[]
): AsyncGenerator<T, void, void> {
  for (const stream of streams) yield* stream
}

#+end_src

*** When to Use

Use =concat= to sequentially combine multiple streams. Each stream must complete before the next one starts — contrast with =merge= which interleaves concurrent streams.

#+begin_src text :tangle no
stream A:        1--2|
stream B:             3--4|
concat(A, B):    1--2--3--4|
                     ^
                     B starts after A completes
#+end_src

#+begin_src javascript :tangle no
// Chain sequential operations
const fullSequence = concat(
  from(['Starting...']),
  processItems(items),
  from(['Done!'])
)

// Prioritized data sources (try cache, then network)
const data = pipe(
  concat(fromCache(key), fromNetwork(url)),
  take(1)  // Take first available
)

// Build up a playlist
const playlist = concat(
  from(introSongs),
  from(mainContent),
  from(outroSongs)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('concat', () => {
  it('concatenates streams in order', async () => {
    const result = await collect(concat(from([1, 2]), from([3, 4])))
    expect(result).toEqual([1, 2, 3, 4])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Concatenates multiple streams into a single stream.
pub fn concat<T, S: Stream<Item = T>>(streams: Vec<S>) -> impl Stream<Item = T> {
    stream! {
        for s in streams {
            tokio::pin!(s);
            while let Some(item) = s.next().await {
                yield item;
            }
        }
    }
}

// For two streams specifically:
pub fn concat2<T, S1: Stream<Item = T>, S2: Stream<Item = T>>(s1: S1, s2: S2) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s1);
        tokio::pin!(s2);
        while let Some(item) = s1.next().await {
            yield item;
        }
        while let Some(item) = s2.next().await {
            yield item;
        }
    }
}
#+end_src

** =fromEvent=

The =fromEvent= function creates a stream from DOM events or any EventTarget-like object.
The stream properly cleans up by removing the event listener when the iterator is closed.

#+begin_src typescript :tangle index.ts

/**
 * An object that can add and remove event listeners.
 * Compatible with DOM EventTarget, Node.js EventEmitter, and similar.
 */
export interface EventTargetLike<E> {
  addEventListener(type: string, listener: (event: E) => void): void
  removeEventListener(type: string, listener: (event: E) => void): void
}

/**
 * Creates a stream from events on an EventTarget-like object.
 * The event listener is automatically removed when the stream is closed.
 * 
 * @example
 * const clicks = fromEvent(button, 'click')
 * for await (const event of clicks) {
 *   console.log('clicked!', event)
 * }
 */
export function fromEvent<E = Event>(
  target: EventTargetLike<E>,
  eventName: string
): AsyncIterable<E> {
  return {
    [Symbol.asyncIterator]() {
      const queue: E[] = []
      let resolve: ((result: IteratorResult<E>) => void) | null = null
      let done = false

      const listener = (event: E) => {
        if (resolve) {
          const r = resolve
          resolve = null
          r({ value: event, done: false })
        } else {
          queue.push(event)
        }
      }

      target.addEventListener(eventName, listener)

      return {
        async next(): Promise<IteratorResult<E>> {
          if (queue.length > 0) {
            return { value: queue.shift()!, done: false }
          }
          if (done) {
            return { value: undefined as any, done: true }
          }
          return new Promise(r => {
            resolve = r
          })
        },
        async return(): Promise<IteratorResult<E>> {
          done = true
          target.removeEventListener(eventName, listener)
          if (resolve) {
            const r = resolve
            resolve = null
            r({ value: undefined as any, done: true })
          }
          return { value: undefined as any, done: true }
        }
      }
    }
  }
}

#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('fromEvent', () => {
  it('creates stream from event emitter', async () => {
    // Create a mock event target
    type Listener = (event: string) => void
    const listeners: Listener[] = []
    const mockTarget = {
      addEventListener(_type: string, listener: Listener) {
        listeners.push(listener)
      },
      removeEventListener(_type: string, listener: Listener) {
        const idx = listeners.indexOf(listener)
        if (idx >= 0) listeners.splice(idx, 1)
      },
      emit(event: string) {
        listeners.forEach(l => l(event))
      }
    }

    const events = fromEvent<string>(mockTarget, 'test')
    const iter = events[Symbol.asyncIterator]()

    // Emit some events
    mockTarget.emit('event1')
    mockTarget.emit('event2')

    const first = await iter.next()
    expect(first.value).toBe('event1')

    const second = await iter.next()
    expect(second.value).toBe('event2')

    // Cleanup
    await iter.return!()
    expect(listeners.length).toBe(0)
  })

  it('removes listener on return', async () => {
    let listenerCount = 0
    const mockTarget = {
      addEventListener() { listenerCount++ },
      removeEventListener() { listenerCount-- }
    }

    const events = fromEvent(mockTarget, 'test')
    const iter = events[Symbol.asyncIterator]()
    expect(listenerCount).toBe(1)

    await iter.return!()
    expect(listenerCount).toBe(0)
  })
})
#+end_src

*** Rust Implementation

In Rust, we typically use channels (tokio::sync::mpsc) for event-driven patterns:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::Stream;
use tokio::sync::mpsc;

/// Creates a stream from a channel receiver.
/// The sender can be used to push events from event handlers.
pub fn from_channel<T>(mut rx: mpsc::Receiver<T>) -> impl Stream<Item = T> {
    stream! {
        while let Some(item) = rx.recv().await {
            yield item;
        }
    }
}

// Example usage for event-like patterns:
// let (tx, rx) = mpsc::channel(100);
// let event_stream = from_channel(rx);
// 
// // In an event handler:
// tx.send(event).await.unwrap();
#+end_src

* Composing with =pipe=

All operators in Agent-Rex use a *data-last* signature: the stream is always the final argument.
Additionally, all operators support *automatic currying* via function overloads — you can call them with or without the stream argument:

#+begin_src javascript :tangle no
// Both forms work:
map(x => x * 2, stream)      // Direct call with all arguments
map(x => x * 2)(stream)      // Curried: returns a function awaiting the stream
#+end_src

This enables clean, point-free composition using a =pipe= function:

#+begin_src javascript :tangle no
// With built-in currying, pipes read naturally:
const result = pipe(
  from([1, 2, 3, 4, 5]),
  filter(x => x % 2 === 0),
  map(x => x * 10),
  take(2),
);
// result: async generator yielding 20, 40
#+end_src

The =pipe= function composes left-to-right.
Using TypeScript 5.0+ recursive conditional types, we can achieve full type safety with an arbitrary number of functions:

#+begin_src typescript :tangle index.ts

/**
 * A unary function type for pipe composition.
 */
type Fn = (arg: any) => any

/**
 * Recursively validates that each function's input matches the previous function's output.
 * If a mismatch is found, the expected type is shown in the error position.
 * 
 * Uses `In extends Parameters<First>[0]` (not the reverse) because function parameters
 * are contravariant: we need to check if In can be assigned TO the function's parameter,
 * not whether the parameter type extends In. This ensures AsyncIterable<number> properly
 * satisfies AsyncIterable<unknown>.
 */
type ValidatePipeline<Fns extends Fn[], In> =
  Fns extends [infer First extends Fn, ...infer Rest extends Fn[]]
    ? In extends Parameters<First>[0]
      ? [First, ...ValidatePipeline<Rest, ReturnType<First>>]
      : [(arg: In) => ReturnType<First>, ...Rest]
    : []

/**
 * Computes the final return type by walking through the function chain.
 */
type PipeReturn<Fns extends Fn[], In> =
  Fns extends [infer First extends Fn, ...infer Rest extends Fn[]]
    ? PipeReturn<Rest, ReturnType<First>>
    : In

/**
 * Composes functions left-to-right, passing the result of each to the next.
 * The first argument is the initial value; subsequent arguments are unary functions.
 * 
 * Uses explicit overloads for 1-10 functions for reliable type inference.
 * Pipelines with 11+ functions fall back to recursive validation.
 * 
 * @example
 * const result = pipe(
 *   from([1, 2, 3, 4, 5]),
 *   filter(x => x % 2 === 0),
 *   map(x => x * 10),
 *   take(2),
 * );
 * // result: async generator yielding 20, 40
 */
export function pipe<A>(initial: A): A;
export function pipe<A, B>(initial: A, f1: (a: A) => B): B;
export function pipe<A, B, C>(initial: A, f1: (a: A) => B, f2: (b: B) => C): C;
export function pipe<A, B, C, D>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D): D;
export function pipe<A, B, C, D, E>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E): E;
export function pipe<A, B, C, D, E, F>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F): F;
export function pipe<A, B, C, D, E, F, G>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G): G;
export function pipe<A, B, C, D, E, F, G, H>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H): H;
export function pipe<A, B, C, D, E, F, G, H, I>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I): I;
export function pipe<A, B, C, D, E, F, G, H, I, J>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I, f9: (i: I) => J): J;
export function pipe<A, B, C, D, E, F, G, H, I, J, K>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I, f9: (i: I) => J, f10: (j: J) => K): K;
export function pipe<A, Fns extends Fn[]>(initial: A, ...fns: Fns & ValidatePipeline<Fns, A>): PipeReturn<Fns, A>;
export function pipe(initial: unknown, ...fns: Fn[]): unknown {
  return fns.reduce((acc, fn) => fn(acc), initial)
}

#+end_src

*** Rust Implementation

In Rust, method chaining with trait extension patterns is idiomatic.
The =StreamExt= trait from =futures= provides chainable methods on any Stream:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Rust uses method chaining instead of pipe:
// let result = stream::iter([1, 2, 3, 4, 5])
//     .filter(|x| futures::future::ready(x % 2 == 0))
//     .map(|x| x * 10)
//     .take(2);

// For a pipe-like macro if desired:
macro_rules! pipe {
    ($initial:expr $(, $fn:expr)*) => {{
        let mut result = $initial;
        $(result = $fn(result);)*
        result
    }};
}

// Usage:
// let stream = pipe!(
//     stream::iter(vec![1, 2, 3]),
//     |s| s.map(|x| x * 2),
//     |s| s.take(2)
// );
#+end_src

** Currying Implementation Pattern

Each operator uses TypeScript function overloads to support both curried and uncurried calls.
Here's the pattern (using =map= as an example):

#+begin_src typescript :tangle no
// Overload 1: Curried (no stream) — returns a function
export function map<T, U>(
  fn: (value: T) => U
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;

// Overload 2: Uncurried (with stream) — returns the generator directly  
export function map<T, U>(
  fn: (value: T) => U,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;

// Implementation: checks if stream is provided
export function map<T, U>(
  fn: (value: T) => U,
  stream?: AsyncIterable<T>,
) {
  if (stream === undefined) return (s) => map(fn, s);  // Return curried
  return (async function* () { /* ... */ })();         // Return generator
}
#+end_src

* Transformations

** =map=

The =map= function transforms each value emitted by a stream using a provided function.
Supports both curried and uncurried calling conventions.

#+begin_src typescript :tangle index.ts

/**
 * Transforms each value emitted by a stream using a provided function.
 */
export function map<T, U>(
  fn: (value: T) => U | Promise<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function map<T, U>(
  fn: (value: T) => U | Promise<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function map<T, U>(
  fn: (value: T) => U | Promise<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => map(fn, s);
  return (async function* () {
    for await (const item of stream) yield await fn(item);
  })();
}

#+end_src

*** When to Use

Use =map= to transform each value in a stream. This is the workhorse operator for data transformation — extract fields, compute derived values, or convert types.

#+begin_src text :tangle no
stream:          --1---2---3--|
map(x => x*10): --10--20--30-|
                  ^   ^   ^
                  transform each value
#+end_src

#+begin_src javascript :tangle no
// Extract a field from objects
const userNames = pipe(
  userStream,
  map(user => user.name)
)

// Async transformation (awaited automatically)
const enrichedData = pipe(
  ids,
  map(async id => {
    const details = await fetchDetails(id)
    return { id, ...details }
  })
)

// Parse incoming messages
const parsedMessages = pipe(
  rawMessages,
  map(msg => JSON.parse(msg))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('map', () => {
  it('transforms each value', async () => {
    const result = await collect(map(x => x * 2, from([1, 2, 3])))
    expect(result).toEqual([2, 4, 6])
  })

  it('handles async mappers', async () => {
    const result = await collect(
      map(async x => x * 2, from([1, 2, 3]))
    )
    expect(result).toEqual([2, 4, 6])
  })
})
#+end_src

*** Rust Implementation

The =StreamExt::map= method is built-in to futures:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

/// Map is built-in to StreamExt:
/// stream.map(|x| x * 2)

// For async mappers, use then():
/// stream.then(|x| async move { x * 2 })

// Custom implementation for reference:
use async_stream::stream;

pub fn map<T, U, S, F>(s: S, f: F) -> impl Stream<Item = U>
where
    S: Stream<Item = T>,
    F: Fn(T) -> U,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            yield f(item);
        }
    }
}
#+end_src

** =constant=

The =constant= function creates a stream that emits a constant value for each item in the source stream.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits a constant value for each item in the source stream.
 */
export function constant<U>(
  value: U
): (stream: AsyncIterable<any>) => AsyncGenerator<U, void, void>;
export function constant<U>(
  value: U,
  stream: AsyncIterable<any>
): AsyncGenerator<U, void, void>;
export function constant<U>(
  value: U,
  stream?: AsyncIterable<any>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<any>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<any>) => constant(value, s);
  return (async function* () {
    for await (const _ of stream) yield value
  })();
}

#+end_src

*** When to Use

Use =constant= to replace all stream values with a fixed value. Often combined with =periodic= to create a stream of repeated values, or used to signal events without caring about the event data.

#+begin_src text :tangle no
stream:            --a--b--c--|
constant('x'):     --x--x--x--|
                     ^  ^
                     all values become 'x'
#+end_src

#+begin_src javascript :tangle no
// Turn a timer into a constant signal
const heartbeat = pipe(
  periodic(1000),
  constant('ping')
)
// yields: 'ping', 'ping', 'ping', ...

// Count events (ignore event data, just count)
const clickCount = pipe(
  fromEvent(button, 'click'),
  constant(1),
  scan((count, one) => count + one, 0)
)

// Signal that "something happened" without details
const refreshSignal = pipe(
  merge(userAction, timerTick, networkReconnect),
  constant('refresh')
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('constant', () => {
  it('replaces each value with the constant', async () => {
    const values = await collect(constant('x', from([1, 2, 3])))
    expect(values).toEqual(['x', 'x', 'x'])
  })

  it('emits nothing for empty stream', async () => {
    const values = await collect(constant('x', empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

/// Map to a constant value.
/// stream.map(|_| constant_value.clone())

// Custom implementation:
use async_stream::stream;

pub fn constant<T, U: Clone, S: Stream<Item = T>>(value: U, s: S) -> impl Stream<Item = U> {
    stream! {
        tokio::pin!(s);
        while let Some(_) = s.next().await {
            yield value.clone();
        }
    }
}
#+end_src

** =scan=

The =scan= function accumulates values from a stream using a provided accumulator function and an initial seed value.
Yields the seed first, then each accumulated value.

#+begin_src typescript :tangle index.ts

/**
 * Accumulates values from a stream using a provided accumulator function and an initial seed value.
 */
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => scan(accumulator, seed, s);
  return (async function* () {
    let acc = seed
    yield acc
    for await (const item of stream) {
      acc = await accumulator(acc, item)
      yield acc
    }
  })();
}

#+end_src

*** When to Use

Use =scan= to accumulate state over time, emitting each intermediate result. Unlike =reduce= in arrays (which only returns the final value), =scan= emits after every input.

#+begin_src text :tangle no
stream:                  --1--2--3--|
scan((a,x) => a+x, 0):  0--1--3--6--|
                        ^  ^  ^  ^
                        |  |  |  1+2+3
                        |  |  1+2
                        |  0+1
                        seed
#+end_src

#+begin_src javascript :tangle no
// Running total
const runningTotal = pipe(
  purchases,
  map(p => p.amount),
  scan((total, amount) => total + amount, 0)
)

// Collect items into an array
const allItems = pipe(
  itemStream,
  scan((arr, item) => [...arr, item], [])
)

// Track min/max/average
const stats = pipe(
  measurements,
  scan((stats, value) => ({
    min: Math.min(stats.min, value),
    max: Math.max(stats.max, value),
    sum: stats.sum + value,
    count: stats.count + 1,
    avg: (stats.sum + value) / (stats.count + 1)
  }), { min: Infinity, max: -Infinity, sum: 0, count: 0, avg: 0 })
)

// Undo/redo history
const history = pipe(
  actions,
  scan((states, action) => [...states, applyAction(states.at(-1), action)], [initialState])
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('scan', () => {
  it('accumulates values starting with seed', async () => {
    const result = await collect(scan((acc, x) => acc + x, 0, from([1, 2, 3])))
    expect(result).toEqual([0, 1, 3, 6])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::scan= is available, but note it doesn't emit the seed first by default:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Scan with seed emission first (matching JS behavior).
pub fn scan<T, U: Clone, S, F>(accumulator: F, seed: U, s: S) -> impl Stream<Item = U>
where
    S: Stream<Item = T>,
    F: Fn(U, T) -> U,
{
    stream! {
        let mut acc = seed.clone();
        yield acc.clone();
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            acc = accumulator(acc, item);
            yield acc.clone();
        }
    }
}
#+end_src

** =tap=

The =tap= function allows you to perform side effects for each value emitted by a stream without modifying the values themselves.
The side effect is fired without awaiting, so it does not block the stream processing.

#+begin_src typescript :tangle index.ts

/**
 * Performs side effects for each value emitted by a stream without modifying the values themselves.
 * The side effect is fired without awaiting, so it does not block the stream processing.
 */
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => tap(sideEffectFn, s);
  return (async function* () {
    for await (const item of stream) {
      sideEffectFn(item)
      yield item
    }
  })();
}

#+end_src

*** When to Use

Use =tap= for side effects that shouldn't block the stream: logging, analytics, non-critical updates. The side effect fires without waiting, so fast streams won't be slowed down by slow side effects.

#+begin_src text :tangle no
stream:          --1---2---3--|
tap(console.log):-1---2---3--|
                  ^
                  side effect fires, value passes through unchanged
#+end_src

#+begin_src javascript :tangle no
// Logging for debugging
const debugged = pipe(
  dataStream,
  tap(x => console.log('Processing:', x)),
  map(transform),
  tap(x => console.log('Transformed:', x))
)

// Analytics tracking (fire-and-forget)
const tracked = pipe(
  userActions,
  tap(action => analytics.track(action.type)),
  filter(action => action.important)
)

// Update UI progressively (non-blocking)
const withProgress = pipe(
  largeDataset,
  tap((_, i) => updateProgressBar(i)),
  map(processItem)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('tap', () => {
  it('performs side effect without modifying values', async () => {
    const sideEffects: number[] = []
    const values = await collect(tap(x => { sideEffects.push(x) }, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
    expect(sideEffects).toEqual([1, 2, 3])
  })

  it('does not await async side effects', async () => {
    const order: string[] = []
    const values = await collect(tap(async x => {
      await new Promise(r => setTimeout(r, 10))
      order.push(`effect-${x}`)
    }, from([1, 2])))
    order.push('done')
    expect(values).toEqual([1, 2])
    // 'done' should appear before effects complete since tap doesn't await
    expect(order[0]).toBe('done')
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Perform side effects for each value without modifying them.
/// Note: In Rust, side effects are synchronous unless you use tokio::spawn.
pub fn tap<T: Clone, S, F>(side_effect: F, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    F: Fn(&T),
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            side_effect(&item);
            yield item;
        }
    }
}

// For fire-and-forget async side effects:
pub fn tap_spawn<T: Clone + Send + 'static, S, F, Fut>(
    side_effect: F,
    s: S,
) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    F: Fn(T) -> Fut + Clone + Send + 'static,
    Fut: std::future::Future<Output = ()> + Send + 'static,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            let f = side_effect.clone();
            let item_clone = item.clone();
            tokio::spawn(async move { f(item_clone).await });
            yield item;
        }
    }
}
#+end_src

** =awaitTap=

The =awaitTap= function is like =tap=, but awaits the side effect before yielding the value.
Use this when the side effect must complete before processing continues.

#+begin_src typescript :tangle index.ts

/**
 * Performs side effects for each value emitted by a stream, awaiting completion before yielding.
 * Use this when the side effect must complete before processing continues.
 */
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => awaitTap(sideEffectFn, s);
  return (async function* () {
    for await (const item of stream) {
      await sideEffectFn(item)
      yield item
    }
  })();
}

#+end_src

*** When to Use

Use =awaitTap= when the side effect must complete before the value proceeds. This adds backpressure — the stream waits for each side effect to finish.

#+begin_src text :tangle no
stream:                --1------2------3--|
awaitTap(save, 50ms): --1------2------3--|  (each value delayed by save time)
                        ^ wait ^ wait ^
#+end_src

#+begin_src javascript :tangle no
// Ensure each item is saved before processing next
const savedItems = pipe(
  itemStream,
  awaitTap(item => database.save(item)),
  map(item => ({ ...item, saved: true }))
)

// Rate-limited API calls (wait for each to complete)
const apiResults = pipe(
  requests,
  awaitTap(req => rateLimiter.acquire()),
  map(req => fetch(req.url))
)

// Sequential file writes (one at a time)
const written = pipe(
  files,
  awaitTap(file => fs.writeFile(file.path, file.content))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('awaitTap', () => {
  it('awaits side effect before yielding', async () => {
    const order: string[] = []
    const values = await collect(awaitTap(async x => {
      await new Promise(r => setTimeout(r, 5))
      order.push(`effect-${x}`)
    }, from([1, 2])))
    order.push('done')
    expect(values).toEqual([1, 2])
    // Effects should complete before 'done' since awaitTap awaits
    expect(order).toEqual(['effect-1', 'effect-2', 'done'])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt, Future};

/// Await side effects before yielding values.
pub fn await_tap<T: Clone, S, F, Fut>(side_effect: F, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    F: Fn(T) -> Fut,
    Fut: Future<Output = ()>,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            side_effect(item.clone()).await;
            yield item;
        }
    }
}
#+end_src

** =continueWith=

The =continueWith= function allows you to continue a stream with another stream once the first one completes.
The first argument =f=, must be a function that returns the continuation stream.

#+begin_src typescript :tangle index.ts

/**
 * Continues a stream with another stream once the first one completes.
 */
export function continueWith<T>(
  f: () => AsyncIterable<T>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function continueWith<T>(
  f: () => AsyncIterable<T>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function continueWith<T>(
  f: () => AsyncIterable<T>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => continueWith(f, s);
  return (async function* () {
    yield* stream
    yield* f()
  })();
}

#+end_src

*** When to Use

Use =continueWith= to append a lazily-created stream after the first completes. The continuation function is only called when needed, unlike =concat= which takes streams directly.

#+begin_src text :tangle no
stream:                    --1--2--|
continueWith(() => B):     --1--2--3--4--|
                                  ^
                                  B() called here
#+end_src

#+begin_src javascript :tangle no
// Provide fallback data when stream is empty
const withFallback = pipe(
  primarySource,
  continueWith(() => from(fallbackData))
)

// Retry pattern: on failure, try alternative
const resilient = pipe(
  primaryApi,
  recoverWith(() => continueWith(() => backupApi, empty()))
)

// Lazy infinite stream (only created if first stream ends)
const extendable = pipe(
  finiteData,
  continueWith(() => generateMore())
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('continueWith', () => {
  it('continues with another stream after first completes', async () => {
    const values = await collect(continueWith(
      () => from([4, 5]),
      from([1, 2, 3])
    ))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('calls continuation function only after first stream completes', async () => {
    let called = false
    const values = await collect(continueWith(
      () => { called = true; return from([99]) },
      from([1])
    ))
    expect(called).toBe(true)
    expect(values).toEqual([1, 99])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Continue with another stream after the first completes.
pub fn continue_with<T, S1, S2, F>(f: F, s: S1) -> impl Stream<Item = T>
where
    S1: Stream<Item = T>,
    S2: Stream<Item = T>,
    F: FnOnce() -> S2,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            yield item;
        }
        let s2 = f();
        tokio::pin!(s2);
        while let Some(item) = s2.next().await {
            yield item;
        }
    }
}
#+end_src

** =concatAll=

The =concatAll= function flattens a stream of streams by concatenating them into a single stream.

#+begin_src typescript :tangle index.ts
/**
 * Flattens a stream of streams by concatenating them into a single stream.
 */
export async function* concatAll<T>(
  streamOfStreams: AsyncIterable<AsyncIterable<T>>,
): AsyncGenerator<T, void, void> {
  for await (const stream of streamOfStreams) yield* stream
}
#+end_src

*** When to Use

Use =concatAll= to flatten a stream of streams sequentially. Each inner stream must complete before the next one starts. Contrast with =mergeAll= which processes inner streams concurrently.

#+begin_src text :tangle no
outer:       --[A]----[B]-----|
A:             1-2|
B:                    3-4-5|
concatAll:   --1-2----3-4-5--|
                 ^
                 B waits for A to complete
#+end_src

#+begin_src javascript :tangle no
// Process file chunks in order
const allChunks = pipe(
  fileStreams,  // Stream of streams, one per file
  concatAll     // Flatten while preserving order
)

// Sequential API pagination
const allPages = pipe(
  pageStreams,  // Each page is a stream of items
  concatAll     // Items from page 1, then page 2, etc.
)

// Alternative to concatMap (manual version)
const flattened = pipe(
  items,
  map(item => from(item.children)),
  concatAll
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('concatAll', () => {
  it('flattens stream of streams in order', async () => {
    const streams = from([from([1, 2]), from([3, 4]), from([5])])
    const values = await collect(concatAll(streams))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('handles empty outer stream', async () => {
    const values = await collect(concatAll(empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::flatten= does exactly this:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Flatten a stream of streams by concatenating them.
/// Built-in: stream_of_streams.flatten()

// Custom implementation:
pub fn concat_all<T, Inner, Outer>(outer: Outer) -> impl Stream<Item = T>
where
    Inner: Stream<Item = T>,
    Outer: Stream<Item = Inner>,
{
    stream! {
        tokio::pin!(outer);
        while let Some(inner) = outer.next().await {
            tokio::pin!(inner);
            while let Some(item) = inner.next().await {
                yield item;
            }
        }
    }
}
#+end_src

** =concatMap=

=concatMap= has one argument, a function that must return a stream.
The first argument =f=, must take in the values of the source stream and return the next stream to concatenate.
You can think of it as a combination of a =map= producing streams being run through =concatAll=.

#+begin_src typescript :tangle index.ts

/**
 * Maps each value to a stream and concatenates the results in order.
 */
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => concatMap(f, s);
  return (async function* () {
    for await (const item of stream) yield* f(item)
  })();
}

#+end_src

*** When to Use

Use =concatMap= when each input needs to produce multiple outputs *in sequence*. The mapper function's stream must complete before the next input is processed. For concurrent processing, use =chain= / =flatMap= instead.

#+begin_src text :tangle no
stream:              --a--------b--------|
f(a):                  1--2|
f(b):                           3--4--5|
concatMap(f):        --1--2-----3--4--5--|
                          ^
                          f(b) waits for f(a)
#+end_src

#+begin_src javascript :tangle no
// Expand each item into multiple (ordered)
const expanded = pipe(
  users,
  concatMap(user => from(user.posts))
)
// All posts from user 1, then all from user 2, etc.

// Sequential async operations per item
const processed = pipe(
  jobs,
  concatMap(job => pipe(
    from(job.steps),
    awaitTap(step => executeStep(step))
  ))
)

// Retry with exponential backoff (one attempt at a time)
const withRetry = pipe(
  requests,
  concatMap(req => pipe(
    iterate(100, d => d * 2),
    take(5),
    concatMap(delay => pipe(
      fromPromise(fetch(req)),
      recoverWith(() => pipe(just(null), delay(delay)))
    )),
    filter(r => r !== null),
    take(1)
  ))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('concatMap', () => {
  it('maps and flattens in order', async () => {
    const values = await collect(concatMap(
      x => from([x, x * 10]),
      from([1, 2, 3])
    ))
    expect(values).toEqual([1, 10, 2, 20, 3, 30])
  })

  it('handles mapper returning empty stream', async () => {
    const values = await collect(concatMap(
      x => x > 1 ? from([x]) : empty(),
      from([1, 2, 3])
    ))
    expect(values).toEqual([2, 3])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Map each value to a stream and concatenate results in order.
pub fn concat_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
    S: Stream<Item = T>,
    Inner: Stream<Item = U>,
    F: Fn(T) -> Inner,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            let inner = f(item);
            tokio::pin!(inner);
            while let Some(inner_item) = inner.next().await {
                yield inner_item;
            }
        }
    }
}
#+end_src

* Filtering

** =filter=

The =filter= function filters values emitted by a stream based on a provided predicate function.
Supports both curried and uncurried calling conventions.

#+begin_src typescript :tangle index.ts

/**
 * Filters values emitted by a stream based on a provided predicate function.
 */
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => filter(predicate, s);
  return (async function* () {
    for await (const item of stream) if (await predicate(item)) yield item;
  })();
}

#+end_src

*** When to Use

Use =filter= to keep only values that match a condition. Values that fail the predicate are dropped entirely — downstream never sees them.

#+begin_src text :tangle no
stream:               --1--2--3--4--5--|
filter(x => x > 2):   -------3--4--5--|
                         ^
                         1 and 2 dropped
#+end_src

#+begin_src javascript :tangle no
// Only process valid items
const validItems = pipe(
  allItems,
  filter(item => item.isValid)
)

// Async predicate (e.g., permission check)
const authorized = pipe(
  requests,
  filter(async req => await checkPermission(req.userId, req.resource))
)

// Type narrowing with filter
const numbers = pipe(
  mixedStream,
  filter((x): x is number => typeof x === 'number')
)

// Chain filters for complex conditions
const results = pipe(
  events,
  filter(e => e.type === 'click'),
  filter(e => e.target.matches('.button')),
  filter(e => !e.defaultPrevented)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('filter', () => {
  it('keeps values matching predicate', async () => {
    const result = await collect(filter(x => x % 2 === 0, from([1, 2, 3, 4])))
    expect(result).toEqual([2, 4])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::filter= is built-in:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.filter(|x| future::ready(x % 2 == 0))

// Custom implementation for sync predicates:
use async_stream::stream;

pub fn filter<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    P: Fn(&T) -> bool,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            if predicate(&item) {
                yield item;
            }
        }
    }
}

// For async predicates:
pub fn filter_async<T, S, P, Fut>(predicate: P, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    P: Fn(&T) -> Fut,
    Fut: std::future::Future<Output = bool>,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            if predicate(&item).await {
                yield item;
            }
        }
    }
}
#+end_src

** =skipRepeats=

The =skipRepeats= function filters out consecutive duplicate values from a stream.

#+begin_src typescript :tangle index.ts

/**
 * Filters out consecutive duplicate values from a stream.
 */
export async function* skipRepeats<T>(
  stream: AsyncIterable<T>,
): AsyncGenerator<T, void, void> {
  let first = true
  let lastValue: T | undefined
  for await (const item of stream) {
    if (first || item !== lastValue) {
      lastValue = item
      yield item
      first = false
    }
  }
}

#+end_src

*** When to Use

Use =skipRepeats= to suppress consecutive duplicates. Only emits when the value changes from the previous one. Uses strict equality (~===~) for comparison.

#+begin_src text :tangle no
stream:       --1--1--2--2--3--1--1--|
skipRepeats:  --1-----2-----3--1-----|
                 ^     ^        ^
                 consecutive 1s and 2s dropped,
                 but new 1 at end emits
#+end_src

#+begin_src javascript :tangle no
// UI: Only update when state actually changes
const distinctStates = pipe(
  stateStream,
  skipRepeats
)

// Avoid redundant API calls
const distinctQueries = pipe(
  searchInput,
  debounce(300),
  skipRepeats  // Don't search if query unchanged
)

// Filter out repeated sensor readings
const changedReadings = pipe(
  sensorData,
  map(d => d.value),
  skipRepeats
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('skipRepeats', () => {
  it('filters consecutive duplicates', async () => {
    const values = await collect(skipRepeats(from([1, 1, 2, 2, 3, 1, 1])))
    expect(values).toEqual([1, 2, 3, 1])
  })

  it('handles empty stream', async () => {
    const values = await collect(skipRepeats(empty()))
    expect(values).toEqual([])
  })

  it('handles single value', async () => {
    const values = await collect(skipRepeats(from([42])))
    expect(values).toEqual([42])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::dedup= doesn't exist by default; use =itertools= or custom:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Filter out consecutive duplicate values.
pub fn skip_repeats<T: PartialEq + Clone, S: Stream<Item = T>>(s: S) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s);
        let mut last: Option<T> = None;
        while let Some(item) = s.next().await {
            let should_yield = match &last {
                None => true,
                Some(prev) => item != *prev,
            };
            if should_yield {
                last = Some(item.clone());
                yield item;
            }
        }
    }
}
#+end_src

** =skipRepeatsWith=

The =skipRepeatsWith= function filters out consecutive duplicate values from a stream based on a provided equality function.

#+begin_src typescript :tangle index.ts

/**
 * Filters out consecutive duplicate values from a stream based on a provided equality function.
 */
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skipRepeatsWith(equals, s);
  return (async function* () {
    let first = true
    let lastValue: T | undefined
    for await (const item of stream) {
      if (first || !(await equals(item, lastValue as T))) {
        lastValue = item
        yield item
        first = false
      }
    }
  })();
}

#+end_src

*** When to Use

Use =skipRepeatsWith= when you need custom equality logic for detecting duplicates. Useful for objects, where reference equality isn't meaningful.

#+begin_src text :tangle no
stream:                      --{a:1}--{a:1}--{a:2}--|
skipRepeatsWith(byA):        --{a:1}--------{a:2}--|
                                      ^
                                      same .a value, dropped
#+end_src

#+begin_src javascript :tangle no
// Compare objects by specific field
const distinctUsers = pipe(
  userUpdates,
  skipRepeatsWith((a, b) => a.id === b.id && a.version === b.version)
)

// Deep equality check
const distinctConfigs = pipe(
  configStream,
  skipRepeatsWith((a, b) => JSON.stringify(a) === JSON.stringify(b))
)

// Fuzzy equality (within tolerance)
const significantChanges = pipe(
  measurements,
  skipRepeatsWith((a, b) => Math.abs(a - b) < 0.01)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('skipRepeatsWith', () => {
  it('filters based on custom equality', async () => {
    const values = await collect(skipRepeatsWith(
      (a, b) => Math.floor(a) === Math.floor(b),
      from([1.1, 1.2, 2.1, 2.2, 3.0])
    ))
    expect(values).toEqual([1.1, 2.1, 3.0])
  })

  it('supports async predicate', async () => {
    const values = await collect(skipRepeatsWith(
      async (a, b) => a === b,
      from([1, 1, 2])
    ))
    expect(values).toEqual([1, 2])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Filter consecutive duplicates using a custom equality function.
pub fn skip_repeats_with<T: Clone, S, F>(equals: F, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    F: Fn(&T, &T) -> bool,
{
    stream! {
        tokio::pin!(s);
        let mut last: Option<T> = None;
        while let Some(item) = s.next().await {
            let should_yield = match &last {
                None => true,
                Some(prev) => !equals(&item, prev),
            };
            if should_yield {
                last = Some(item.clone());
                yield item;
            }
        }
    }
}
#+end_src

* Slicing

** =take=

The =take= function creates a stream that emits only the first =n= values from the source stream.
Supports both curried and uncurried calling conventions.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits only the first `n` values from the source stream.
 */
export function take<T>(
  n: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function take<T>(
  n: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function take<T>(
  n: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => take(n, s);
  return (async function* () {
    let count = 0;
    for await (const item of stream) {
      if (count++ < n) yield item;
      else break;
    }
  })();
}

#+end_src

*** When to Use

Use =take= to limit the number of values from a stream. Essential for working with infinite streams or when you only need the first N results.

#+begin_src text :tangle no
stream:     --1--2--3--4--5--|
take(3):    --1--2--3|         (completes early)
                    ^
                    stops after 3 values
#+end_src

#+begin_src javascript :tangle no
// Get first 10 search results
const topResults = pipe(
  searchResults,
  take(10)
)

// Limit infinite streams
const sample = pipe(
  periodic(100),
  take(5)  // Only 5 ticks
)

// "First N or all if fewer" pattern
const preview = pipe(
  items,
  take(3)  // At most 3 items for preview
)

// Take first match (like find but as stream)
const firstMatch = pipe(
  allItems,
  filter(item => item.matches(criteria)),
  take(1)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('take', () => {
  it('takes only first N values', async () => {
    const result = await collect(take(2, from([1, 2, 3, 4, 5])))
    expect(result).toEqual([1, 2])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::take= is built-in:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.take(n)

// Custom implementation for reference:
use async_stream::stream;

pub fn take<T, S: Stream<Item = T>>(n: usize, s: S) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s);
        let mut count = 0;
        while let Some(item) = s.next().await {
            if count < n {
                yield item;
                count += 1;
            } else {
                break;
            }
        }
    }
}
#+end_src

** =skip=

The =skip= function creates a stream that skips the first =n= values from the source stream and emits the rest.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that skips the first `n` values from the source stream and emits the rest.
 */
export function skip<T>(
  n: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skip<T>(
  n: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skip<T>(
  n: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skip(n, s);
  return (async function* () {
    let count = 0;
    for await (const item of stream) if (count++ >= n) yield item;
  })();
}

#+end_src

*** When to Use

Use =skip= to ignore the first N values from a stream. The stream still processes those values — it just doesn't emit them.

#+begin_src text :tangle no
stream:     --1--2--3--4--5--|
skip(2):    -------3--4--5--|
               ^
               first 2 values dropped
#+end_src

#+begin_src javascript :tangle no
// Skip header row in CSV data
const dataRows = pipe(
  csvRows,
  skip(1)  // Skip header
)

// Pagination: skip to page N
const page3 = pipe(
  allItems,
  skip(20),   // Skip pages 1-2 (10 items each)
  take(10)    // Take page 3
)

// Ignore initial "loading" state
const loadedStates = pipe(
  stateStream,
  skip(1)  // Skip initial empty/loading state
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('skip', () => {
  it('skips first N values', async () => {
    const result = await collect(skip(2, from([1, 2, 3, 4, 5])))
    expect(result).toEqual([3, 4, 5])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::skip= is built-in:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.skip(n)

// Custom implementation:
use async_stream::stream;

pub fn skip<T, S: Stream<Item = T>>(n: usize, s: S) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s);
        let mut count = 0;
        while let Some(item) = s.next().await {
            if count >= n {
                yield item;
            }
            count += 1;
        }
    }
}
#+end_src

** =slice=

The =slice= function creates a stream that emits values from the source stream starting from index =start= up to, but not including, index =end=.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits values from the source stream starting from index `start` up to, but not including, index `end`.
 */
export function slice<T>(
  start: number,
  end: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function slice<T>(
  start: number,
  end: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function slice<T>(
  start: number,
  end: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => slice(start, end, s);
  return (async function* () {
    let index = 0
    for await (const item of stream) {
      if (index >= start && index < end) yield item
      if (index++ >= end) break
    }
  })();
}

#+end_src

*** When to Use

Use =slice= to extract a range of values by index, like Array.slice(). Combines the functionality of =skip= and =take= in a single operator.

#+begin_src text :tangle no
stream:         --0--1--2--3--4--5--|
slice(1, 4):    -----1--2--3|        
                  ^        ^
                  start    end (exclusive)
#+end_src

#+begin_src javascript :tangle no
// Get items 10-20 (pagination)
const page2 = pipe(
  allItems,
  slice(10, 20)
)

// Skip first and last (equivalent to slice(1, -1) for known length)
const middle = pipe(
  items,
  slice(1, items.length - 1)
)

// Extract specific range for processing
const range = pipe(
  dataPoints,
  slice(100, 200)  // Points 100-199
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('slice', () => {
  it('emits values from start to end indices', async () => {
    const values = await collect(slice(1, 4, from([0, 1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3])
  })

  it('handles start at 0', async () => {
    const values = await collect(slice(0, 2, from([10, 20, 30])))
    expect(values).toEqual([10, 20])
  })

  it('returns empty for out of range', async () => {
    const values = await collect(slice(10, 20, from([1, 2, 3])))
    expect(values).toEqual([])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Emit values from index start to end (exclusive).
pub fn slice<T, S: Stream<Item = T>>(start: usize, end: usize, s: S) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s);
        let mut index = 0;
        while let Some(item) = s.next().await {
            if index >= start && index < end {
                yield item;
            }
            index += 1;
            if index >= end {
                break;
            }
        }
    }
}

// Or using built-in methods:
// stream.skip(start).take(end - start)
#+end_src

** =takeWhile=

The =takeWhile= function creates a stream that emits values from the source stream as long as the provided predicate function returns true and ends the stream as soon as it returns false.

#+begin_src typescript :tangle index.ts
/**
 * Creates a stream that emits values from the source stream as long as the provided predicate function returns true.
 */
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => takeWhile(predicate, s);
  return (async function* () {
    for await (const item of stream) {
      if (await predicate(item)) yield item
      else break
    }
  })();
}

#+end_src

*** When to Use

Use =takeWhile= to take values as long as a condition holds, stopping at the first failure. The failing value is *not* emitted.

#+begin_src text :tangle no
stream:              --1--2--3--4--5--|
takeWhile(x < 4):    --1--2--3|         (stops at 4)
                              ^
                              4 fails predicate, stream ends
#+end_src

#+begin_src javascript :tangle no
// Read until end marker
const untilEnd = pipe(
  lines,
  takeWhile(line => line !== 'END')
)

// Process while resources available
const whileAvailable = pipe(
  tasks,
  takeWhile(() => memory.available > threshold)
)

// Countdown until zero
const countdown = pipe(
  iterate(10, n => n - 1),
  takeWhile(n => n >= 0)
)
// yields: 10, 9, 8, ..., 1, 0
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('takeWhile', () => {
  it('takes while predicate is true', async () => {
    const values = await collect(takeWhile(x => x < 4, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3])
  })

  it('stops at first false', async () => {
    const values = await collect(takeWhile(x => x !== 'stop', from(['a', 'b', 'stop', 'c'])))
    expect(values).toEqual(['a', 'b'])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::take_while= is built-in:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.take_while(|x| future::ready(*x < 4))

// Custom implementation:
use async_stream::stream;

pub fn take_while<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    P: Fn(&T) -> bool,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            if predicate(&item) {
                yield item;
            } else {
                break;
            }
        }
    }
}
#+end_src

** =skipWhile=

The =skipWhile= function creates a stream that skips values from the source stream as long as the provided predicate function returns true and starts emitting values as soon as it returns false.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that skips values from the source stream while the provided predicate function returns true, then emits the rest of the stream.
 */
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skipWhile(predicate, s);
  return (async function* () {
    let match = false
    for await (const item of stream) {
      if (!match && !(await predicate(item))) match = true
      if (match) yield item
    }
  })();
}

#+end_src

*** When to Use

Use =skipWhile= to drop values as long as a condition holds, then emit everything after. Once the predicate fails, all subsequent values pass through (even if they would match the predicate).

#+begin_src text :tangle no
stream:              --1--2--3--4--2--1--|
skipWhile(x < 3):    -------3--4--2--1--|
                        ^
                        first value where predicate fails,
                        all values after are emitted
#+end_src

#+begin_src javascript :tangle no
// Skip header comments in a file
const codeLines = pipe(
  fileLines,
  skipWhile(line => line.startsWith('#'))
)

// Skip loading states, start from first real data
const realData = pipe(
  states,
  skipWhile(state => state.loading)
)

// Skip until a specific marker
const afterMarker = pipe(
  events,
  skipWhile(e => e.type !== 'START'),
  skip(1)  // Also skip the START event itself
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('skipWhile', () => {
  it('skips while predicate is true then emits rest', async () => {
    const values = await collect(skipWhile(x => x < 3, from([1, 2, 3, 4, 2, 1])))
    expect(values).toEqual([3, 4, 2, 1])
  })

  it('emits all if predicate never true', async () => {
    const values = await collect(skipWhile(() => false, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::skip_while= is built-in:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.skip_while(|x| future::ready(*x < 3))

// Custom implementation:
use async_stream::stream;

pub fn skip_while<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    P: Fn(&T) -> bool,
{
    stream! {
        tokio::pin!(s);
        let mut skipping = true;
        while let Some(item) = s.next().await {
            if skipping && !predicate(&item) {
                skipping = false;
            }
            if !skipping {
                yield item;
            }
        }
    }
}
#+end_src

** =takeUntil=

The =takeUntil= function creates a stream that emits values from the source stream until the provided predicate function returns true, at which point it completes (the matching value is *not* emitted).

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits values from the source stream until the provided predicate function returns true.
 * The matching value is not emitted.
 */
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => takeUntil(predicate, s);
  return (async function* () {
    for await (const item of stream) {
      if (await predicate(item)) break
      yield item
    }
  })();
}

#+end_src

*** When to Use

Use =takeUntil= to take values until a condition is met, then stop. The matching value is *not* emitted (exclusive). Contrast with =takeWhile= which stops when the condition *fails*.

#+begin_src text :tangle no
stream:               --1--2--3--4--5--|
takeUntil(x === 3):   --1--2|            (stops before 3)
                            ^
                            3 matches, not emitted, stream ends
#+end_src

#+begin_src javascript :tangle no
// Process until error marker
const untilError = pipe(
  messages,
  takeUntil(msg => msg.type === 'ERROR')
)

// Read stream until timeout
const withTimeout = pipe(
  dataStream,
  takeUntil(() => Date.now() > deadline)
)

// Process until user cancels
const untilCancel = pipe(
  workItems,
  takeUntil(() => cancelled)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('takeUntil', () => {
  it('takes until predicate matches (exclusive)', async () => {
    const values = await collect(takeUntil(x => x === 3, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2])
  })

  it('emits all if predicate never matches', async () => {
    const values = await collect(takeUntil(() => false, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Take values until predicate matches (matching value not emitted).
pub fn take_until<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
    S: Stream<Item = T>,
    P: Fn(&T) -> bool,
{
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            if predicate(&item) {
                break;
            }
            yield item;
        }
    }
}
#+end_src

* Time-based Operators

These operators work with time, adding delays or controlling the rate of emissions.

** =delay=

The =delay= operator delays each emission by a specified duration.

#+begin_src typescript :tangle index.ts

/**
 * Delays each value emitted by the source stream by the specified duration.
 */
export function delay<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function delay<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function delay<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => delay(ms, s);
  return (async function* () {
    for await (const item of stream) {
      await new Promise(r => setTimeout(r, ms))
      yield item
    }
  })();
}

#+end_src

*** When to Use

Use =delay= to add a pause before each emission. Each value is held for the specified duration before being yielded downstream.

#+begin_src text :tangle no
time:         0ms    100ms   200ms    300ms
stream:       --1-------2-------3--|
delay(50):    ----1-------2-------3--|
                  ^
                  each value delayed by 50ms
#+end_src

#+begin_src javascript :tangle no
// Simulate network latency in tests
const slowResponse = pipe(
  mockData,
  delay(500)  // Simulate 500ms network delay
)

// Rate-limit outgoing messages
const throttledMessages = pipe(
  messages,
  delay(100)  // At most 10 messages per second
)

// Stagger animations
const staggered = pipe(
  elements,
  delay(50),
  tap(el => el.classList.add('visible'))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('delay', () => {
  it('delays each emission', async () => {
    const start = Date.now()
    const values = await collect(delay(20, from([1, 2, 3])))
    const elapsed = Date.now() - start
    expect(values).toEqual([1, 2, 3])
    expect(elapsed).toBeGreaterThanOrEqual(50)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2]), delay(10)))
    expect(values).toEqual([1, 2])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::time::{sleep, Duration};

/// Delay each value by a specified duration.
pub fn delay<T, S: Stream<Item = T>>(ms: u64, s: S) -> impl Stream<Item = T> {
    stream! {
        tokio::pin!(s);
        while let Some(item) = s.next().await {
            sleep(Duration::from_millis(ms)).await;
            yield item;
        }
    }
}
#+end_src

** =debounce=

The =debounce= operator only emits a value if no new values arrive within the specified duration.
It waits for the stream to "settle" before emitting the most recent value.

#+begin_src typescript :tangle index.ts

/**
 * Only emits a value from the source stream if no new value arrives within the specified duration.
 * Useful for waiting until input has "settled" (e.g., user stops typing).
 */
export function debounce<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function debounce<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function debounce<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => debounce(ms, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let pending: { value: T; timer: ReturnType<typeof setTimeout> } | null = null
    let done = false
    let pendingResolve: ((value: T | null) => void) | null = null

    const emitPending = () => {
      if (pending && pendingResolve) {
        const value = pending.value
        pending = null
        pendingResolve(value)
        pendingResolve = null
      }
    }

    // Start consuming source in background
    ;(async () => {
      try {
        while (true) {
          const result = await iterator.next()
          if (result.done) {
            done = true
            // Emit any pending value immediately on completion
            if (pending) {
              clearTimeout(pending.timer)
              emitPending()
            } else if (pendingResolve) {
              const resolver: (value: T | null) => void = pendingResolve
              resolver(null)
            }
            break
          }
          // Cancel previous timer
          if (pending) clearTimeout(pending.timer)
          // Set new pending value with timer
          pending = {
            value: result.value,
            timer: setTimeout(emitPending, ms)
          }
        }
      } catch (e) {
        // Handle errors by clearing pending and re-throwing via the generator
        if (pending) clearTimeout(pending.timer)
        pending = null
        throw e
      }
    })()

    // Yield debounced values
    while (!done || pending) {
      const value = await new Promise<T | null>(resolve => {
        if (done && !pending) {
          resolve(null)
          return
        }
        pendingResolve = resolve
      })
      if (value !== null) yield value
      if (done && !pending) break
    }
  })();
}

#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('debounce', () => {
  it('only emits after stream settles', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 10 })
    const values = await collect(debounce(30, stream))
    // Only the last value should be emitted since delay < debounce time
    expect(values).toEqual([3])
  })

  it('emits multiple values when gaps are large enough', async () => {
    const stream = createAsyncIterable([1, 2], { delay: 50 })
    const values = await collect(debounce(20, stream))
    // Both should emit since delay > debounce time
    expect(values).toEqual([1, 2])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1]), debounce(5)))
    expect(values).toEqual([1])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::time::{sleep, Duration, Instant};
use std::pin::Pin;
use futures::future::Fuse;
use futures::FutureExt;

/// Only emit a value if no new values arrive within the specified duration.
pub fn debounce<T: Clone, S: Stream<Item = T> + Unpin>(ms: u64, mut s: S) -> impl Stream<Item = T> {
    stream! {
        let duration = Duration::from_millis(ms);
        let mut pending: Option<T> = None;
        let mut timer: Option<Pin<Box<tokio::time::Sleep>>> = None;

        loop {
            tokio::select! {
                biased;

                item = s.next() => {
                    match item {
                        Some(value) => {
                            pending = Some(value);
                            timer = Some(Box::pin(sleep(duration)));
                        }
                        None => {
                            // Stream ended, emit any pending value
                            if let Some(value) = pending.take() {
                                yield value;
                            }
                            break;
                        }
                    }
                }
                _ = async {
                    if let Some(ref mut t) = timer {
                        t.await;
                    } else {
                        std::future::pending::<()>().await;
                    }
                } => {
                    if let Some(value) = pending.take() {
                        yield value;
                    }
                    timer = None;
                }
            }
        }
    }
}
#+end_src

** =throttle=

The =throttle= operator limits the rate of emissions.
It's configurable with =leading= (emit first value immediately) and =trailing= (emit last value after window) options.

#+begin_src typescript :tangle index.ts

/**
 * Options for throttle behavior.
 */
export interface ThrottleOptions {
  /** Emit the first value immediately when the window starts (default: true) */
  leading?: boolean
  /** Emit the last value after the window ends (default: true) */
  trailing?: boolean
}

/**
 * Limits the rate of emissions from a stream.
 * 
 * @param ms - The throttle window duration in milliseconds
 * @param options - Configure leading/trailing edge behavior
 *   - leading: emit first value immediately (default: true)
 *   - trailing: emit last value after window (default: true)
 */
export function throttle<T>(
  ms: number,
  options?: ThrottleOptions
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function throttle<T>(
  ms: number,
  options: ThrottleOptions | undefined,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function throttle<T>(
  ms: number,
  optionsOrStream?: ThrottleOptions | AsyncIterable<T>,
  maybeStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  // Parse arguments: supports throttle(ms), throttle(ms, opts), throttle(ms, opts, stream)
  let options: ThrottleOptions
  let stream: AsyncIterable<T> | undefined
  
  if (maybeStream !== undefined) {
    options = (optionsOrStream as ThrottleOptions) ?? {}
    stream = maybeStream
  } else if (optionsOrStream !== undefined && typeof (optionsOrStream as any)[Symbol.asyncIterator] === 'function') {
    options = {}
    stream = optionsOrStream as AsyncIterable<T>
  } else {
    options = (optionsOrStream as ThrottleOptions) ?? {}
    stream = undefined
  }

  const { leading = true, trailing = true } = options

  if (stream === undefined) return (s: AsyncIterable<T>) => throttle(ms, options, s);
  
  const sourceStream = stream
  return (async function* () {
    let lastEmitTime = 0
    let trailingValue: T | undefined
    let hasTrailingValue = false
    let trailingTimer: ReturnType<typeof setTimeout> | null = null

    const emitTrailing = function* (): Generator<T, void, void> {
      if (hasTrailingValue && trailing) {
        yield trailingValue as T
        hasTrailingValue = false
        lastEmitTime = Date.now()
      }
    }

    for await (const item of sourceStream) {
      const now = Date.now()
      const elapsed = now - lastEmitTime

      if (elapsed >= ms) {
        // Window has passed
        if (leading) {
          yield item
          lastEmitTime = now
          hasTrailingValue = false
        } else {
          // Store for trailing
          trailingValue = item
          hasTrailingValue = true
        }
      } else {
        // Within window, store for trailing
        trailingValue = item
        hasTrailingValue = true
      }
    }

    // Emit final trailing value if any
    if (hasTrailingValue && trailing) {
      yield trailingValue as T
    }
  })();
}

#+end_src

*** When to Use

Use =throttle= to limit how frequently values are emitted. Unlike =debounce= (which waits for quiet), =throttle= ensures regular updates during continuous activity.

#+begin_src text :tangle no
time:             0   100  200  300  400  500  600
stream:           a-b-c-d-e-f-g-h-i-j-k-|
                  ^ ^       ^       ^   ^
                  rapid continuous emissions

throttle(200):    a-------d-------g-----k|
                  ^       ^       ^     ^
                  leading trailing leading trailing
                  (first) (last   (first (final)
                          in       after
                          window)  window)
#+end_src

#+begin_src javascript :tangle no
// Scroll position updates (max 10 per second)
const scrollPosition = pipe(
  fromEvent(window, 'scroll'),
  map(() => window.scrollY),
  throttle(100)  // At most every 100ms
)

// Mouse move tracking
const mousePosition = pipe(
  fromEvent(document, 'mousemove'),
  map(e => ({ x: e.clientX, y: e.clientY })),
  throttle(16)  // ~60fps
)

// Progress updates (don't spam UI)
const progressUpdates = pipe(
  rawProgress,
  throttle(250, { leading: true, trailing: true })
)

// Rate-limited API polling
const apiData = pipe(
  trigger,
  throttle(1000, { leading: true, trailing: false }),
  chain(() => fetchData())
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('throttle', () => {
  it('limits emission rate with default options', async () => {
    const stream = createAsyncIterable([1, 2, 3, 4, 5], { delay: 10 })
    const values = await collect(throttle(25, {}, stream))
    // First emits immediately, then throttled
    expect(values.length).toBeLessThan(5)
    expect(values[0]).toBe(1)
  })

  it('respects leading: false', async () => {
    const values = await collect(throttle(50, { leading: false }, from([1, 2, 3])))
    // Should not emit leading values
    expect(values.length).toBeGreaterThan(0)
  })

  it('respects trailing: false', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 5 })
    const values = await collect(throttle(20, { trailing: false }, stream))
    // Should only emit leading values
    expect(values).toContain(1)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3]), throttle(10)))
    expect(values.length).toBeGreaterThan(0)
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::time::{Instant, Duration};

pub struct ThrottleOptions {
    pub leading: bool,
    pub trailing: bool,
}

impl Default for ThrottleOptions {
    fn default() -> Self {
        Self { leading: true, trailing: true }
    }
}

/// Limit emission rate with leading/trailing edge control.
pub fn throttle<T: Clone, S: Stream<Item = T> + Unpin>(
    ms: u64,
    options: ThrottleOptions,
    mut s: S,
) -> impl Stream<Item = T> {
    stream! {
        let duration = Duration::from_millis(ms);
        let mut last_emit = Instant::now() - duration;  // Allow first emit
        let mut trailing_value: Option<T> = None;

        while let Some(item) = s.next().await {
            let now = Instant::now();
            let elapsed = now.duration_since(last_emit);

            if elapsed >= duration {
                if options.leading {
                    yield item;
                    last_emit = now;
                    trailing_value = None;
                } else {
                    trailing_value = Some(item);
                }
            } else {
                trailing_value = Some(item);
            }
        }

        // Emit final trailing value
        if options.trailing {
            if let Some(value) = trailing_value {
                yield value;
            }
        }
    }
}
#+end_src

* Error Handling

** =recoverWith= 

The =recoverWith= function allows you to recover from errors in a stream by providing a function that returns an alternative stream when an error occurs.

#+begin_src typescript :tangle index.ts

/**
 * Recovers from errors in a stream by providing an alternative stream.
 */
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => recoverWith(recoverFn, s);
  return (async function* () {
    try { yield* stream }
    catch (error) { yield* recoverFn(error as E) }
  })();
}

#+end_src

*** When to Use

Use =recoverWith= to gracefully handle errors by switching to an alternative stream. The error is passed to your recovery function, allowing error-specific handling.

#+begin_src text :tangle no
stream:               --1--2--X
                             ^
                             error thrown

recoverWith(fallback): -1--2--a--b--|   
                             ^
                             switches to fallback stream
#+end_src

#+begin_src javascript :tangle no
// Fallback to cached data on network error
const data = pipe(
  networkStream,
  recoverWith(err => {
    console.error('Network failed:', err)
    return from(cachedData)
  })
)

// Provide default value on parse error
const parsed = pipe(
  rawData,
  map(JSON.parse),
  recoverWith(() => just({ error: 'Invalid JSON' }))
)

// Log and continue empty on non-critical errors
const resilient = pipe(
  allItems,
  recoverWith(err => {
    logError(err)
    return empty()
  })
)

// Error-specific recovery
const smart = pipe(
  apiCall,
  recoverWith(err => {
    if (err.status === 404) return just(null)
    if (err.status === 401) return fromPromise(refreshAndRetry())
    throw err  // Re-throw unexpected errors
  })
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('recoverWith', () => {
  it('yields values from recovery stream on error', async () => {
    const failing = throwError(new Error('oops'))
    const values = await collect(recoverWith(
      () => from([1, 2, 3]),
      failing
    ))
    expect(values).toEqual([1, 2, 3])
  })

  it('passes error to recovery function', async () => {
    let capturedError: Error | undefined
    const failing = throwError(new Error('captured'))
    await collect(recoverWith(
      (e: Error) => { capturedError = e; return empty() },
      failing
    ))
    expect(capturedError?.message).toBe('captured')
  })

  it('yields source values if no error', async () => {
    const values = await collect(recoverWith(
      () => from(['fallback']),
      from(['success'])
    ))
    expect(values).toEqual(['success'])
  })
})
#+end_src

*** Rust Implementation

In Rust, we use =Result= types for error handling in streams:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use std::error::Error;

/// For streams that emit Result<T, E>, recover from errors.
pub fn recover_with<T, E, S, S2, F>(
    recover_fn: F,
    s: S,
) -> impl Stream<Item = T>
where
    S: Stream<Item = Result<T, E>>,
    S2: Stream<Item = T>,
    F: FnOnce(E) -> S2,
    E: Error,
{
    stream! {
        tokio::pin!(s);
        loop {
            match s.next().await {
                Some(Ok(item)) => yield item,
                Some(Err(e)) => {
                    let recovery = recover_fn(e);
                    tokio::pin!(recovery);
                    while let Some(item) = recovery.next().await {
                        yield item;
                    }
                    break;
                }
                None => break,
            }
        }
    }
}

// Alternatively, using TryStreamExt from futures:
// use futures::TryStreamExt;
// stream.or_else(|e| async move { Ok(fallback_value) })
#+end_src

** =throwError=

The =throwError= function creates a stream that immediately throws an error when consumed.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that immediately throws an error when consumed.
 */
export async function* throwError<E = unknown>(
    error: E
): AsyncGenerator<never, void, void> {
  throw error
}

#+end_src

*** When to Use

Use =throwError= to create a stream that immediately fails. Useful for testing error handling, conditional error injection, or signaling failures in stream compositions.

#+begin_src text :tangle no
throwError(new Error('fail')):  X
                                ^
                                immediately throws
#+end_src

#+begin_src javascript :tangle no
// Validate input before processing
const validated = input.isValid
  ? from(input.data)
  : throwError(new Error('Invalid input'))

// Test error handling
const mockFailingApi = throwError(new Error('Network timeout'))
await expectStream(pipe(
  mockFailingApi,
  recoverWith(() => just('fallback'))
)).toEmit(['fallback'])

// Conditional failure in pipeline
const checked = pipe(
  items,
  chain(item => item.required 
    ? just(item) 
    : throwError(new Error(`Missing required: ${item.name}`))
  )
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('throwError', () => {
  it('creates a stream that immediately errors', async () => {
    await expectStream(throwError(new Error('test error')))
      .toErrorWith('test error')
  })
})
#+end_src

*** Rust Implementation

In Rust, we'd emit an =Err= in a Result stream:

#+begin_src rust :tangle no
use futures::stream::{self, Stream};

/// Creates a stream that immediately emits an error.
pub fn throw_error<T, E: Clone>(error: E) -> impl Stream<Item = Result<T, E>> {
    stream::once(async move { Err(error) })
}

// For panicking (not recommended for production):
use async_stream::stream;

pub fn throw_panic<T>(message: &'static str) -> impl Stream<Item = T> {
    stream! {
        panic!("{}", message);
    }
}
#+end_src

** =retry=

The =retry= function attempts to resubscribe to a stream when it errors.
You can specify the maximum number of retry attempts.

*Note:* Error handling in streams is an evolving area. This implementation provides a simple retry mechanism,
but more sophisticated approaches (exponential backoff, conditional retries, etc.) may be needed for production use.
Consider wrapping =retry= with custom logic for your specific needs.

#+begin_src typescript :tangle index.ts

/**
 * Options for retry behavior.
 */
export interface RetryOptions {
  /** Maximum number of retry attempts (default: 3) */
  maxAttempts?: number
  /** Delay between retries in milliseconds (default: 0) */
  delayMs?: number
  /** Optional predicate to decide whether to retry based on the error */
  shouldRetry?: (error: unknown, attempt: number) => boolean
}

/**
 * Retries a stream factory when it errors.
 * 
 * @param options - Retry configuration
 * @param streamFactory - A function that creates the stream to retry
 */
export function retry<T>(
  options: RetryOptions | number
): (streamFactory: () => AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function retry<T>(
  options: RetryOptions | number,
  streamFactory: () => AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function retry<T>(
  options: RetryOptions | number,
  streamFactory?: () => AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((streamFactory: () => AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  const opts: RetryOptions = typeof options === 'number' ? { maxAttempts: options } : options
  const { maxAttempts = 3, delayMs = 0, shouldRetry = () => true } = opts

  if (streamFactory === undefined) return (sf: () => AsyncIterable<T>) => retry(opts, sf);
  
  const factory = streamFactory
  return (async function* () {
    let attempt = 0
    while (true) {
      try {
        yield* factory()
        return // Success, exit
      } catch (error) {
        attempt++
        if (attempt >= maxAttempts || !shouldRetry(error, attempt)) {
          throw error
        }
        if (delayMs > 0) {
          await new Promise(r => setTimeout(r, delayMs))
        }
        // Continue to next attempt
      }
    }
  })();
}

#+end_src

*** When to Use

Use =retry= when operations may fail transiently (network issues, rate limits, temporary unavailability). Provide a *factory function* that creates fresh streams for each attempt.

#+begin_src text :tangle no
streamFactory():    --1--X     (fails)
retry(3):           --1--X     (attempt 1)
                    --1--X     (attempt 2)
                    --1--2--|  (attempt 3: success!)
result:             --1--2--|
#+end_src

#+begin_src javascript :tangle no
// Simple retry with max attempts
const resilientFetch = retry(3, () => 
  fromPromise(fetch('/api/data').then(r => r.json()))
)

// Retry with exponential backoff
const withBackoff = retry({
  maxAttempts: 5,
  delayMs: 1000,  // Start with 1s delay
  shouldRetry: (err, attempt) => {
    console.log(`Attempt ${attempt} failed:`, err)
    return true
  }
}, () => fetchLatestData())

// Retry only specific errors
const selectiveRetry = retry({
  maxAttempts: 3,
  shouldRetry: (err) => {
    // Only retry network errors, not validation errors
    return err.name === 'NetworkError' || err.status === 503
  }
}, () => apiCall())

// Combine with recoverWith for fallback after all retries fail
const withFallback = pipe(
  retry(3, () => primaryApi()),
  recoverWith(() => just(fallbackData))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('retry', () => {
  it('retries on error up to maxAttempts', async () => {
    let attempts = 0
    const values = await collect(retry(3, () => {
      attempts++
      if (attempts < 3) return throwError(new Error('fail'))
      return from([1, 2, 3])
    }))
    expect(attempts).toBe(3)
    expect(values).toEqual([1, 2, 3])
  })

  it('throws after maxAttempts exceeded', async () => {
    let attempts = 0
    await expect(collect(retry(2, () => {
      attempts++
      return throwError(new Error('always fails'))
    }))).rejects.toThrow('always fails')
    expect(attempts).toBe(2)
  })

  it('supports options object', async () => {
    let attempts = 0
    await collect(retry({ maxAttempts: 2, delayMs: 10 }, () => {
      attempts++
      if (attempts < 2) return throwError(new Error('fail'))
      return from(['ok'])
    }))
    expect(attempts).toBe(2)
  })

  it('supports shouldRetry predicate', async () => {
    let attempts = 0
    await expect(collect(retry({
      maxAttempts: 5,
      shouldRetry: (err, attempt) => attempt < 2
    }, () => {
      attempts++
      return throwError(new Error('fail'))
    }))).rejects.toThrow('fail')
    expect(attempts).toBe(2)
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt, TryStreamExt};
use tokio::time::{sleep, Duration};
use std::error::Error;

pub struct RetryOptions<F> {
    pub max_attempts: usize,
    pub delay_ms: u64,
    pub should_retry: F,
}

/// Retry a stream factory on error.
pub fn retry<T, E, S, F, SR>(
    max_attempts: usize,
    delay_ms: u64,
    mut stream_factory: F,
) -> impl Stream<Item = Result<T, E>>
where
    S: Stream<Item = Result<T, E>>,
    F: FnMut() -> S,
    E: Clone,
{
    stream! {
        let mut attempt = 0;
        loop {
            let s = stream_factory();
            tokio::pin!(s);
            let mut failed = false;
            
            while let Some(item) = s.next().await {
                match item {
                    Ok(value) => yield Ok(value),
                    Err(e) => {
                        attempt += 1;
                        if attempt >= max_attempts {
                            yield Err(e);
                            return;
                        }
                        if delay_ms > 0 {
                            sleep(Duration::from_millis(delay_ms)).await;
                        }
                        failed = true;
                        break;
                    }
                }
            }
            
            if !failed {
                return;  // Stream completed successfully
            }
        }
    }
}
#+end_src

* Concurrent Operations

This section covers operations that work with multiple streams concurrently.
These require internal helpers that use =Promise.race= to handle multiple async iterators simultaneously.

** Concurrency Helpers

The key insight is that while =for await...of= is sequential, we can race multiple =.next()= calls concurrently:

#+begin_src text :tangle no
Sequential (for await):       Concurrent (Promise.race):
                              
  iter.next()                   Promise.race([
      │                           iterA.next(),
      ▼                           iterB.next(),
  iter.next()                     iterC.next()
      │                         ])
      ▼                             │
  iter.next()                       ▼
      │                         Winner emits first
      ▼
  ...waits for each             Re-queue winner, race again
#+end_src

*** =raceIterators=

The =raceIterators= function races multiple async iterators, yielding values tagged with their source index as they arrive.
This is the core building block for merge, latest, and other concurrent operations.

**** Algorithm

1. *Initialize*: For each iterator, call =.next()= and store the pending promise in a Map keyed by index
2. *Race*: Use =Promise.race= to await whichever promise resolves first
3. *Handle result*:
   - If =done=: Remove that iterator from the pending map
   - If value: Yield ={index, value}=, then re-queue a new =.next()= promise for that iterator
4. *Repeat* until all iterators are exhausted (pending map is empty)

#+begin_src typescript :tangle index.ts

type TaggedResult<T> = { index: number; value: T }

/**
 * Races multiple async iterators, yielding values tagged with their source index.
 * Values are emitted as soon as any iterator produces one.
 */
async function* raceIterators<T>(
  iterators: AsyncIterator<T>[]
): AsyncGenerator<TaggedResult<T>, void, void> {
  const pending = new Map<number, Promise<{ index: number; result: IteratorResult<T> }>>()

  // Start all iterators
  for (let i = 0; i < iterators.length; i++)
    pending.set(i, iterators[i].next().then(result => ({ index: i, result })))

  while (pending.size > 0) {
    const { index, result } = await Promise.race(pending.values())

    if (result.done) pending.delete(index)
    else {
      yield { index, value: result.value }
      pending.set(index, iterators[index].next().then(result => ({ index, result })))
    }
  }
}

#+end_src

*** =raceIteratorsWithOuter=

The =raceIteratorsWithOuter= function extends =raceIterators= to also race against an outer stream that can add new iterators dynamically.
This is used for =mergeAll= and =chain= where inner streams are created as the outer stream emits.

#+begin_src typescript :tangle index.ts

type RaceResult<T, O> =
  | { type: 'inner'; index: number; value: T }
  | { type: 'outer'; value: O }
  | { type: 'outerDone' }

/**
 * Races inner iterators against an outer stream that produces new iterables.
 * Useful for mergeAll/chain where we need to race existing inner streams
 * while also listening for new streams from the outer source.
 */
async function* raceIteratorsWithOuter<T, O>(
  outerIterator: AsyncIterator<O>,
  getInnerIterator: (value: O) => AsyncIterator<T>
): AsyncGenerator<RaceResult<T, O>, void, void> {
  const innerIterators: AsyncIterator<T>[] = []
  const pending = new Map<number | 'outer', Promise<{ key: number | 'outer'; result: IteratorResult<any> }>>()

  // Start listening to outer
  pending.set('outer', outerIterator.next().then(result => ({ key: 'outer' as const, result })))

  while (pending.size > 0) {
    const { key, result } = await Promise.race(pending.values())

    if (key === 'outer') {
      if (result.done) {
        pending.delete('outer')
        yield { type: 'outerDone' }
      } else {
        yield { type: 'outer', value: result.value }
        // Add new inner iterator
        const innerIndex = innerIterators.length
        const innerIterator = getInnerIterator(result.value)
        innerIterators.push(innerIterator)
        pending.set(innerIndex, innerIterator.next().then(result => ({ key: innerIndex, result })))
        // Continue listening to outer
        pending.set('outer', outerIterator.next().then(result => ({ key: 'outer' as const, result })))
      }
    } else {
      // Inner iterator result
      const index = key as number
      if (result.done) pending.delete(index)
      else {
        yield { type: 'inner', index, value: result.value }
        pending.set(index, innerIterators[index].next().then(result => ({ key: index, result })))
      }
    }
  }
}

#+end_src

** =merge=

The =merge= function merges multiple streams into a single stream, emitting values from any stream as they arrive.

#+begin_src typescript :tangle index.ts

/**
 * Merges multiple streams into a single stream, emitting values as they arrive.
 */
export async function* merge<T>(
  ...streams: AsyncIterable<T>[]
): AsyncGenerator<T, void, void> {
  const iterators = streams.map(s => s[Symbol.asyncIterator]())
  for await (const { value } of raceIterators(iterators)) yield value
}

#+end_src

*** When to Use

Use =merge= to combine multiple streams into one, emitting values from any source as they arrive. Order depends on timing, not input order. All sources run concurrently.

#+begin_src text :tangle no
stream A:      --1-----3-----5--|
stream B:      ----2-----4-----|
merge(A, B):   --1-2---3-4---5--|
                 ^ ^   ^ ^
                 interleaved by arrival time
#+end_src

#+begin_src javascript :tangle no
// Combine multiple event sources
const allClicks = merge(
  fromEvent(button1, 'click'),
  fromEvent(button2, 'click'),
  fromEvent(button3, 'click')
)

// Poll multiple APIs simultaneously
const allData = merge(
  pollApi('/api/users'),
  pollApi('/api/orders'),
  pollApi('/api/inventory')
)

// First-wins pattern
const fastest = pipe(
  merge(
    fromPromise(fetchFromCdn()),
    fromPromise(fetchFromOrigin())
  ),
  take(1)
)

// Combine user actions with system events
const allEvents = merge(
  userActions,
  systemNotifications,
  timerTicks
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('merge', () => {
  it('merges multiple streams', async () => {
    const a = createAsyncIterable([1, 3], { delay: 20 })
    const b = createAsyncIterable([2, 4], { delay: 20, initialDelay: 10 })
    const result = await collect(merge(a, b))
    expect(result).toEqual([1, 2, 3, 4])
  })
})
#+end_src

*** Rust Implementation

=futures::stream::select= and =futures::stream::select_all= provide merge functionality:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt, stream};

// For two streams:
// stream::select(stream_a, stream_b)

// For multiple streams:
// stream::select_all(vec![stream_a, stream_b, stream_c].into_iter())

// Custom implementation with tokio::select!:
use async_stream::stream;
use futures::future::FusedFuture;
use std::pin::Pin;

pub fn merge<T, S1: Stream<Item = T> + Unpin, S2: Stream<Item = T> + Unpin>(
    mut s1: S1,
    mut s2: S2,
) -> impl Stream<Item = T> {
    stream! {
        loop {
            tokio::select! {
                biased;
                item = s1.next() => {
                    match item {
                        Some(v) => yield v,
                        None => {
                            // s1 done, drain s2
                            while let Some(v) = s2.next().await {
                                yield v;
                            }
                            break;
                        }
                    }
                }
                item = s2.next() => {
                    match item {
                        Some(v) => yield v,
                        None => {
                            // s2 done, drain s1
                            while let Some(v) = s1.next().await {
                                yield v;
                            }
                            break;
                        }
                    }
                }
            }
        }
    }
}
#+end_src

** =mergeAll=

The =mergeAll= function flattens a stream of streams by merging them into a single stream.

#+begin_src typescript :tangle index.ts
/**
 * Flattens a stream of streams by merging them into a single stream.
 */
export async function* mergeAll<T>(
  streamOfStreams: AsyncIterable<AsyncIterable<T>>,
): AsyncGenerator<T, void, void> {
  const outerIterator = streamOfStreams[Symbol.asyncIterator]()
  for await (const result of raceIteratorsWithOuter(outerIterator, s => s[Symbol.asyncIterator]()))
    if (result.type === 'inner') yield result.value
}
#+end_src

*** When to Use

Use =mergeAll= to flatten a stream of streams concurrently. Unlike =concatAll= (which waits for each inner to complete), =mergeAll= runs all inner streams simultaneously.

#+begin_src text :tangle no
outer:        --[A]-----[B]------|
A:               1--2--3|
B:                       4--5|
mergeAll:     ---1--2--3-4--5---|
                 ^       ^
                 A and B values interleaved
                 (A starts first, B joins while A active)
#+end_src

#+begin_src javascript :tangle no
// Fetch all URLs concurrently
const allResponses = pipe(
  from(urls),
  map(url => fromPromise(fetch(url))),
  mergeAll  // All fetches run in parallel
)

// Process queue items concurrently
const results = pipe(
  jobQueue,
  map(job => processJob(job)),
  mergeAll
)

// Flatten nested data with concurrency
const allItems = pipe(
  categories,
  map(cat => from(cat.items)),
  mergeAll
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('mergeAll', () => {
  it('flattens stream of streams concurrently', async () => {
    const streams = from([from([1, 2]), from([3, 4])])
    const values = await collect(mergeAll(streams))
    // Order may vary, but all values should be present
    expect(values.sort()).toEqual([1, 2, 3, 4])
  })

  it('handles empty outer stream', async () => {
    const values = await collect(mergeAll(empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::flatten_unordered= provides concurrent flattening:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: outer.flatten_unordered(None) // None = unlimited concurrency
// Or: outer.flatten_unordered(Some(10))  // limit to 10 concurrent streams

// Custom implementation using FuturesUnordered:
use async_stream::stream;
use futures::stream::FuturesUnordered;
use std::sync::Arc;
use tokio::sync::Mutex;

pub fn merge_all<T, Inner, Outer>(outer: Outer) -> impl Stream<Item = T>
where
    Inner: Stream<Item = T> + Unpin + Send + 'static,
    Outer: Stream<Item = Inner> + Unpin,
    T: Send + 'static,
{
    // For production, use flatten_unordered from futures
    outer.flatten_unordered(None)
}
#+end_src

** =chain= / =flatMap=

The =chain= function (also exported as =flatMap=) maps each value from the source stream to a new stream and flattens the resulting streams into a single stream.
You can think of it as a combination of a =map= producing streams being run through =mergeAll=.

Note, that it doesn't concatenate the inner streams, but interleaves them as values become available.

#+begin_src text :tangle no
stream:            -a----b----c|
f(a):               1--2--3|
f(b):                    1----2----3|
f(c):                           1-2-3|
stream.chain(f):   -1--2-13---2-1-233|
#+end_src

#+begin_src typescript :tangle index.ts
/**
 * Maps each value from the source stream to a new stream and flattens the resulting streams into a single stream.
 */
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => chain(fn, s);
  return (async function* () {
    const outerIterator = stream[Symbol.asyncIterator]()
    for await (const result of raceIteratorsWithOuter(outerIterator, v => fn(v)[Symbol.asyncIterator]())) {
      if (result.type === 'inner') yield result.value
    }
  })();
}

export const flatMap = chain

#+end_src

*** When to Use

Use =chain= (or its alias =flatMap=) when each input produces multiple async outputs that should all run concurrently.
This is the go-to operator for =for each X, do Y and flatten results=.


#+begin_src javascript :tangle no
// Fetch related data for each user
const userPosts = pipe(
  userIds,
  chain(id => fromPromise(fetchUserPosts(id)))
)

// Parallel file processing
const allLines = pipe(
  filePaths,
  chain(path => readFileLines(path))
)

// Expand and process concurrently
const processedItems = pipe(
  categories,
  chain(cat => pipe(
    from(cat.items),
    map(processItem)
  ))
)

// Retry pattern using chain
const withRetries = pipe(
  requests,
  chain(req => pipe(
    from([1, 2, 3]),  // 3 attempts
    concatMap(() => pipe(
      fromPromise(tryRequest(req)),
      recoverWith(() => empty())
    )),
    take(1)
  ))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('chain / flatMap', () => {
  it('maps and merges inner streams', async () => {
    const values = await collect(chain(
      x => from([x, x * 10]),
      from([1, 2])
    ))
    // All values present, order may vary due to merging
    expect(values.sort((a, b) => a - b)).toEqual([1, 2, 10, 20])
  })

  it('flatMap is an alias for chain', () => {
    expect(flatMap).toBe(chain)
  })
})
#+end_src

*** Rust Implementation

=StreamExt::flat_map_unordered= provides concurrent flatMap:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in concurrent flatMap:
// stream.flat_map_unordered(None, |item| create_inner_stream(item))

// For sequential flatMap (like concatMap), use flat_map:
// stream.flat_map(|item| create_inner_stream(item))

// Custom implementation:
use async_stream::stream;

pub fn flat_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
    S: Stream<Item = T>,
    Inner: Stream<Item = U> + Unpin + Send + 'static,
    F: Fn(T) -> Inner,
    U: Send + 'static,
{
    s.map(f).flatten_unordered(None)
}

// Alias
pub fn chain<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
    S: Stream<Item = T>,
    Inner: Stream<Item = U> + Unpin + Send + 'static,
    F: Fn(T) -> Inner,
    U: Send + 'static,
{
    flat_map(f, s)
}
#+end_src

** =switchMap=

The =switchMap= operator is like =chain=, but cancels the previous inner stream whenever a new outer value arrives.
This is useful for scenarios like autocomplete, where you only care about the result from the latest query.

#+begin_src text :tangle no
stream:            -a------b------c|
f(a):               1--2--3--4--5|     (cancelled at b)
f(b):                      1--2|       (cancelled at c)
f(c):                             1-2-3|
stream.switchMap:  -1--2---1--2---1-2-3|
#+end_src

#+begin_src typescript :tangle index.ts

/**
 * Maps each value to a new stream, cancelling the previous inner stream when a new value arrives.
 * Only values from the most recent inner stream are emitted.
 * 
 * Useful for scenarios like autocomplete where only the latest request matters.
 */
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => switchMap(fn, s);
  return (async function* () {
    const outerIterator = stream[Symbol.asyncIterator]()
    let currentInnerIterator: AsyncIterator<U> | null = null
    let outerDone = false
    
    type PendingResult = 
      | { type: 'outer'; result: IteratorResult<T> }
      | { type: 'inner'; result: IteratorResult<U> }

    const pending = new Map<'outer' | 'inner', Promise<PendingResult>>()

    // Start listening to outer
    pending.set('outer', outerIterator.next().then(result => ({ type: 'outer' as const, result })))

    while (pending.size > 0) {
      const winner = await Promise.race(pending.values())

      if (winner.type === 'outer') {
        if (winner.result.done) {
          outerDone = true
          pending.delete('outer')
          // Continue processing current inner stream if any
        } else {
          // Cancel current inner stream (by removing from pending and not calling return)
          pending.delete('inner')
          // Start new inner stream
          currentInnerIterator = fn(winner.result.value)[Symbol.asyncIterator]()
          pending.set('inner', currentInnerIterator.next().then(result => ({ type: 'inner' as const, result })))
          // Continue listening to outer
          pending.set('outer', outerIterator.next().then(result => ({ type: 'outer' as const, result })))
        }
      } else {
        // Inner result
        if (winner.result.done) {
          pending.delete('inner')
          currentInnerIterator = null
          // If outer is also done, we're finished
        } else {
          yield winner.result.value
          // Continue listening to current inner
          pending.set('inner', currentInnerIterator!.next().then(result => ({ type: 'inner' as const, result })))
        }
      }
    }
  })();
}

#+end_src

*** When to Use

Use =switchMap= when only the latest request matters and previous in-flight operations should be abandoned. The classic example is search autocomplete.

#+begin_src javascript :tangle no
// Search autocomplete (cancel stale searches)
const searchResults = pipe(
  fromEvent(searchInput, 'input'),
  debounce(300),
  map(e => e.target.value),
  switchMap(query => 
    query.length < 2 
      ? just([])
      : fromPromise(searchApi(query))
  )
)

// Tab content loading (cancel previous tab's fetch)
const tabContent = pipe(
  selectedTab,
  switchMap(tabId => fromPromise(fetchTabContent(tabId)))
)

// Live data that should always be fresh
const liveData = pipe(
  refreshTrigger,
  switchMap(() => fromPromise(fetchLatestData()))
)

// Form validation (cancel validation on new input)
const validationResult = pipe(
  formValue,
  debounce(200),
  switchMap(value => fromPromise(validateOnServer(value)))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('switchMap', () => {
  it('cancels previous inner stream on new outer value', async () => {
    // Fast outer, slow inner - should cancel early inner streams
    const outer = createAsyncIterable([1, 2, 3], { delay: 10 })
    const values = await collect(switchMap(
      x => createAsyncIterable([x * 10, x * 100], { delay: 30 }),
      outer
    ))
    // Only values from the last inner stream should complete
    expect(values).toContain(30)
    expect(values).toContain(300)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(
      from([1]),
      switchMap(x => from([x, x * 2]))
    ))
    expect(values).toEqual([1, 2])
  })

  it('completes when outer and inner complete', async () => {
    const values = await collect(switchMap(
      x => from([x]),
      from([1, 2, 3])
    ))
    expect(values.length).toBeGreaterThan(0)
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::sync::mpsc;

/// Switch to new inner stream on each outer value, cancelling previous.
pub fn switch_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
    S: Stream<Item = T> + Unpin,
    Inner: Stream<Item = U> + Unpin,
    F: Fn(T) -> Inner,
{
    stream! {
        tokio::pin!(s);
        let mut current_inner: Option<std::pin::Pin<Box<dyn Stream<Item = U> + Unpin>>> = None;

        loop {
            tokio::select! {
                biased;

                // Check outer stream first (higher priority for switching)
                outer_item = s.next() => {
                    match outer_item {
                        Some(item) => {
                            // Cancel old inner by dropping, start new one
                            current_inner = Some(Box::pin(f(item)));
                        }
                        None => {
                            // Outer done, drain current inner
                            if let Some(ref mut inner) = current_inner {
                                while let Some(v) = inner.next().await {
                                    yield v;
                                }
                            }
                            break;
                        }
                    }
                }

                // Process current inner
                inner_item = async {
                    if let Some(ref mut inner) = current_inner {
                        inner.next().await
                    } else {
                        std::future::pending().await
                    }
                } => {
                    match inner_item {
                        Some(v) => yield v,
                        None => current_inner = None,
                    }
                }
            }
        }
    }
}
#+end_src

** =latest=

The =latest= function combines multiple streams into a single stream that emits a tuple of the latest values from each input stream whenever any of them emit a new value.

We use a mapped tuple type to preserve the individual types of each stream in the output tuple.

#+begin_src typescript :tangle index.ts
/**
 * Extracts the element type from an AsyncIterable.
 */
type AsyncIterableValue<T> = T extends AsyncIterable<infer U> ? U : never

/**
 * Maps a tuple of AsyncIterables to a tuple of their element types.
 */
type LatestValues<T extends readonly AsyncIterable<any>[]> = {
  [K in keyof T]: AsyncIterableValue<T[K]>
}

/**
 * Combines multiple streams into a single stream that emits a tuple of the latest values
 * from each input stream whenever any of them emit a new value.
 * 
 * Type-safe: preserves individual stream types in the output tuple.
 */
export async function* latest<T extends readonly AsyncIterable<any>[]>(
  streams: [...T],
): AsyncGenerator<LatestValues<T>, void, void> {
  const iterators = streams.map(s => s[Symbol.asyncIterator]())
  const latestValues: any[] = new Array(streams.length)
  const hasValue: boolean[] = new Array(streams.length).fill(false)
  let hasAllValues = false

  for await (const { index, value } of raceIterators(iterators)) {
    latestValues[index] = value
    hasValue[index] = true
    if (!hasAllValues) hasAllValues = hasValue.every(Boolean)
    if (hasAllValues) yield [...latestValues] as LatestValues<T>
  }
}
#+end_src

*** When to Use

Use =latest= to combine multiple streams where you need the current value from each. Emits only after all streams have produced at least one value, then on every subsequent emission from any stream.

#+begin_src text :tangle no
stream A:      --1-----3---------5--|
stream B:      ----a-------b--------|
latest([A,B]): ----[1,a]-[3,a]-[3,b]-[5,b]|
               ^^^^^^^^^^
               waits for both, then emits on any change
#+end_src

#+begin_src javascript :tangle no
// Combine width and height for calculations
const dimensions = pipe(
  latest([widthStream, heightStream]),
  map(([w, h]) => ({ width: w, height: h, area: w * h }))
)

// React to changes in any of multiple inputs
const formState = pipe(
  latest([nameField, emailField, passwordField]),
  map(([name, email, password]) => ({ name, email, password }))
)

// Price calculator with live updates
const totalPrice = pipe(
  latest([quantityStream, unitPriceStream, discountStream]),
  map(([qty, price, discount]) => qty * price * (1 - discount))
)

// Synchronized state from multiple sources
const dashboardState = pipe(
  latest([userStream, settingsStream, dataStream]),
  map(([user, settings, data]) => ({ user, settings, data }))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('latest', () => {
  it('emits tuple of latest values after all streams have emitted', async () => {
    const a = from([1, 2])
    const b = from(['x', 'y'])
    const values = await collect(latest([a, b]))
    // After both emit, we should get tuples
    expect(values.length).toBeGreaterThan(0)
    // Each tuple should have a number and string
    values.forEach(([n, s]) => {
      expect(typeof n).toBe('number')
      expect(typeof s).toBe('string')
    })
  })
})
#+end_src

*** Rust Implementation

=tokio_stream::StreamExt::merge= with state tracking or =futures::stream::SelectAll= patterns:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Combine two streams, emitting tuple of latest values.
pub fn latest2<T: Clone, U: Clone, S1: Stream<Item = T> + Unpin, S2: Stream<Item = U> + Unpin>(
    mut s1: S1,
    mut s2: S2,
) -> impl Stream<Item = (T, U)> {
    stream! {
        let mut latest1: Option<T> = None;
        let mut latest2: Option<U> = None;

        loop {
            tokio::select! {
                biased;

                item = s1.next() => {
                    match item {
                        Some(v) => {
                            latest1 = Some(v);
                            if let (Some(ref a), Some(ref b)) = (&latest1, &latest2) {
                                yield (a.clone(), b.clone());
                            }
                        }
                        None => break,
                    }
                }
                item = s2.next() => {
                    match item {
                        Some(v) => {
                            latest2 = Some(v);
                            if let (Some(ref a), Some(ref b)) = (&latest1, &latest2) {
                                yield (a.clone(), b.clone());
                            }
                        }
                        None => break,
                    }
                }
            }
        }
    }
}
#+end_src

** =applyLatest=

The =applyLatest= function applies the latest function from a stream of functions to the latest value from a stream of values.

#+begin_src typescript :tangle index.ts

/**
 * Applies the latest function from a stream of functions to the latest value from a stream of values.
 */
export async function* applyLatest<T, U>(
  fnStream: AsyncIterable<(value: T) => U>,
  valueStream: AsyncIterable<T>,
): AsyncGenerator<U, void, void> {
  yield* map(
    ([fn, value]) => fn(value),
    latest([fnStream, valueStream]),
  );
}

#+end_src

*** When to Use

Use =applyLatest= for applicative-style stream composition where you have a stream of functions and a stream of values. Each time either changes, apply the current function to the current value.

#+begin_src text :tangle no
functions:     f----g---------|
values:        --1----2-------|
applyLatest:   --f(1)-g(1)g(2)|
#+end_src

#+begin_src javascript :tangle no
// Dynamic formatting based on locale
const formattedPrices = applyLatest(
  pipe(localeStream, map(locale => price => formatPrice(price, locale))),
  priceStream
)

// Apply current validation rules to form value
const validationResults = applyLatest(
  validationRulesStream,  // Stream of validator functions
  formValueStream
)

// Dynamic sorting
const sortedItems = applyLatest(
  pipe(sortConfigStream, map(config => items => sortItems(items, config))),
  itemsStream
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('applyLatest', () => {
  it('applies latest function to latest value', async () => {
    const fns = from([(x: number) => x * 2, (x: number) => x * 3])
    const vals = from([10, 20])
    const values = await collect(applyLatest(fns, vals))
    expect(values.length).toBeGreaterThan(0)
    // Results should be numbers
    values.forEach(v => expect(typeof v).toBe('number'))
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

/// Apply latest function to latest value.
pub fn apply_latest<T, U, F, S1, S2>(fn_stream: S1, value_stream: S2) -> impl Stream<Item = U>
where
    S1: Stream<Item = F> + Unpin,
    S2: Stream<Item = T> + Unpin,
    F: Fn(T) -> U + Clone,
    T: Clone,
{
    latest2(fn_stream, value_stream).map(|(f, v)| f(v))
}
#+end_src

** =untilStream=

The =untilStream= function creates a stream that emits values from the source stream until another stream emits a value, at which point it stops emitting values.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that emits values from the source stream until another stream emits a value.
 */
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>
): (sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>,
  sourceStream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>,
  sourceStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (sourceStream === undefined) return (s: AsyncIterable<T>) => untilStream(stopStream, s);
  return (async function* () {
    const sourceIterator = sourceStream[Symbol.asyncIterator]()
    const stopIterator = stopStream[Symbol.asyncIterator]()
    const iterators: AsyncIterator<T | S>[] = [sourceIterator, stopIterator]

    for await (const { index, value } of raceIterators(iterators)) {
      if (index === 1) break // stopStream emitted
      yield value as T
    }
  })();
}

#+end_src

*** When to Use

Use =untilStream= to stop a stream when an external signal arrives. The source continues until the stop stream emits its first value.

#+begin_src text :tangle no
source:          --1--2--3--4--5--6--|
stop:            -----------X--------|
untilStream:     --1--2--3--|         
                           ^
                           stops when stop emits
#+end_src

#+begin_src javascript :tangle no
// Stop polling when user logs out
const data = pipe(
  periodic(5000),
  chain(() => fetchData()),
  untilStream(logoutEvent)
)

// Process until cancel button clicked
const processing = pipe(
  workItems,
  map(processItem),
  untilStream(fromEvent(cancelButton, 'click'))
)

// Stop after timeout
const withTimeout = pipe(
  longRunningStream,
  untilStream(fromPromise(sleep(30000)))
)

// Component lifecycle: stop when unmounted
const subscription = pipe(
  dataUpdates,
  untilStream(componentDestroyed$)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('untilStream', () => {
  it('stops when stop stream emits', async () => {
    // Source emits forever, stop after 3 items
    const source = pipe(iterate(1, x => x + 1), take(10))
    const stop = pipe(from([1, 2, 3]), skip(2)) // emits on 3rd
    // This test is tricky with sync streams - use take to limit
    const values = await collect(pipe(untilStream(stop, from([1, 2, 3, 4, 5])), take(5)))
    expect(values.length).toBeLessThanOrEqual(5)
  })
})
#+end_src

*** Rust Implementation

=StreamExt::take_until= provides this functionality:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Emit from source until stop stream emits.
pub fn until_stream<T, U, S: Stream<Item = T> + Unpin, Stop: Stream<Item = U> + Unpin>(
    mut stop: Stop,
    mut source: S,
) -> impl Stream<Item = T> {
    stream! {
        loop {
            tokio::select! {
                biased;

                _ = stop.next() => break,
                item = source.next() => {
                    match item {
                        Some(v) => yield v,
                        None => break,
                    }
                }
            }
        }
    }
}

// Or use built-in:
// use tokio_stream::StreamExt;
// source.take_until(stop.next())
#+end_src

** =sinceStream=

The =sinceStream= function creates a stream that starts emitting values from the source stream only after another stream emits a value.

#+begin_src typescript :tangle index.ts

/**
 * Creates a stream that starts emitting values from the source stream only after another stream emits a value.
 */
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>
): (sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>,
  sourceStream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>,
  sourceStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (sourceStream === undefined) return (s: AsyncIterable<T>) => sinceStream(startStream, s);
  return (async function* () {
    const sourceIterator = sourceStream[Symbol.asyncIterator]()
    const startIterator = startStream[Symbol.asyncIterator]()
    const iterators: AsyncIterator<T | S>[] = [sourceIterator, startIterator]
    let started = false

    for await (const { index, value } of raceIterators(iterators)) {
      if (index === 1) {
        started = true
        continue
      }
      if (started) yield value as T
    }
  })();
}

#+end_src

*** When to Use

Use =sinceStream= to gate a stream until an external signal arrives. Values before the signal are dropped.

#+begin_src text :tangle no
source:          --1--2--3--4--5--6--|
start:           -------X------------|
sinceStream:     ---------4--5--6---|  
                    ^
                    values before start are dropped
#+end_src

#+begin_src javascript :tangle no
// Start processing after initialization
const mainLoop = pipe(
  events,
  sinceStream(appInitialized)
)

// Wait for user permission before tracking
const tracking = pipe(
  userActions,
  sinceStream(consentGiven)
)

// Ignore events until animation completes
const afterAnimation = pipe(
  clickEvents,
  sinceStream(animationComplete)
)

// Begin recording after start signal
const recording = pipe(
  audioSamples,
  sinceStream(fromEvent(startButton, 'click'))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('sinceStream', () => {
  it('emits only after start stream emits', async () => {
    // With sync streams, behavior depends on interleaving
    const start = just('go')
    const source = from([1, 2, 3, 4, 5])
    const values = await collect(sinceStream(start, source))
    // Should emit some subset after start signal
    expect(Array.isArray(values)).toBe(true)
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};

/// Emit from source only after start stream emits.
pub fn since_stream<T, U, S: Stream<Item = T> + Unpin, Start: Stream<Item = U> + Unpin>(
    mut start: Start,
    mut source: S,
) -> impl Stream<Item = T> {
    stream! {
        let mut started = false;

        loop {
            tokio::select! {
                biased;

                _ = async {
                    if !started {
                        start.next().await
                    } else {
                        std::future::pending().await
                    }
                } => {
                    started = true;
                }

                item = source.next() => {
                    match item {
                        Some(v) if started => yield v,
                        Some(_) => {}  // Drop values before start
                        None => break,
                    }
                }
            }
        }
    }
}
#+end_src

* Buffering

These operators collect values into buffers before emitting them downstream.

** =buffer=

The =buffer= operator collects values from the source stream into arrays of a specified size,
emitting each buffer when it's full.

#+begin_src typescript :tangle index.ts

/**
 * Collects values into arrays of the specified size, emitting each buffer when full.
 * The final buffer may be smaller if the source completes.
 */
export function buffer<T>(
  size: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>;
export function buffer<T>(
  size: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T[], void, void>;
export function buffer<T>(
  size: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T[], void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => buffer(size, s);
  return (async function* () {
    let buf: T[] = []
    for await (const item of stream) {
      buf.push(item)
      if (buf.length >= size) {
        yield buf
        buf = []
      }
    }
    if (buf.length > 0) yield buf
  })();
}

#+end_src

*** When to Use

Use =buffer= to batch items for bulk processing. Reduces number of operations when handling many small items.

#+begin_src text :tangle no
stream:       --1--2--3--4--5--|
buffer(2):    -----[1,2]--[3,4]--[5]|
                   ^       ^      ^
                   batch   batch  partial
#+end_src

#+begin_src javascript :tangle no
// Batch API writes
const batchWrites = pipe(
  dataStream,
  buffer(100),  // Write in batches of 100
  awaitTap(batch => db.insertMany(batch))
)

// Process chunks for display
const tableRows = pipe(
  allRecords,
  buffer(50),  // Display 50 rows at a time
  map(batch => renderRows(batch))
)

// Reduce network overhead
const batchedEvents = pipe(
  analytics,
  buffer(10),
  tap(batch => sendToServer(batch))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('buffer', () => {
  it('collects values into fixed-size arrays', async () => {
    const values = await collect(buffer(2, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([[1, 2], [3, 4], [5]])
  })

  it('emits partial buffer at end', async () => {
    const values = await collect(buffer(3, from([1, 2])))
    expect(values).toEqual([[1, 2]])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3, 4]), buffer(2)))
    expect(values).toEqual([[1, 2], [3, 4]])
  })
})
#+end_src

*** Rust Implementation

=StreamExt::chunks= provides batching:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};

// Built-in: stream.chunks(size)

// Custom implementation:
use async_stream::stream;

pub fn buffer<T, S: Stream<Item = T>>(size: usize, s: S) -> impl Stream<Item = Vec<T>> {
    stream! {
        tokio::pin!(s);
        let mut buf: Vec<T> = Vec::with_capacity(size);
        while let Some(item) = s.next().await {
            buf.push(item);
            if buf.len() >= size {
                yield std::mem::replace(&mut buf, Vec::with_capacity(size));
            }
        }
        if !buf.is_empty() {
            yield buf;
        }
    }
}
#+end_src

** =bufferTime=

The =bufferTime= operator collects values over a time window, emitting the buffer when the window closes.

#+begin_src typescript :tangle index.ts

/**
 * Collects values over a time window, emitting the buffer when the window closes.
 * Continues creating new windows until the source completes.
 */
export function bufferTime<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>;
export function bufferTime<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T[], void, void>;
export function bufferTime<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T[], void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => bufferTime(ms, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let currentBuffer: T[] = []
    let done = false
    let bufferResolve: (() => void) | null = null

    // Timer that fires to emit buffer
    const startTimer = () => {
      return new Promise<'timer'>(resolve => {
        setTimeout(() => resolve('timer'), ms)
      })
    }

    // Source consumer
    const getNext = async (): Promise<{ done: true } | { done: false; value: T }> => {
      const result = await iterator.next()
      return result.done ? { done: true } : { done: false, value: result.value }
    }

    let timerPromise = startTimer()
    let nextPromise = getNext()

    while (!done) {
      const result = await Promise.race([timerPromise, nextPromise])

      if (result === 'timer') {
        // Timer fired - emit buffer and restart timer
        if (currentBuffer.length > 0) {
          yield currentBuffer
          currentBuffer = []
        }
        timerPromise = startTimer()
      } else if (result.done) {
        // Source completed
        done = true
        if (currentBuffer.length > 0) {
          yield currentBuffer
        }
      } else {
        // Got a value
        currentBuffer.push(result.value)
        nextPromise = getNext()
      }
    }
  })();
}

#+end_src

*** When to Use

Use =bufferTime= when you want to batch items by time rather than count. Useful for rate-limiting or collecting events over a time window.

#+begin_src text :tangle no
time:           0   100  200  300  400
stream:         -1-2--3--4-5---6------|\nbufferTime(200):[1,2,3]--[4,5,6]------|\n                ^        ^\n                window   window\n#+end_src

#+begin_src javascript :tangle no
// Batch analytics events every 5 seconds
const analyticsBuffer = pipe(
  userEvents,
  bufferTime(5000),
  filter(batch => batch.length > 0),
  tap(batch => sendAnalytics(batch))
)

// Aggregate log entries
const logBatches = pipe(
  logStream,
  bufferTime(1000),
  map(logs => logs.join('\\n'))
)

// Rate-limited updates to UI
const throttledUpdates = pipe(
  rapidChanges,
  bufferTime(100),
  map(changes => changes.at(-1)),  // Take latest in window
  filter(Boolean)
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('bufferTime', () => {
  it('collects values over time window', async () => {
    const stream = createAsyncIterable([1, 2, 3, 4], { delay: 15 })
    const values = await collect(bufferTime(35, stream))
    // With 15ms delay between items and 35ms window:
    // Window 1 (0-35ms): 1, 2
    // Window 2 (35-70ms): 3, 4
    expect(values.length).toBeGreaterThanOrEqual(1)
    expect(values.flat()).toEqual([1, 2, 3, 4])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2]), bufferTime(50)))
    expect(values.flat()).toEqual([1, 2])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::time::{interval, Duration, Instant};

/// Buffer values over time windows.
pub fn buffer_time<T, S: Stream<Item = T> + Unpin>(ms: u64, mut s: S) -> impl Stream<Item = Vec<T>> {
    stream! {
        let duration = Duration::from_millis(ms);
        let mut buf: Vec<T> = Vec::new();
        let mut timer = Box::pin(tokio::time::sleep(duration));

        loop {
            tokio::select! {
                biased;

                _ = &mut timer => {
                    if !buf.is_empty() {
                        yield std::mem::take(&mut buf);
                    }
                    timer = Box::pin(tokio::time::sleep(duration));
                }
                item = s.next() => {
                    match item {
                        Some(v) => buf.push(v),
                        None => {
                            if !buf.is_empty() {
                                yield buf;
                            }
                            break;
                        }
                    }
                }
            }
        }
    }
}
#+end_src

** =window=

The =window= operator is like =buffer=, but emits streams instead of arrays.
Each window is a separate async iterable that emits values as they arrive.

#+begin_src typescript :tangle index.ts

/**
 * Splits the source into windows of the specified size.
 * Each window is emitted as a separate async iterable.
 */
export function window<T>(
  size: number
): (stream: AsyncIterable<T>) => AsyncGenerator<AsyncIterable<T>, void, void>;
export function window<T>(
  size: number,
  stream: AsyncIterable<T>
): AsyncGenerator<AsyncIterable<T>, void, void>;
export function window<T>(
  size: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<AsyncIterable<T>, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<AsyncIterable<T>, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => window(size, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let done = false

    while (!done) {
      let count = 0
      const windowValues: T[] = []
      let windowDone = false
      let windowResolve: ((result: IteratorResult<T>) => void) | null = null

      // Create a window stream
      const windowStream: AsyncIterable<T> = {
        [Symbol.asyncIterator]() {
          let index = 0
          return {
            async next(): Promise<IteratorResult<T>> {
              if (index < windowValues.length) {
                return { value: windowValues[index++], done: false }
              }
              if (windowDone) {
                return { value: undefined as any, done: true }
              }
              return new Promise(resolve => {
                windowResolve = resolve
              })
            }
          }
        }
      }

      // Yield the window stream
      yield windowStream

      // Fill the window
      while (count < size && !done) {
        const result = await iterator.next()
        if (result.done) {
          done = true
          windowDone = true
          if (windowResolve) {
            const resolver: (result: IteratorResult<T>) => void = windowResolve
            resolver({ value: undefined as any, done: true })
          }
        } else {
          windowValues.push(result.value)
          count++
          if (windowResolve) {
            const resolver: (result: IteratorResult<T>) => void = windowResolve
            windowResolve = null
            resolver({ value: result.value, done: false })
          }
        }
      }
      windowDone = true
      if (windowResolve) {
        const resolver: (result: IteratorResult<T>) => void = windowResolve
        resolver({ value: undefined as any, done: true })
      }
    }
  })();
}

#+end_src

*** When to Use

Use =window= when you need streaming access to batches (rather than waiting for the full batch like =buffer=). Each window is itself a stream that can be processed incrementally.

#+begin_src text :tangle no
stream:       --1--2--3--4--5--|
window(2):    --[S1]----[S2]----[S3]|
              S1: 1-2|
              S2: 3-4|
              S3: 5|
#+end_src

#+begin_src javascript :tangle no
// Process large files in chunks without loading full chunk
const chunkedProcessing = pipe(
  largeFileStream,
  window(1000),
  concatMap(async windowStream => {
    let sum = 0
    for await (const line of windowStream) {
      sum += parseLine(line).value
    }
    return sum
  })
)

// Stream processing with per-window aggregation
const windowAggregates = pipe(
  dataPoints,
  window(100),
  chain(async window => {
    const values = await collect(window)
    return just({ avg: average(values), count: values.length })
  })
)

// Different processing per window
const windowed = pipe(
  events,
  window(50),
  map(w => processWindow(w))
)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('window', () => {
  it('splits stream into window streams', async () => {
    const windows = await collect(window(2, from([1, 2, 3, 4, 5])))
    expect(windows.length).toBe(3)
    
    const values = await Promise.all(windows.map(w => collect(w)))
    expect(values).toEqual([[1, 2], [3, 4], [5]])
  })

  it('supports curried form', async () => {
    const windows = await collect(pipe(from([1, 2, 3]), window(2)))
    expect(windows.length).toBe(2)
  })
})
#+end_src

*** Rust Implementation

Windowing in Rust typically uses channels to create sub-streams:

#+begin_src rust :tangle no
use async_stream::stream;
use futures::{Stream, StreamExt};
use tokio::sync::mpsc;

/// Split source into windows of specified size.
/// Each window is a separate stream.
pub fn window<T: Send + 'static, S: Stream<Item = T> + Unpin>(
    size: usize,
    mut s: S,
) -> impl Stream<Item = impl Stream<Item = T>> {
    stream! {
        loop {
            let (tx, rx) = mpsc::channel::<T>(size);
            let mut count = 0;
            let mut done = false;

            // Yield the receiver as a stream before filling
            let window_stream = tokio_stream::wrappers::ReceiverStream::new(rx);
            yield window_stream;

            // Fill the window
            while count < size {
                match s.next().await {
                    Some(item) => {
                        let _ = tx.send(item).await;
                        count += 1;
                    }
                    None => {
                        done = true;
                        break;
                    }
                }
            }
            drop(tx);  // Close the channel

            if done {
                break;
            }
        }
    }
}
#+end_src

** =eager= and =eagerNow=

The =eager= operator pre-fetches values from a slow producer, holding them in a cache
so downstream consumers can receive them immediately when ready.

This is like a "reverse throttle" — instead of slowing down emissions, it speeds them up
by doing work ahead of time.

- =eager(n)= - Lazily starts buffering when downstream first requests (default behavior)
- =eagerNow(n)= - Immediately starts buffering as soon as called

Use =eager(0)= or =eagerNow(0)= to buffer all values (use with caution on infinite streams!).

#+begin_src typescript :tangle index.ts

/**
 * Pre-fetches up to `bufferSize` values from a slow producer, caching them for fast downstream access.
 * Starts buffering lazily when the first value is requested.
 * 
 * @param bufferSize - Maximum values to pre-fetch. Use 0 for unlimited (careful with infinite streams!)
 * 
 * @example
 * // Pre-fetch 5 file contents while processing
 * const files = pipe(
 *   filePathStream,
 *   map(path => fs.readFile(path)),
 *   eager(5)  // Buffer up to 5 files ahead
 * )
 */
export function eager<T>(
  bufferSize: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function eager<T>(
  bufferSize: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function eager<T>(
  bufferSize: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => eager(bufferSize, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    const buffer: T[] = []
    let error: Error | null = null
    let done = false
    let consuming = false
    let waitingResolve: (() => void) | null = null

    const startConsuming = () => {
      if (consuming) return
      consuming = true
      
      // Consume source in background
      ;(async () => {
        try {
          while (!done) {
            // Respect buffer limit (0 = unlimited)
            if (bufferSize > 0 && buffer.length >= bufferSize) {
              // Wait for buffer to drain
              await new Promise<void>(r => { waitingResolve = r })
              continue
            }
            
            const result = await iterator.next()
            if (result.done) {
              done = true
            } else {
              buffer.push(result.value)
            }
          }
        } catch (e) {
          error = e as Error
          done = true
        }
      })()
    }

    // Start consuming on first pull
    startConsuming()

    while (true) {
      // Yield buffered values first
      if (buffer.length > 0) {
        const value = buffer.shift()!
        // Signal that buffer has space
        if (waitingResolve) {
          const resolver: () => void = waitingResolve
          waitingResolve = null
          resolver()
        }
        yield value
      } else if (error) {
        // Emit buffered values before error (requirement)
        throw error
      } else if (done) {
        break
      } else {
        // Wait for more values
        await new Promise<void>(r => setTimeout(r, 1))
      }
    }
  })();
}

/**
 * Pre-fetches up to `bufferSize` values from a slow producer immediately on creation.
 * Like `eager`, but starts consuming right away rather than waiting for the first pull.
 * 
 * @param bufferSize - Maximum values to pre-fetch. Use 0 for unlimited (careful with infinite streams!)
 */
export function eagerNow<T>(
  bufferSize: number
): (stream: AsyncIterable<T>) => AsyncIterable<T>;
export function eagerNow<T>(
  bufferSize: number,
  stream: AsyncIterable<T>
): AsyncIterable<T>;
export function eagerNow<T>(
  bufferSize: number,
  stream?: AsyncIterable<T>,
): AsyncIterable<T> | ((stream: AsyncIterable<T>) => AsyncIterable<T>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => eagerNow(bufferSize, s);
  
  const iterator = stream[Symbol.asyncIterator]()
  const buffer: T[] = []
  let error: Error | null = null
  let done = false
  let waitingResolves: (() => void)[] = []

  // Start consuming immediately
  ;(async () => {
    try {
      while (!done) {
        // Respect buffer limit (0 = unlimited)
        if (bufferSize > 0 && buffer.length >= bufferSize) {
          await new Promise<void>(r => { waitingResolves.push(r) })
          continue
        }
        
        const result = await iterator.next()
        if (result.done) {
          done = true
        } else {
          buffer.push(result.value)
        }
      }
    } catch (e) {
      error = e as Error
      done = true
    }
  })()

  return {
    [Symbol.asyncIterator]() {
      return {
        async next(): Promise<IteratorResult<T>> {
          while (true) {
            if (buffer.length > 0) {
              const value = buffer.shift()!
              // Signal that buffer has space
              if (waitingResolves.length > 0) {
                const resolve = waitingResolves.shift()!
                resolve()
              }
              return { value, done: false }
            } else if (error) {
              throw error
            } else if (done) {
              return { value: undefined as any, done: true }
            } else {
              await new Promise<void>(r => setTimeout(r, 1))
            }
          }
        }
      }
    }
  }
}

#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('eager', () => {
  it('pre-fetches values from slow producer', async () => {
    let fetchCount = 0
    const slowStream = async function* () {
      for (let i = 1; i <= 5; i++) {
        fetchCount++
        await new Promise(r => setTimeout(r, 20))
        yield i
      }
    }

    const eagerStream = eager(3, slowStream())
    
    // First pull starts fetching
    const iter = eagerStream[Symbol.asyncIterator]()
    await new Promise(r => setTimeout(r, 70)) // Let it buffer
    
    // Should have pre-fetched some values
    const result = await iter.next()
    expect(result.value).toBe(1)
  })

  it('respects buffer size limit', async () => {
    const values = await collect(eager(2, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3]), eager(2)))
    expect(values).toEqual([1, 2, 3])
  })

  it('emits buffered values then error', async () => {
    // This tests that buffered values are emitted before error
    const failingStream = async function* () {
      yield 1
      yield 2
      throw new Error('fail')
    }
    
    try {
      const values = await collect(eager(5, failingStream()))
      // Should have gotten values before error
      expect(values).toContain(1)
    } catch (e) {
      // Error is expected
      expect((e as Error).message).toBe('fail')
    }
  })
})

describe('eagerNow', () => {
  it('starts buffering immediately', async () => {
    let started = false
    const slowStream = async function* () {
      started = true
      yield 1
    }

    const eager = eagerNow(3, slowStream())
    
    // Give it time to start
    await new Promise(r => setTimeout(r, 10))
    
    // Should have started consuming
    expect(started).toBe(true)
    
    const values = await collect(eager)
    expect(values).toEqual([1])
  })

  it('supports curried form', async () => {
    const eager = eagerNow(2)
    const values = await collect(eager(from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Rust Implementation

Pre-fetching in Rust is typically done with buffered channels or background tasks:

#+begin_src rust :tangle no
use futures::{Stream, StreamExt};
use tokio::sync::mpsc;
use async_stream::stream;

/// Pre-fetch values from a slow producer into a buffer.
/// Starts lazily when first value is requested.
pub fn eager<T: Send + 'static, S: Stream<Item = T> + Send + Unpin + 'static>(
    buffer_size: usize,
    s: S,
) -> impl Stream<Item = T> {
    // Use a channel as the buffer
    let (tx, mut rx) = mpsc::channel::<T>(buffer_size.max(1));
    
    // Spawn background consumer on first pull
    let mut spawned = false;
    let mut s = Some(s);
    
    stream! {
        if !spawned {
            spawned = true;
            let mut source = s.take().unwrap();
            let tx = tx.clone();
            tokio::spawn(async move {
                while let Some(item) = source.next().await {
                    if tx.send(item).await.is_err() {
                        break;  // Receiver dropped
                    }
                }
            });
        }
        drop(tx);  // Drop our copy so channel closes when task finishes
        
        while let Some(item) = rx.recv().await {
            yield item;
        }
    }
}

/// Pre-fetch values immediately on creation.
pub fn eager_now<T: Send + 'static, S: Stream<Item = T> + Send + Unpin + 'static>(
    buffer_size: usize,
    s: S,
) -> impl Stream<Item = T> {
    let (tx, mut rx) = mpsc::channel::<T>(buffer_size.max(1));
    
    // Start consuming immediately
    let mut source = s;
    tokio::spawn(async move {
        while let Some(item) = source.next().await {
            if tx.send(item).await.is_err() {
                break;
            }
        }
    });
    
    stream! {
        while let Some(item) = rx.recv().await {
            yield item;
        }
    }
}
#+end_src

* Multicasting

By default, async generators are single-consumer: each consumer pulls values independently.
These operators enable multiple consumers to share a single source stream.

** =ReplaySubject=

A =ReplaySubject= is a multicasting primitive that:
1. Buffers up to N most recent values
2. Allows multiple consumers to subscribe
3. Replays buffered values to new subscribers
4. Forwards live values to all active subscribers

#+begin_src typescript :tangle index.ts

/**
 * A multicasting subject that replays buffered values to new subscribers.
 * 
 * @example
 * const subject = new ReplaySubject<number>(2)  // buffer last 2 values
 * 
 * // Push values
 * subject.next(1)
 * subject.next(2)
 * subject.next(3)
 * 
 * // New subscriber gets [2, 3] immediately, then live values
 * for await (const value of subject) { ... }
 */
export class ReplaySubject<T> implements AsyncIterable<T> {
  private buffer: T[] = []
  private subscribers: Set<{
    queue: T[]
    resolve: ((result: IteratorResult<T>) => void) | null
  }> = new Set()
  private completed = false
  private error: Error | null = null

  constructor(private bufferSize: number = Infinity) {}

  /**
   * Push a value to all subscribers.
   */
  next(value: T): void {
    if (this.completed) throw new Error('Cannot push to completed ReplaySubject')
    
    // Add to buffer
    this.buffer.push(value)
    if (this.buffer.length > this.bufferSize) {
      this.buffer.shift()
    }

    // Notify all subscribers
    for (const sub of this.subscribers) {
      if (sub.resolve) {
        const resolve = sub.resolve
        sub.resolve = null
        resolve({ value, done: false })
      } else {
        sub.queue.push(value)
      }
    }
  }

  /**
   * Signal completion to all subscribers.
   */
  complete(): void {
    this.completed = true
    for (const sub of this.subscribers) {
      if (sub.resolve) {
        const resolve = sub.resolve
        sub.resolve = null
        resolve({ value: undefined as T, done: true })
      }
    }
  }

  /**
   * Signal an error to all subscribers.
   */
  throw(error: Error): void {
    this.error = error
    this.completed = true
    // Subscribers will see the error on next pull
  }

  [Symbol.asyncIterator](): AsyncIterator<T> {
    const sub = {
      queue: [...this.buffer],  // Start with buffered values
      resolve: null as ((result: IteratorResult<T>) => void) | null
    }
    this.subscribers.add(sub)

    return {
      next: async (): Promise<IteratorResult<T>> => {
        // Check for error
        if (this.error) throw this.error
        
        // Return queued value if available
        if (sub.queue.length > 0) {
          return { value: sub.queue.shift()!, done: false }
        }
        
        // Check if completed
        if (this.completed) {
          this.subscribers.delete(sub)
          return { value: undefined as T, done: true }
        }

        // Wait for next value
        return new Promise(resolve => {
          sub.resolve = resolve
        })
      },
      return: async (): Promise<IteratorResult<T>> => {
        this.subscribers.delete(sub)
        return { value: undefined as T, done: true }
      }
    }
  }

  /**
   * Get the current buffer contents (snapshot).
   */
  getBuffer(): readonly T[] {
    return [...this.buffer]
  }

  /**
   * Number of active subscribers.
   */
  get subscriberCount(): number {
    return this.subscribers.size
  }
}

#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('ReplaySubject', () => {
  it('replays buffered values to new subscribers', async () => {
    const subject = new ReplaySubject<number>(2)
    
    subject.next(1)
    subject.next(2)
    subject.next(3)
    subject.complete()
    
    // New subscriber gets last 2 values
    const values = await collect(subject)
    expect(values).toEqual([2, 3])
  })

  it('multicasts to multiple subscribers', async () => {
    const subject = new ReplaySubject<number>()
    
    // Start two consumers
    const consumer1: number[] = []
    const consumer2: number[] = []
    
    const iter1 = subject[Symbol.asyncIterator]()
    const iter2 = subject[Symbol.asyncIterator]()
    
    subject.next(1)
    subject.next(2)
    subject.complete()
    
    // Both should receive all values
    let result = await iter1.next()
    while (!result.done) {
      consumer1.push(result.value)
      result = await iter1.next()
    }
    
    result = await iter2.next()
    while (!result.done) {
      consumer2.push(result.value)
      result = await iter2.next()
    }
    
    expect(consumer1).toEqual([1, 2])
    expect(consumer2).toEqual([1, 2])
  })
})
#+end_src

*** Rust Implementation

Rust's =tokio::sync::broadcast= provides similar multicasting capabilities:

#+begin_src rust :tangle no
use std::sync::{Arc, Mutex};\nuse tokio::sync::broadcast;\nuse futures::Stream;\nuse async_stream::stream;\n\n/// A multicasting subject that replays buffered values to new subscribers.\npub struct ReplaySubject<T: Clone + Send + 'static> {\n    buffer: Arc<Mutex<Vec<T>>>,\n    buffer_size: usize,\n    tx: broadcast::Sender<T>,\n}\n\nimpl<T: Clone + Send + 'static> ReplaySubject<T> {\n    pub fn new(buffer_size: usize) -> Self {\n        let (tx, _) = broadcast::channel(buffer_size.max(16));\n        Self {\n            buffer: Arc::new(Mutex::new(Vec::new())),\n            buffer_size,\n            tx,\n        }\n    }\n\n    pub fn next(&self, value: T) {\n        let mut buf = self.buffer.lock().unwrap();\n        buf.push(value.clone());\n        if buf.len() > self.buffer_size {\n            buf.remove(0);\n        }\n        let _ = self.tx.send(value);\n    }\n\n    pub fn subscribe(&self) -> impl Stream<Item = T> {\n        let buffer = self.buffer.lock().unwrap().clone();\n        let mut rx = self.tx.subscribe();\n        \n        stream! {\n            // Replay buffered values first\n            for item in buffer {\n                yield item;\n            }\n            // Then receive live values\n            while let Ok(item) = rx.recv().await {\n                yield item;\n            }\n        }\n    }\n}\n#+end_src

** =replay=

The =replay= function wraps a source stream to allow multiple consumers.
Each consumer receives buffered values plus all subsequent values.

The source stream is consumed lazily on first subscription.

#+begin_src typescript :tangle index.ts

/**
 * Makes a stream consumable by multiple consumers by buffering values.
 * 
 * @param bufferSize - Maximum number of values to buffer for replay (default: Infinity)
 * @param source - The source stream to multicast
 * @returns An AsyncIterable that can be consumed by multiple consumers
 * 
 * @example
 * const shared = replay(2, sourceStream)
 * 
 * // Consumer 1 starts
 * const consumer1 = collect(shared)
 * 
 * // Consumer 2 joins later, gets last 2 values + live values
 * const consumer2 = collect(shared)
 */
export function replay<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): AsyncIterable<T> {
  const subject = new ReplaySubject<T>(bufferSize)
  let started = false

  const startSource = () => {
    if (started) return
    started = true
    
    ;(async () => {
      try {
        for await (const value of source) {
          subject.next(value)
        }
        subject.complete()
      } catch (e) {
        subject.throw(e as Error)
      }
    })()
  }

  return {
    [Symbol.asyncIterator](): AsyncIterator<T> {
      startSource()
      return subject[Symbol.asyncIterator]()
    }
  }
}

#+end_src

*** When to Use

Use =replay= to share a single source among multiple consumers while buffering recent values. Late subscribers receive buffered values plus live updates.

#+begin_src text :tangle no
source:      --1--2--3--4--5--|

[with replay(2)]:

consumer 1:  --1--2--3--4--5--|  (starts at beginning)
consumer 2:       [2,3]4--5--|   (joins at 3, gets buffer [2,3])
consumer 3:            [4,5]|    (joins at end, gets buffer [4,5])
#+end_src

#+begin_src javascript :tangle no
// Share expensive computation result
const sharedData = replay(Infinity, pipe(
  fromPromise(expensiveFetch()),
  chain(data => from(data.items))
))

// Multiple components can consume
const component1 = collect(sharedData)
const component2 = collect(sharedData)  // Same data, no refetch

// Cache recent values for late subscribers
const priceUpdates = replay(1, livePrice$)  // Cache latest price

// Event sourcing: replay history for new subscribers
const eventLog = replay(1000, events)  // Keep last 1000 events
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('replay', () => {
  it('allows multiple consumers of a single source', async () => {
    const source = from([1, 2, 3])
    const shared = replay(Infinity, source)
    
    const values1 = await collect(shared)
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3])
    expect(values2).toEqual([1, 2, 3])
  })

  it('respects buffer size', async () => {
    const source = from([1, 2, 3, 4, 5])
    const shared = replay(2, source)
    
    // First consumer triggers source consumption
    const values1 = await collect(shared)
    
    // Second consumer only gets last 2 buffered values
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3, 4, 5])
    expect(values2).toEqual([4, 5])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use std::sync::Arc;
use tokio::sync::Mutex;

/// Replay creates a shared stream that buffers values for late subscribers.
struct Replay<T> {
    inner: Arc<Mutex<ReplayInner<T>>>,
}

struct ReplayInner<T> {
    buffer: Vec<T>,
    buffer_size: usize,
    completed: bool,
    error: Option<Arc<dyn std::error::Error + Send + Sync>>,
    source_started: bool,
    subscribers: Vec<tokio::sync::mpsc::UnboundedSender<Result<T, Arc<dyn std::error::Error + Send + Sync>>>>,
}

impl<T: Clone + Send + 'static> Replay<T> {
    fn new<S>(buffer_size: usize, source: S) -> Self
    where
        S: futures::Stream<Item = T> + Send + Unpin + 'static,
    {
        let inner = Arc::new(Mutex::new(ReplayInner {
            buffer: Vec::new(),
            buffer_size,
            completed: false,
            error: None,
            source_started: false,
            subscribers: Vec::new(),
        }));
        
        Replay { inner }
    }
    
    fn subscribe(&self) -> impl futures::Stream<Item = T> {
        let inner = self.inner.clone();
        
        async_stream::stream! {
            let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();
            
            // Get buffered values and register subscriber
            let buffered: Vec<T>;
            {
                let mut guard = inner.lock().await;
                buffered = guard.buffer.clone();
                
                if !guard.completed && guard.error.is_none() {
                    guard.subscribers.push(tx);
                }
            }
            
            // Yield buffered values first
            for value in buffered {
                yield value;
            }
            
            // Receive live values
            while let Some(result) = rx.recv().await {
                match result {
                    Ok(value) => yield value,
                    Err(_) => break,
                }
            }
        }
    }
    
    async fn start_source<S>(&self, mut source: S)
    where
        S: futures::Stream<Item = T> + Send + Unpin + 'static,
    {
        use futures::StreamExt;
        
        while let Some(value) = source.next().await {
            let mut guard = self.inner.lock().await;
            
            // Buffer the value
            guard.buffer.push(value.clone());
            if guard.buffer.len() > guard.buffer_size {
                guard.buffer.remove(0);
            }
            
            // Broadcast to subscribers
            guard.subscribers.retain(|tx| tx.send(Ok(value.clone())).is_ok());
        }
        
        // Mark complete
        let mut guard = self.inner.lock().await;
        guard.completed = true;
        guard.subscribers.clear();
    }
}

/// Convenience function to replay a stream
fn replay<T, S>(buffer_size: usize, source: S) -> impl futures::Stream<Item = T>
where
    T: Clone + Send + 'static,
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
    use std::sync::Once;
    use futures::StreamExt;
    
    let replay = Arc::new(Replay::new(buffer_size, source));
    let replay_clone = replay.clone();
    
    // Start source consumption on first subscribe
    async_stream::stream! {
        let stream = replay_clone.subscribe();
        tokio::pin!(stream);
        while let Some(value) = stream.next().await {
            yield value;
        }
    }
}
#+end_src

** =share=

The =share= function is like =replay= with a buffer size of 0.
New subscribers only receive values emitted after they subscribe.

#+begin_src typescript :tangle index.ts

/**
 * Shares a stream among multiple consumers without buffering.
 * New subscribers only receive values emitted after subscription.
 * 
 * @example
 * const shared = share(sourceStream)
 * const consumer1 = shared[Symbol.asyncIterator]()
 * // ... later ...
 * const consumer2 = shared[Symbol.asyncIterator]()
 * // consumer2 misses values emitted before subscription
 */
export function share<T>(source: AsyncIterable<T>): AsyncIterable<T> {
  return replay(0, source)
}

#+end_src

*** When to Use

Use =share= when multiple consumers should receive the same live stream but don't need historical values. Late subscribers only get values emitted after they subscribe.

#+begin_src text :tangle no
source:      --1--2--3--4--5--|\n
[with share]:\n
consumer 1:  --1--2--3--4--5--|  (starts at beginning)
consumer 2:       ?--3--4--5--|   (joins at 3, misses 1,2)
consumer 3:            ?--5--|    (joins at 5, misses 1-4)
#+end_src

#+begin_src javascript :tangle no
// Share WebSocket connection among components
const wsMessages = share(fromWebSocket(ws))

// Multiple listeners get same live events
for await (const msg of wsMessages) { handleMsg1(msg) }
for await (const msg of wsMessages) { handleMsg2(msg) }  // Different messages!

// Share mouse position stream
const mousePosition = share(
  fromEvent(document, 'mousemove')
)

// Use replay(1) instead if you need the current value for late subscribers
const currentPosition = replay(1, mousePosition)
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('share', () => {
  it('shares without buffering', async () => {
    const source = from([1, 2, 3])
    const shared = share(source)
    
    // First consumer gets all values
    const values1 = await collect(shared)
    
    // Second consumer gets nothing (no buffer)
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3])
    expect(values2).toEqual([])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use std::sync::Arc;
use tokio::sync::Mutex;

/// Share a stream among multiple consumers without buffering.
/// This is equivalent to replay(0, source).
fn share<T, S>(source: S) -> impl futures::Stream<Item = T>
where
    T: Clone + Send + 'static,
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
    replay(0, source)
}

// Example usage
async fn share_example() {
    use futures::StreamExt;
    
    // Since share has no buffer, late subscribers miss early values
    let source = futures::stream::iter(vec![1, 2, 3]);
    let shared = share(source);
    
    // First consumer gets values
    tokio::pin!(shared);
    while let Some(value) = shared.next().await {
        println!("Got: {}", value);
    }
}
#+end_src

** =replayFactory= and =replayStream=

The =replayFactory= function returns a factory that produces independent stream copies.
Each emitted stream is a complete replay of the source from the beginning.

This is useful when you need to provide fresh copies of a stream to different parts of your application.

#+begin_src typescript :tangle index.ts

/**
 * Creates a factory that produces independent copies of a buffered stream.
 * 
 * @param bufferSize - Maximum values to buffer
 * @param source - The source stream
 * @returns A function that creates new stream copies
 * 
 * @example
 * const factory = replayFactory(Infinity, sourceStream)
 * 
 * const copy1 = factory()  // Gets all values from beginning
 * const copy2 = factory()  // Also gets all values from beginning
 */
export function replayFactory<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): () => AsyncIterable<T> {
  const subject = new ReplaySubject<T>(bufferSize)
  let started = false

  const startSource = () => {
    if (started) return
    started = true
    
    ;(async () => {
      try {
        for await (const value of source) {
          subject.next(value)
        }
        subject.complete()
      } catch (e) {
        subject.throw(e as Error)
      }
    })()
  }

  return () => {
    startSource()
    return {
      [Symbol.asyncIterator]: () => subject[Symbol.asyncIterator]()
    }
  }
}

#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('replayFactory', () => {
  it('creates factory that produces stream copies', async () => {
    const factory = replayFactory(Infinity, from([1, 2, 3]))
    
    const copy1 = await collect(factory())
    const copy2 = await collect(factory())
    
    expect(copy1).toEqual([1, 2, 3])
    expect(copy2).toEqual([1, 2, 3])
  })

  it('respects buffer size in replayFactory', async () => {
    const factory = replayFactory(2, from([1, 2, 3, 4, 5]))
    
    // First consumer gets all values and triggers buffering
    const copy1 = await collect(factory())
    expect(copy1).toEqual([1, 2, 3, 4, 5])
    
    // Second consumer only gets last 2 buffered values
    const copy2 = await collect(factory())
    expect(copy2).toEqual([4, 5])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use std::sync::Arc;
use tokio::sync::Mutex;

/// Creates a factory that produces independent copies of a buffered stream.
/// Each call to the factory returns a fresh stream that replays buffered values.
fn replay_factory<T, S>(
    buffer_size: usize,
    source: S,
) -> impl Fn() -> impl futures::Stream<Item = T>
where
    T: Clone + Send + Sync + 'static,
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
    use std::sync::atomic::{AtomicBool, Ordering};
    
    struct SharedState<T> {
        buffer: Vec<T>,
        buffer_size: usize,
        completed: bool,
        subscribers: Vec<tokio::sync::mpsc::UnboundedSender<T>>,
    }
    
    let state = Arc::new(Mutex::new(SharedState {
        buffer: Vec::new(),
        buffer_size,
        completed: false,
        subscribers: Vec::new(),
    }));
    let started = Arc::new(AtomicBool::new(false));
    let source = Arc::new(Mutex::new(Some(source)));
    
    move || {
        let state = state.clone();
        let started = started.clone();
        let source = source.clone();
        
        async_stream::stream! {
            // Start source consumption if not already started
            if !started.swap(true, Ordering::SeqCst) {
                let state_clone = state.clone();
                if let Some(mut src) = source.lock().await.take() {
                    tokio::spawn(async move {
                        use futures::StreamExt;
                        while let Some(value) = src.next().await {
                            let mut guard = state_clone.lock().await;
                            guard.buffer.push(value.clone());
                            if guard.buffer.len() > guard.buffer_size {
                                guard.buffer.remove(0);
                            }
                            guard.subscribers.retain(|tx| tx.send(value.clone()).is_ok());
                        }
                        state_clone.lock().await.completed = true;
                    });
                }
            }
            
            let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();
            let buffered: Vec<T>;
            {
                let mut guard = state.lock().await;
                buffered = guard.buffer.clone();
                if !guard.completed {
                    guard.subscribers.push(tx);
                }
            }
            
            for value in buffered {
                yield value;
            }
            
            while let Some(value) = rx.recv().await {
                yield value;
            }
        }
    }
}
#+end_src

** =replayStream=

=replayStream= returns a stream that emits independent copies of the source stream.

#+begin_src typescript :tangle index.ts
/**
 * Returns a stream that emits independent copies of the source stream.
 * Each pull creates a new subscriber that receives buffered + live values.
 * 
 * @example
 * const copies = replayStream(2, sourceStream)
 * 
 * for await (const streamCopy of copies) {
 *   // Each streamCopy is an independent consumer
 *   processStream(streamCopy)
 * }
 */
export async function* replayStream<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): AsyncGenerator<AsyncIterable<T>, void, void> {
  const factory = replayFactory(bufferSize, source)
  
  // Emit copies indefinitely until the caller stops asking
  while (true) {
    yield factory()
  }
}
#+end_src

*** Tests

#+begin_src typescript :noweb-ref tests
describe('replayStream', () => {
  it('emits stream copies', async () => {
    const copies = replayStream(Infinity, from([1, 2, 3]))
    
    // Get first copy
    const first = await copies.next()
    expect(first.done).toBe(false)
    
    // Collect values from the copy
    const values = await collect(first.value!)
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Rust Implementation

#+begin_src rust :tangle no
use std::sync::Arc;
use tokio::sync::Mutex;

/// Returns a stream that emits independent copies of the source stream.
/// Each pull creates a new subscriber that receives buffered + live values.
fn replay_stream<T, S>(
    buffer_size: usize,
    source: S,
) -> impl futures::Stream<Item = impl futures::Stream<Item = T>>
where
    T: Clone + Send + Sync + 'static,
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
    let factory = replay_factory(buffer_size, source);
    
    async_stream::stream! {
        // Emit stream copies indefinitely
        loop {
            yield factory();
        }
    }
}

// Example usage
async fn replay_stream_example() {
    use futures::StreamExt;
    
    let source = futures::stream::iter(vec![1, 2, 3]);
    let mut copies = replay_stream(usize::MAX, source);
    
    // Get first copy
    if let Some(copy) = copies.next().await {
        tokio::pin!(copy);
        let values: Vec<_> = copy.collect().await;
        println!("Copy values: {:?}", values);
    }
}
#+end_src

* Key Concepts

This section explains important concepts for working with async generator streams.

** Backpressure

Async generators are *pull-based*: values are only produced when a consumer requests them via =.next()=.
This provides natural backpressure — if your consumer is slow, the producer automatically waits.

#+begin_src text :tangle no
Push-based (Observables):          Pull-based (Async Generators):

  Producer                           Producer
     │                                  │
     ▼ emit(1)                          │ (idle)
     ▼ emit(2)                          │
     ▼ emit(3)     ← Consumer           ▼ .next() ← Consumer ready
     ▼ emit(4)       overwhelmed!       │ yield 1
     ▼ emit(5)                          │ (waits for next pull)
     │                                  ▼ .next() ← Consumer ready
  Buffer overflow?                      │ yield 2
                                        │ ...
#+end_src

This means you don't need explicit buffering strategies for slow consumers — the async iteration protocol handles it naturally.

** Cancellation

Async iterators support cancellation via the =return()= method.
When you =break= from a =for await...of= loop, JavaScript automatically calls =return()= on the iterator.

#+begin_src javascript :tangle no
// Cancellation happens automatically when breaking from a loop
for await (const value of someStream) {
  if (value > 100) break;  // Iterator's return() is called
}

// Manual cancellation
const iterator = someStream[Symbol.asyncIterator]();
await iterator.next();  // Get first value
await iterator.return();  // Cancel — cleanup runs
#+end_src

For cleanup logic (closing connections, clearing timers), use =try/finally= in your generators:

#+begin_src javascript :tangle no
async function* resourceStream() {
  const connection = await openConnection();
  try {
    while (true) {
      yield await connection.read();
    }
  } finally {
    // Runs on normal completion OR cancellation
    await connection.close();
  }
}
#+end_src

** Memory Considerations

*Unbounded buffering:* Be cautious with operators like =replay(Infinity, ...)= on long-running or infinite streams — they buffer all values in memory.

*Holding iterator references:* An async generator cannot be garbage collected while something holds a reference to its iterator.
If you create an iterator but never consume it, the generator function remains suspended indefinitely.

#+begin_src javascript :tangle no
// ⚠️ Potential memory leak
const iterator = infiniteStream[Symbol.asyncIterator]();
await iterator.next();  // Generator is now suspended
// If you forget about 'iterator', the generator stays in memory

// ✓ Always clean up when done
await iterator.return();  // Allows garbage collection
#+end_src

*Never-completing streams:* When merging or combining streams, remember that the combined stream won't complete until all source streams complete.
For streams that never complete (like =periodic= or event streams), use =take=, =takeUntil=, or =untilStream= to ensure termination.

* Project Configuration

Configuration files for building and testing the library.

** =package.json=

#+begin_src json :tangle package.json
{
  "name": "agent-rex",
  "version": "0.1.0",
  "description": "An Async Generator/Iterator Based FRP-Like Library for JavaScript",
  "type": "module",
  "main": "index.ts",
  "scripts": {
    "test": "vitest",
    "test:run": "vitest run",
    "test:coverage": "vitest run --coverage"
  },
  "devDependencies": {
    "vitest": "^2.1.0",
    "typescript": "^5.6.0"
  },
  "author": "Timothy Hope",
  "license": "MIT"
}
#+end_src

** =vitest.config.ts=

#+begin_src typescript :tangle vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    globals: true,
    include: ['**/*.test.ts'],
    testTimeout: 5000,
  },
})
#+end_src

** =tsconfig.json=

#+begin_src json :tangle tsconfig.json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "declaration": true,
    "outDir": "dist",
    "rootDir": "."
  },
  "include": ["*.ts"],
  "exclude": ["node_modules", "dist"]
}
#+end_src

* Testing Infrastructure

This section provides test helpers for ergonomic testing of async generator streams.
These helpers focus on three key areas:

1. *Stream Creation*: Easily create test streams with controlled timing
2. *Stream Collection*: Collect stream values into arrays or with timing metadata
3. *Assertions*: Custom matchers for stream behavior verification

** Test Helpers

The test helpers are designed to make testing async streams as intuitive as testing synchronous code.

*** =TestScheduler=

A virtual time scheduler for deterministic testing of time-based operations.
This allows tests to run instantly without waiting for real time to pass.

*Note:* The =TestScheduler= is currently a standalone utility and is not integrated with
the time-based operators (=debounce=, =throttle=, =delay=, =periodic=) out of the box.
To use virtual time in tests, you would need to inject the scheduler's =delay= method
into operators or create custom test variants. A future version may provide tighter integration.

For now, use real-time delays with reasonable durations (10-50ms) for testing, or mock
=setTimeout=/=Promise= directly if you need deterministic timing.

#+begin_src typescript :tangle no
// Usage:
const scheduler = new TestScheduler()

// Schedule events at virtual times
scheduler.schedule(100, () => emit(1))
scheduler.schedule(200, () => emit(2))

// Advance virtual time
await scheduler.advanceTo(150)  // First event fires
await scheduler.advanceTo(300)  // Second event fires
#+end_src

#+begin_src typescript :tangle test-helpers.ts
/**
 * A virtual time scheduler for deterministic async stream testing.
 * Allows you to control time progression without waiting for real time.
 */
export class TestScheduler {
  private currentTime = 0
  private queue: Array<{ time: number; action: () => void }> = []
  private resolvers: Array<{ time: number; resolve: () => void }> = []

  /**
   * Get the current virtual time in milliseconds.
   */
  get now(): number {
    return this.currentTime
  }

  /**
   * Schedule an action to run at a specific virtual time.
   */
  schedule(time: number, action: () => void): void {
    this.queue.push({ time, action })
    this.queue.sort((a, b) => a.time - b.time)
  }

  /**
   * Create a promise that resolves after a virtual delay.
   * Use this instead of `setTimeout` in test streams.
   */
  delay(ms: number): Promise<void> {
    const targetTime = this.currentTime + ms
    return new Promise(resolve => {
      this.resolvers.push({ time: targetTime, resolve })
      this.resolvers.sort((a, b) => a.time - b.time)
    })
  }

  /**
   * Advance virtual time to a specific point, executing all scheduled actions.
   */
  async advanceTo(time: number): Promise<void> {
    while (this.queue.length > 0 || this.resolvers.length > 0) {
      const nextQueued = this.queue[0]?.time ?? Infinity
      const nextResolver = this.resolvers[0]?.time ?? Infinity
      const nextTime = Math.min(nextQueued, nextResolver)

      if (nextTime > time) break

      this.currentTime = nextTime

      // Process all actions at this time
      while (this.queue[0]?.time === nextTime) {
        const { action } = this.queue.shift()!
        action()
      }

      // Resolve all delays at this time
      while (this.resolvers[0]?.time === nextTime) {
        const { resolve } = this.resolvers.shift()!
        resolve()
      }

      // Allow microtasks to run
      await Promise.resolve()
    }

    this.currentTime = time
  }

  /**
   * Advance virtual time by a relative amount.
   */
  async advanceBy(ms: number): Promise<void> {
    await this.advanceTo(this.currentTime + ms)
  }

  /**
   * Run all scheduled actions to completion.
   */
  async flush(): Promise<void> {
    const maxTime = Math.max(
      ...this.queue.map(q => q.time),
      ...this.resolvers.map(r => r.time),
      this.currentTime
    )
    await this.advanceTo(maxTime)
  }

  /**
   * Reset the scheduler to initial state.
   */
  reset(): void {
    this.currentTime = 0
    this.queue = []
    this.resolvers = []
  }
}

#+end_src

*** =TestStream=

A controllable async generator for testing.
Values can be pushed manually, allowing precise control over when emissions occur.

#+begin_src typescript :tangle no
// Usage:
const stream = new TestStream<number>()

// Push values (can be done from anywhere)
stream.push(1)
stream.push(2)
stream.complete()

// Consume in test
const values = await collect(stream)
expect(values).toEqual([1, 2])
#+end_src

#+begin_src typescript :tangle test-helpers.ts

/**
 * A controllable async stream for testing.
 * Push values manually and control completion/errors.
 */
export class TestStream<T> implements AsyncIterable<T> {
  private queue: T[] = []
  private waiting: ((value: IteratorResult<T>) => void) | null = null
  private done = false
  private error: Error | null = null

  /**
   * Push a value to the stream.
   * If a consumer is waiting, it receives the value immediately.
   */
  push(value: T): void {
    if (this.done) throw new Error('Cannot push to completed stream')
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      resolve({ value, done: false })
    } else {
      this.queue.push(value)
    }
  }

  /**
   * Push multiple values to the stream.
   */
  pushAll(...values: T[]): void {
    values.forEach(v => this.push(v))
  }

  /**
   * Signal that the stream is complete.
   * No more values can be pushed after this.
   */
  complete(): void {
    this.done = true
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      resolve({ value: undefined as any, done: true })
    }
  }

  /**
   * Signal an error on the stream.
   */
  throw(error: Error): void {
    this.error = error
    this.done = true
    // If someone is waiting, we need to reject them
    // However, we can't reject a resolve function directly.
    // The error will be thrown on the next next() call.
    // Clear waiting so they re-check error state.
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      // Resolve with done=true, the error will be thrown on next call
      // Actually, we need to handle this by having next() check error first
      // which it already does. But for pending waiters, we need to wake them.
      // Since we can't reject, we resolve with done and let next() throw.
      resolve({ value: undefined as any, done: true })
    }
  }

  [Symbol.asyncIterator](): AsyncIterator<T> {
    return {
      next: async (): Promise<IteratorResult<T>> => {
        if (this.error) throw this.error
        if (this.queue.length > 0) {
          return { value: this.queue.shift()!, done: false }
        }
        if (this.done) {
          return { value: undefined as any, done: true }
        }
        return new Promise(resolve => {
          this.waiting = resolve
          // Check for error after setting waiting
          if (this.error) {
            this.waiting = null
            throw this.error
          }
        })
      }
    }
  }
}

#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('TestStream', () => {
  it('allows manual value pushing', async () => {
    const stream = new TestStream<number>()
    
    // Push values async
    setTimeout(() => {
      stream.push(1)
      stream.push(2)
      stream.complete()
    }, 10)

    const values = await collect(stream)
    expect(values).toEqual([1, 2])
  })
})
#+end_src

*** =collect=

Collectors for gathering stream values into arrays.
Essential for making assertions about stream output.

#+begin_src typescript :tangle no
// Usage:
// Basic collection
const values = await collect(from([1, 2, 3]))
expect(values).toEqual([1, 2, 3])

// With timing information
const timed = await collectWithTime(stream)
// [{ value: 1, time: 0 }, { value: 2, time: 100 }, ...]

// Collect first N values
const first3 = await collectN(3, infiniteStream)
#+end_src

#+begin_src typescript :tangle test-helpers.ts

/**
 * Collect all values from a stream into an array.
 * The stream must complete for this to resolve.
 */
export async function collect<T>(stream: AsyncIterable<T>): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) values.push(value)
  return values
}

/**
 * Collected value with timing metadata.
 */
export interface TimedValue<T> {
  value: T
  /** Milliseconds since collection started */
  elapsed: number
}

/**
 * Collect all values from a stream with timing information.
 * Useful for testing time-based operations.
 */
export async function collectWithTime<T>(
  stream: AsyncIterable<T>
): Promise<TimedValue<T>[]> {
  const values: TimedValue<T>[] = []
  const start = Date.now()
  for await (const value of stream) {
    values.push({ value, elapsed: Date.now() - start })
  }
  return values
}

/**
 * Collect exactly N values from a stream.
 * Useful for testing infinite or long-running streams.
 */
export async function collectN<T>(
  n: number,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) {
    values.push(value)
    if (values.length >= n) break
  }
  return values
}

/**
 * Collect values until a predicate returns true.
 * The matching value is included in the result.
 */
export async function collectUntil<T>(
  predicate: (value: T) => boolean,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) {
    values.push(value)
    if (predicate(value)) break
  }
  return values
}

/**
 * Collect values with a timeout.
 * Returns whatever was collected when the timeout expires.
 */
export async function collectWithTimeout<T>(
  ms: number,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  const iterator = stream[Symbol.asyncIterator]()
  const timeout = new Promise<'timeout'>(resolve => 
    setTimeout(() => resolve('timeout'), ms)
  )

  while (true) {
    const result = await Promise.race([iterator.next(), timeout])
    if (result === 'timeout') break
    if (result.done) break
    values.push(result.value)
  }

  return values
}

#+end_src

*** =marble=

Marble testing helpers for visual stream descriptions.
Inspired by RxJS marble diagrams.

#+begin_src text :tangle no
Marble syntax:
  '-'  = 10ms of time passing
  'a'  = emit value (from values object)
  '|'  = complete
  '#'  = error
  '()' = sync grouping (multiple values at same time)

Usage:
  const stream = marble('-a-b-c|', { a: 1, b: 2, c: 3 })
  // Emits 1 at 10ms, 2 at 30ms, 3 at 50ms, completes at 60ms

  expect(await collect(stream)).toEqual([1, 2, 3])
#+end_src

#+begin_src typescript :tangle test-helpers.ts

/**
 * Options for marble stream creation.
 */
export interface MarbleOptions<T> {
  /** Map of characters to their emission values */
  values?: Record<string, T>
  /** Time per frame (each '-' or character), default 10ms */
  frameTime?: number
  /** Error to throw when '#' is encountered */
  error?: Error
}

/**
 * Create a stream from a marble diagram string.
 * 
 * Marble syntax:
 * - '-' advances time by one frame
 * - Letters emit the corresponding value from the values map
 * - '|' completes the stream
 * - '#' errors the stream
 * - '()' groups emissions at the same time point
 * 
 * @example
 * const stream = marble('-a-b-|', { a: 1, b: 2 })
 * // Emits 1 at 10ms, 2 at 30ms, completes at 50ms
 */
export async function* marble<T>(
  diagram: string,
  options: MarbleOptions<T> = {}
): AsyncGenerator<T, void, void> {
  const { values = {} as Record<string, T>, frameTime = 10, error = new Error('marble error') } = options
  let i = 0
  let inGroup = false
  let groupValues: T[] = []

  while (i < diagram.length) {
    const char = diagram[i]

    if (char === '-') {
      if (!inGroup) await delay(frameTime)
    } else if (char === '|') {
      return
    } else if (char === '#') {
      throw error
    } else if (char === '(') {
      inGroup = true
      groupValues = []
    } else if (char === ')') {
      inGroup = false
      for (const v of groupValues) yield v
      await delay(frameTime)
    } else if (char === ' ') {
      // Ignore spaces (for readability)
    } else {
      const value = values[char] ?? (char as unknown as T)
      if (inGroup) {
        groupValues.push(value)
      } else {
        yield value
        await delay(frameTime)
      }
    }
    i++
  }
}

function delay(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms))
}

/**
 * Parse a marble diagram into a sequence of events for testing.
 * Returns the expected values and their relative times.
 */
export function parseMarble<T>(
  diagram: string,
  options: MarbleOptions<T> = {}
): Array<{ time: number; value: T }> {
  const { values = {} as Record<string, T>, frameTime = 10 } = options
  const events: Array<{ time: number; value: T }> = []
  let time = 0
  let i = 0
  let inGroup = false

  while (i < diagram.length) {
    const char = diagram[i]

    if (char === '-') {
      if (!inGroup) time += frameTime
    } else if (char === '|' || char === '#') {
      // Completion/error markers don't emit values
    } else if (char === '(') {
      inGroup = true
    } else if (char === ')') {
      inGroup = false
      time += frameTime
    } else if (char === ' ') {
      // Ignore spaces
    } else {
      const value = values[char] ?? (char as unknown as T)
      events.push({ time, value })
      if (!inGroup) time += frameTime
    }
    i++
  }

  return events
}

#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('marble', () => {
  it('creates streams from marble diagrams', async () => {
    const stream = marble('-a-b-c|', { values: { a: 1, b: 2, c: 3 } })
    const result = await collect(stream)
    expect(result).toEqual([1, 2, 3])
  })
})
#+end_src

#+begin_src typescript :noweb-ref tests
describe('collectWithTime', () => {
  it('records timing of emissions', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 50 })
    const result = await collectWithTime(stream)
    
    expect(result.map(r => r.value)).toEqual([1, 2, 3])
    expect(result[1].elapsed).toBeGreaterThanOrEqual(40)
    expect(result[2].elapsed).toBeGreaterThanOrEqual(90)
  })
})
#+end_src

*** =drainN=

Drain helpers for consuming streams without collecting values.

#+begin_src typescript :tangle test-helpers.ts

/**
 * Consume N values from a stream, discarding them.
 * Useful for advancing a stream to a certain point.
 */
export async function drainN<T>(
  n: number,
  stream: AsyncIterable<T>
): Promise<void> {
  let count = 0
  for await (const _ of stream) {
    if (++count >= n) break
  }
}

/**
 * Consume all values from a stream, discarding them.
 * Useful for ensuring a stream completes.
 */
export async function drain<T>(stream: AsyncIterable<T>): Promise<void> {
  for await (const _ of stream) { /* consume */ }
}

#+end_src

*** =spy=

Spy wrappers for observing stream behavior in tests.

#+begin_src typescript :tangle test-helpers.ts

/**
 * A record of events that occurred on a spied stream.
 */
export interface SpyEvent<T> {
  type: 'value' | 'complete' | 'error'
  value?: T
  error?: Error
  time: number
}

/**
 * A spy that records stream events for later assertion.
 */
export interface StreamSpy<T> {
  /** The wrapped stream to consume */
  stream: AsyncIterable<T>
  /** All recorded events */
  events: SpyEvent<T>[]
  /** Just the emitted values */
  values: T[]
  /** Whether the stream completed */
  completed: boolean
  /** The error if one occurred */
  error?: Error
  /** Wait for N values to be emitted */
  waitForN(n: number): Promise<T[]>
  /** Wait for completion */
  waitForComplete(): Promise<void>
}

/**
 * Wrap a stream with a spy to record all events.
 * 
 * @example
 * const spied = spy(myStream)
 * await collect(spied.stream)
 * expect(spied.values).toEqual([1, 2, 3])
 * expect(spied.completed).toBe(true)
 */
export function spy<T>(source: AsyncIterable<T>): StreamSpy<T> {
  const startTime = Date.now()
  const events: SpyEvent<T>[] = []
  const values: T[] = []
  let completed = false
  let error: Error | undefined
  let valueListeners: Array<{ count: number; resolve: (values: T[]) => void }> = []
  let completeListeners: Array<() => void> = []

  const stream: AsyncIterable<T> = {
    [Symbol.asyncIterator]() {
      const iterator = source[Symbol.asyncIterator]()
      return {
        async next(): Promise<IteratorResult<T>> {
          try {
            const result = await iterator.next()
            if (result.done) {
              completed = true
              events.push({ type: 'complete', time: Date.now() - startTime })
              completeListeners.forEach(l => l())
              return result
            }
            values.push(result.value)
            events.push({ type: 'value', value: result.value, time: Date.now() - startTime })
            checkValueListeners()
            return result
          } catch (e) {
            error = e as Error
            events.push({ type: 'error', error, time: Date.now() - startTime })
            throw e
          }
        }
      }
    }
  }

  function checkValueListeners() {
    valueListeners = valueListeners.filter(({ count, resolve }) => {
      if (values.length >= count) {
        resolve([...values])
        return false
      }
      return true
    })
  }

  return {
    stream,
    events,
    values,
    get completed() { return completed },
    get error() { return error },
    waitForN(n: number): Promise<T[]> {
      if (values.length >= n) return Promise.resolve([...values])
      return new Promise(resolve => {
        valueListeners.push({ count: n, resolve })
      })
    },
    waitForComplete(): Promise<void> {
      if (completed) return Promise.resolve()
      return new Promise(resolve => {
        completeListeners.push(resolve)
      })
    }
  }
}

#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('spy', () => {
  it('records stream events', async () => {
    const spied = spy(from([1, 2, 3]))
    await collect(spied.stream)
    
    expect(spied.values).toEqual([1, 2, 3])
    expect(spied.completed).toBe(true)
    expect(spied.events).toHaveLength(4) // 3 values + 1 complete
  })
})
#+end_src

*** =expectStream=

Fluent assertion helpers for testing stream behavior.

#+begin_src typescript :tangle test-helpers.ts

/**
 * Fluent assertion builder for streams.
 */
export interface StreamExpectation<T> {
  /** Assert the stream emits exactly these values */
  toEmit(expected: T[]): Promise<void>
  /** Assert the stream emits values matching a predicate */
  toEmitMatching(predicate: (values: T[]) => boolean): Promise<void>
  /** Assert the stream emits at least N values */
  toEmitAtLeast(n: number): Promise<T[]>
  /** Assert the stream completes */
  toComplete(): Promise<void>
  /** Assert the stream errors */
  toError(): Promise<Error>
  /** Assert the stream errors with a specific message */
  toErrorWith(message: string | RegExp): Promise<void>
  /** Assert the stream is empty */
  toBeEmpty(): Promise<void>
  /** Assert first N values match */
  firstN(n: number): StreamExpectation<T>
}

/**
 * Create fluent assertions for a stream.
 * 
 * @example
 * await expectStream(from([1, 2, 3])).toEmit([1, 2, 3])
 * await expectStream(empty()).toBeEmpty()
 * await expectStream(throwError(new Error('oops'))).toError()
 */
export function expectStream<T>(stream: AsyncIterable<T>): StreamExpectation<T> {
  let limit: number | undefined

  const createExpectation = (s: AsyncIterable<T>): StreamExpectation<T> => ({
    async toEmit(expected: T[]): Promise<void> {
      const actual = limit !== undefined 
        ? await collectN(limit, s)
        : await collect(s)
      if (!arraysEqual(actual, expected)) {
        throw new Error(
          `Expected stream to emit ${JSON.stringify(expected)}, but got ${JSON.stringify(actual)}`
        )
      }
    },

    async toEmitMatching(predicate: (values: T[]) => boolean): Promise<void> {
      const values = limit !== undefined
        ? await collectN(limit, s)
        : await collect(s)
      if (!predicate(values)) {
        throw new Error(
          `Stream values ${JSON.stringify(values)} did not match predicate`
        )
      }
    },

    async toEmitAtLeast(n: number): Promise<T[]> {
      const values = await collectN(n, s)
      if (values.length < n) {
        throw new Error(
          `Expected stream to emit at least ${n} values, but got ${values.length}`
        )
      }
      return values
    },

    async toComplete(): Promise<void> {
      await collect(s)
      // If we get here without error, stream completed
    },

    async toError(): Promise<Error> {
      try {
        await collect(s)
        throw new Error('Expected stream to error, but it completed')
      } catch (e) {
        return e as Error
      }
    },

    async toErrorWith(message: string | RegExp): Promise<void> {
      try {
        await collect(s)
        throw new Error('Expected stream to error, but it completed')
      } catch (e) {
        const error = e as Error
        const matches = typeof message === 'string'
          ? error.message === message
          : message.test(error.message)
        if (!matches) {
          throw new Error(
            `Expected error message to match ${message}, but got "${error.message}"`
          )
        }
      }
    },

    async toBeEmpty(): Promise<void> {
      const values = await collect(s)
      if (values.length > 0) {
        throw new Error(
          `Expected stream to be empty, but got ${JSON.stringify(values)}`
        )
      }
    },

    firstN(n: number): StreamExpectation<T> {
      limit = n
      return this
    }
  })

  return createExpectation(stream)
}

function arraysEqual<T>(a: T[], b: T[]): boolean {
  if (a.length !== b.length) return false
  return a.every((v, i) => v === b[i])
}

#+end_src

*** =createAsyncIterable=

Utility for quickly creating async iterables from arrays with optional delays.

#+begin_src typescript :tangle test-helpers.ts

/**
 * Options for creating an async iterable.
 */
export interface AsyncIterableOptions {
  /** Delay between emissions in milliseconds */
  delay?: number
  /** Delay before first emission */
  initialDelay?: number
}

/**
 * Create an async iterable from an array with optional timing.
 * 
 * @example
 * const stream = createAsyncIterable([1, 2, 3], { delay: 100 })
 * // Emits 1, then waits 100ms, emits 2, waits 100ms, emits 3
 */
export async function* createAsyncIterable<T>(
  values: T[],
  options: AsyncIterableOptions = {}
): AsyncGenerator<T, void, void> {
  const { delay: delayMs = 0, initialDelay = 0 } = options

  if (initialDelay > 0) {
    await new Promise(r => setTimeout(r, initialDelay))
  }

  for (let i = 0; i < values.length; i++) {
    yield values[i]
    if (delayMs > 0 && i < values.length - 1) {
      await new Promise(r => setTimeout(r, delayMs))
    }
  }
}

#+end_src

** Test File

The test file is assembled from all the =:noweb-ref tests= blocks scattered throughout this document.
This keeps tests close to the code they test while producing a single test file.

#+begin_src typescript :tangle index.test.ts :noweb yes
import { describe, it, expect } from 'vitest'
import {
  collect,
  collectN,
  collectWithTime,
  marble,
  TestStream,
  spy,
  expectStream,
  createAsyncIterable
} from './test-helpers'
import {
  just,
  from,
  fromPromise,
  fromEvent,
  periodic,
  empty,
  never,
  iterate,
  unfold,
  startWith,
  concat,
  pipe,
  map,
  constant,
  scan,
  tap,
  awaitTap,
  continueWith,
  concatAll,
  concatMap,
  filter,
  skipRepeats,
  skipRepeatsWith,
  take,
  skip,
  slice,
  takeWhile,
  skipWhile,
  takeUntil,
  delay,
  debounce,
  throttle,
  recoverWith,
  throwError,
  retry,
  merge,
  mergeAll,
  chain,
  flatMap,
  switchMap,
  latest,
  applyLatest,
  untilStream,
  sinceStream,
  buffer,
  bufferTime,
  window,
  eager,
  eagerNow,
  ReplaySubject,
  replay,
  share,
  replayFactory,
  replayStream
} from './index'

<<tests>>
#+end_src


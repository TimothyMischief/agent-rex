#+TITLE: Agent-Rex, An Async Generator/Iterator Based FRP-Like Library for JavaScript
#+AUTHOR: Timothy Hope

* Introduction

FRP in Javascript has a long history with libraries such as RxJS, Bacon.js, Most.js, Kefir.js and many others.
These libraries often use the Observable pattern to represent streams of data that can be observed and reacted to over time.
The ergonomic of these libraries can vary significantly, with some using method chaining and others using functional combinators.
Agent-Rex takes a different approach by leveraging async generators, which are a native feature of JavaScript, to provide a more intuitive and flexible way to work with streams of data.
(Most.js has a generator-based implementation, Agent-Rex just makes async generators first-class citizens.)

For example, async generator functions allow you to use `for await...of` loops to consume streams of data in a straightforward manner.

The library is designed to be lightweight and easy to use, while still providing powerful capabilities for composing and transforming streams of data.
The entire library is implemented and documented in this literate programming document.

** Why Streams?

Consider a common UI pattern: debouncing user input while fetching autocomplete suggestions.

*Imperative approach* (callbacks, state management, manual cleanup):

#+begin_src javascript :tangle no
let timeoutId = null;
let currentController = null;

inputElement.addEventListener('input', (e) => {
  // Cancel previous debounce
  if (timeoutId) clearTimeout(timeoutId);
  // Cancel in-flight request
  if (currentController) currentController.abort();
  
  timeoutId = setTimeout(async () => {
    currentController = new AbortController();
    try {
      const results = await fetch(`/api/search?q=${e.target.value}`, {
        signal: currentController.signal
      });
      displayResults(await results.json());
    } catch (err) {
      if (err.name !== 'AbortError') console.error(err);
    }
  }, 300);
});

// Don't forget cleanup on unmount!#+end_src

*Stream-based approach* (declarative, composable, automatic resource management):

#+begin_src javascript :tangle no
import { fromEvent, debounce, map, chain, take } from 'agent-rex';

const suggestions = pipe(
  fromEvent(inputElement, 'input'),
  debounce(300),
  map(e => e.target.value),
  chain(query => fromFetch(`/api/search?q=${query}`)),
);

for await (const results of suggestions) {
  displayResults(results);
}
#+end_src

The stream-based approach:
- *Declares intent* rather than managing state
- *Composes naturally* — add =filter=, =take=, or error handling without restructuring
- *Handles cleanup automatically* — breaking from the loop cancels pending operations
- *Is testable* — streams can be mocked with predictable timing

** Key Concepts

This section explains important concepts for working with async generator streams.

*** Backpressure

Async generators are *pull-based*: values are only produced when a consumer requests them via =.next()=.
This provides natural backpressure — if your consumer is slow, the producer automatically waits.

#+begin_src text :tangle no
Push-based (Observables):          Pull-based (Async Generators):

  Producer                           Producer
     │                                  │
     ▼ emit(1)                          │ (idle)
     ▼ emit(2)                          │
     ▼ emit(3)     ← Consumer           ▼ .next() ← Consumer ready
     ▼ emit(4)       overwhelmed!       │ yield 1
     ▼ emit(5)                          │ (waits for next pull)
     │                                  ▼ .next() ← Consumer ready
  Buffer overflow?                      │ yield 2
                                        │ ...#+end_src

This means you don't need explicit buffering strategies for slow consumers — the async iteration protocol handles it naturally.

** Cancellation

Async iterators support cancellation via the =return()= method.
When you =break= from a =for await...of= loop, JavaScript automatically calls =return()= on the iterator.

#+begin_src javascript :tangle no
// Cancellation happens automatically when breaking from a loop
for await (const value of someStream) {
  if (value > 100) break;  // Iterator's return() is called
}

// Manual cancellation
const iterator = someStream[Symbol.asyncIterator]();
await iterator.next();  // Get first value
await iterator.return();  // Cancel — cleanup runs#+end_src

For cleanup logic (closing connections, clearing timers), use =try/finally= in your generators:

#+begin_src javascript :tangle no
async function* resourceStream() {
  const connection = await openConnection();
  try {
    while (true) {
      yield await connection.read();
    }
  } finally {
    // Runs on normal completion OR cancellation
    await connection.close();
  }
}
#+end_src

*** Memory Considerations

*Unbounded buffering:* Be cautious with operators like =replay(Infinity, ...)= on long-running or infinite streams — they buffer all values in memory.

*Holding iterator references:* An async generator cannot be garbage collected while something holds a reference to its iterator.
If you create an iterator but never consume it, the generator function remains suspended indefinitely.

#+begin_src javascript :tangle no
// ⚠️ Potential memory leak
const iterator = infiniteStream[Symbol.asyncIterator]();
await iterator.next();  // Generator is now suspended
// If you forget about 'iterator', the generator stays in memory

// ✓ Always clean up when done
await iterator.return();  // Allows garbage collection
#+end_src

*Never-completing streams:* When merging or combining streams, remember that the combined stream won't complete until all source streams complete.
For streams that never complete (like =periodic= or event streams), use =take=, =takeUntil=, or =untilStream= to ensure termination.

** Under the Hood of Async Generators

You may be familiar with the syntactic sugarof async generators and have built or consumed them with functions like this:

#+begin_src javascript :tangle no
async function* asyncGenerator() {
  yield Promise.resolve(1);
  yield await Promise.resolve(2);
  yield 3;
}
const asyncGen = asyncGenerator();
asyncGen.next().then((res) => console.log(res.value)); // 1
asyncGen.next().then((res) => console.log(res.value)); // 2
asyncGen.next().then((res) => console.log(res.value)); // 3#+end_src

However, under the hood, async generators are built on top of Promises and iterators.
When you call an async generator function, it returns an async iterator object that conforms to the async iteration protocol.

#+begin_src typescript :tangle no
interface AsyncIterator<T> {
  next(value?: any): Promise<IteratorResult<T>>;
  return?(value?: any): Promise<IteratorResult<T>>;
  throw?(e?: any): Promise<IteratorResult<T>>;
}

interface IteratorResult<T> {
  done: boolean;
  value: T;
}
#+end_src

When a =for await...of= loop is used to consume an async generator, it repeatedly calls the =next()= method on the async iterator.
Each call to =next()= returns a Promise that resolves to an =IteratorResult= object.
The =value= property of this object contains the yielded value from the generator, and the =done= property indicates whether the generator has completed.
This mechanism allows async generators to produce values asynchronously, making them well-suited for representing streams of data that may arrive over time.
They are also lazy, meaning that values are only produced when requested, which can help with performance and resource management.

** Python: Async Generators and Async Iterators

Python's async generators and async iterators are conceptually similar to JavaScript's, but with some differences in syntax and behavior.
In Python, you define an async generator using the =async def= syntax and use =yield= to produce values:

*** Setup

We need to import necessary types and define some basic utilities for our Python implementation of Agent-Rex.
Python Generics need to be created with TypeVar, and we will use AsyncIterator and AsyncIterable for our stream types.

#+begin_src python :tangle python/agent_rex.py
"""
Agent-Rex: An Async Generator/Iterator Based FRP-Like Library for Python

This library provides composable async stream operators similar to RxJS/Most.js,
built on Python's native async generators.

Example:
  from agent_rex import just, map, filter, pipe, collect

  async def main():
    result = await collect(pipe(
      just(42),
      map(lambda x: x * 2),
    ))
    print(result) # [84]
"""

from __future__ import annotations

import asyncio
from typing import (
  TypeVar, AsyncIterator, AsyncIterable, Callable, Awaitable,
  Optional, Union, List, Tuple, Any, Generic, overload
)
from dataclasses import dataclass
from collections import deque

T = TypeVar('T')
U = TypeVar('U')
S = TypeVar('S')
E = TypeVar('E')
#+end_src

*** Test Setup

#+begin_src python :tangle python/test_agent_rex.py
"""Tests for the agent_rex library."""

import asyncio
from typing import TypeVar, AsyncIterable, List
import pytest

T = TypeVar('T')

from agent_rex import (
  # Creation
  just, of, from_promise, from_iter, periodic, empty, never,
  iterate, unfold, start_with, concat,
  # Composition
  pipe,
  # Transformation
  map, constant, scan, tap, await_tap, continue_with,
  concat_all, concat_map,
  # Filtering
  filter, skip_repeats, skip_repeats_with,
  # Slicing
  take, skip, slice, take_while, skip_while, take_until,
  # Time
  delay,
  # Error handling
  recover_with, throw_error, retry, RetryOptions,
  # Concurrent
  merge, merge_all, chain, flat_map, switch_map, latest,
  # Buffering
  buffer, eager,
  # Multicasting
  ReplaySubject, replay, share,
  # Types
  UnfoldResult
)
#+end_src

** Rust: Async Streams and Runtime Independence

Rust takes a different approach to async than JavaScript. In JavaScript, the runtime (the browser or Node.js) provides async facilities like timers and I/O automatically. In Rust, async is *runtime-agnostic* — the language provides the primitives (=Future=, =async/await=), but you choose the executor that runs your async code.

*** Futures and Streams in Rust

A =Future= in Rust is analogous to a JavaScript =Promise= — it represents a value that will be available later:

#+begin_src rust :tangle no
// JavaScript Promise
const promise: Promise<number> = fetchData();
const value = await promise;

// Rust Future
let future: impl Future<Output = i32> = fetch_data();
let value = future.await;#+end_src

A =Stream= in Rust is the async iterator equivalent — it yields multiple values over time:

#+begin_src rust :tangle no
// JavaScript AsyncIterator
for await (const value of asyncIterator) {
  console.log(value);
}

// Rust Stream (using futures crate)
use futures::StreamExt;
while let Some(value) = stream.next().await {
    println!("{}", value);
}
#+end_src

The =Stream= trait from the =futures= crate is defined as:

#+begin_src rust :tangle no
pub trait Stream {
  type Item;
  
  fn poll_next(
    self: Pin<&mut Self>,
    cx: &mut Context<'_>,
  ) -> Poll<Option<Self::Item>>;
}
#+end_src

While you can implement =Stream= manually, the =async-stream= crate provides a convenient macro:

#+begin_src rust :tangle no
use async_stream::stream;

fn my_stream() -> impl Stream<Item = i32> {
  stream! {
    for i in 0..3 {
      yield i;
    }
  }
}
#+end_src

*** Why Runtime Independence?

Different Rust async runtimes offer different tradeoffs:

| Runtime | Strengths | Best For |
|---------+-----------+----------|
| *tokio* | Most popular, feature-rich, great ecosystem | Production servers, general async |
| *async-std* | Mirrors std API, easy migration | Projects preferring familiar API |
| *smol* | Tiny, minimal dependencies | Embedded, libraries, small binaries |

Agent-Rex's Rust implementations are designed to work with *any* runtime by:

1. Using the =futures= crate for runtime-agnostic Stream utilities
2. Providing a =Runtime= trait for runtime-specific operations (timers, spawning)
3. Including built-in implementations for common runtimes

*** The Runtime Trait

Some operations require runtime-specific features. We abstract these behind a trait:

#+name: rust-setup
#+begin_src rust :tangle rust/src/lib.rs :noweb yes
<<lib-header>>

/// Runtime abstraction for async operations that need executor-specific features.
/// 
/// Most stream operations are runtime-agnostic and use only `futures` primitives.
/// This trait is needed only for:
/// - Time-based operations (delay, debounce, throttle)
/// - Spawning background tasks (multicasting, eager evaluation)
pub trait Runtime: Clone + Send + Sync + 'static {
  /// Sleep for the given duration
  fn sleep(duration: Duration) -> Pin<Box<dyn Future<Output = ()> + Send>>;
  
  /// Create an interval that yields at regular intervals
  fn interval(period: Duration) -> Pin<Box<dyn futures::Stream<Item = ()> + Send>>;
  
  /// Spawn a future as a background task
  fn spawn<F>(future: F)
  where
    F: Future<Output = ()> + Send + 'static;
}
#+end_src

*** Built-in Runtime Implementations

#+begin_src rust :tangle rust/src/lib.rs
// Tokio runtime (most common)
#[cfg(feature = "tokio-runtime")]
#[derive(Clone)]
pub struct TokioRuntime;

#[cfg(feature = "tokio-runtime")]
impl Runtime for TokioRuntime {
  fn sleep(duration: Duration) -> Pin<Box<dyn Future<Output = ()> + Send>> {
    Box::pin(tokio::time::sleep(duration))
  }
  
  fn interval(period: Duration) -> Pin<Box<dyn futures::Stream<Item = ()> + Send>> {
    use async_stream::stream;
    Box::pin(stream! {
      let mut interval = tokio::time::interval(period);
      loop {
        interval.tick().await;
        yield ();
      }
    })
  }
  
  fn spawn<F>(future: F)
  where
    F: Future<Output = ()> + Send + 'static,
  {
    tokio::spawn(future);
  }
}

// Smol runtime (lightweight)
#[cfg(feature = "smol-runtime")]
#[derive(Clone)]
pub struct SmolRuntime;

#[cfg(feature = "smol-runtime")]
impl Runtime for SmolRuntime {
  fn sleep(duration: Duration) -> Pin<Box<dyn Future<Output = ()> + Send>> {
    Box::pin(async_io::Timer::after(duration))
  }
  
  fn interval(period: Duration) -> Pin<Box<dyn futures::Stream<Item = ()> + Send>> {
    use async_stream::stream;
    Box::pin(stream! {
      loop {
        async_io::Timer::after(period).await;
        yield ();
      }
    })
  }
  
  fn spawn<F>(future: F)
  where
    F: Future<Output = ()> + Send + 'static,
  {
    smol::spawn(future).detach();
  }
}

// async-std runtime
#[cfg(feature = "async-std-runtime")]
#[derive(Clone)]
pub struct AsyncStdRuntime;

#[cfg(feature = "async-std-runtime")]
impl Runtime for AsyncStdRuntime {
  fn sleep(duration: Duration) -> Pin<Box<dyn Future<Output = ()> + Send>> {
    Box::pin(async_std::task::sleep(duration))
  }
  
  fn interval(period: Duration) -> Pin<Box<dyn futures::Stream<Item = ()> + Send>> {
    use async_stream::stream;
    Box::pin(stream! {
      loop {
        async_std::task::sleep(period).await;
        yield ();
      }
    })
  }
  
  fn spawn<F>(future: F)
  where
    F: Future<Output = ()> + Send + 'static,
  {
    async_std::task::spawn(future);
  }
}
#+end_src

*** Using the Library

Most operations don't need a runtime — they work with pure =futures= primitives:

#+begin_src rust :tangle no
use futures::StreamExt;

// These work with ANY runtime (or no runtime at all for testing)
let stream = just(42);
let doubled = map(stream, |x| x * 2);
let filtered = filter(doubled, |x| *x > 10);
let first_five = take(filtered, 5);

// Consume with any executor
while let Some(value) = first_five.next().await {
  println!("{}", value);
}
#+end_src

Only time-based and spawning operations need the runtime parameter:

#+begin_src rust :tangle no
// Time-based operations require a runtime
let delayed = delay::<TokioRuntime, _, _>(stream, Duration::from_millis(100));
let debounced = debounce::<TokioRuntime, _, _>(stream, Duration::from_millis(300));

// Multicasting requires spawning
let shared = replay::<TokioRuntime, _, _>(10, source);
#+end_src

* Creating a Stream

** =just=
The =just= function creates a stream that emits a single value and then completes.
Has the alias =of=.

*** When to Use

Use =just= when you need to lift a single value into the stream context, often for testing or as a starting point for composition.

#+begin_src text :tangle no
just(42):  42|
           ^  ^
           |  complete
           emit value#+end_src

#+begin_src javascript :tangle no
// Provide a default value when a stream might be empty
const withDefault = pipe(
  potentiallyEmptyStream,
  continueWith(() => just('default'))
)

// Start a chain of async operations
const result = pipe(
  just(userId),
  chain(id => fetchUser(id)),
  map(user => user.name)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits a single value and then completes.
 */
export async function* just<T>(
  value: T
): AsyncGenerator<T, void, void> {
  yield value
}

export const of = just
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('just', () => {
  it('emits a single value and completes', async () => {
    const values = await collect(just(42))
    expect(values).toEqual([42])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def just(value: T) -> AsyncIterator[T]:
  """Creates a stream that emits a single value and then completes."""
  yield value

# Alias for just
of = just
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestJust:
  async def test_emits_single_value(self):
    result = await collect(just(42))
    assert result == [42]
  async def test_of_is_alias(self):
    result = await collect(of("hello"))
    assert result == ["hello"]
#+end_src

*** Rust Implementation

In Rust, we use =async_stream= for ergonomic async generators with tokio:

#+begin_src rust :tangle rust/src/lib.rs
/// Create a stream that emits a single value.
pub fn just<T>(value: T) -> impl Stream<Item = T> {
  stream! { yield value; }
}

/// Alias for just
pub fn of<T: Clone>(value: T) -> impl Stream<Item = T> {
  just(value)
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)] 
mod just_tests {
  use super::*;
  #[tokio::test]
  async fn test_just_emits_single_value() {
    let stream = just(42);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![42]);
  }
  #[tokio::test]
  async fn test_just_with_string() {
    let stream = just("hello".to_string());
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec!["hello"]);
  }
  #[tokio::test]
  async fn test_of_alias() {
    let stream = of(99);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![99]);
  }
}
#+end_src

** =fromPromise=
The =fromPromise= function creates a stream from a Promise.
When the Promise resolves, the stream emits the resolved value and then completes.

*** When to Use

Use =fromPromise= to integrate Promise-based APIs into stream pipelines. The stream waits for the Promise to resolve, emits the value, then completes.

#+begin_src text :tangle no
fromPromise(fetch('/api/data')):

  ---(waiting)---data|
                 ^    ^
                 |    complete
                 resolved value#+end_src

#+begin_src javascript :tangle no
// Convert a fetch call to a stream
const userData = fromPromise(fetch('/api/user').then(r => r.json()))

// Use in a pipeline
const notifications = pipe(
  fromPromise(getNotifications()),
  chain(notifications => from(notifications)),
  filter(n => n.unread)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream from a Promise.
 * When the Promise resolves, the stream emits the resolved value and then completes.
 */
export async function* fromPromise<T>(promise: Promise<T>): AsyncGenerator<T, void, void> {
  const value = await promise
  yield value
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('fromPromise', () => {
  it('emits the resolved value', async () => {
    const values = await collect(fromPromise(Promise.resolve(42)))
    expect(values).toEqual([42])
  })

  it('waits for promise resolution', async () => {
    const delayed = new Promise<string>(r => setTimeout(() => r('delayed'), 10))
    const values = await collect(fromPromise(delayed))
    expect(values).toEqual(['delayed'])
  })

  it('propagates rejection as error', async () => {
    const failing = Promise.reject(new Error('fail'))
    await expect(collect(fromPromise(failing))).rejects.toThrow('fail')
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def from_future(awaitable: Awaitable[T]) -> AsyncIterator[T]:
  """Creates a stream from an awaitable (coroutine/Future).

  When the awaitable resolves, the stream emits the resolved value and completes.
  """
  value = await awaitable
  yield value

# Alias for API consistency with JavaScript
from_promise = from_future
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestFromPromise:
  async def test_emits_awaitable_result(self):
    async def get_value():
      return 99
    
    result = await collect(from_promise(get_value()))
    assert result == [99]
#+end_src

*** Rust Implementation

In Rust, futures are the equivalent of Promises:

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream from a Future.
/// When the Future resolves, the stream emits the value and completes.
pub fn from_future<T, F: Future<Output = T>>(future: F) -> impl Stream<Item = T> {
  stream! {
    let value = future.await;
    yield value;
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod from_future_tests {
  use super::*;
  #[tokio::test]
  async fn test_from_future_emits_resolved_value() {
    let future = async { 42 };
    let stream = from_future(future);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![42]);
  }
  #[tokio::test]
  async fn test_from_future_with_async_computation() {
    let future = async {
      tokio::time::sleep(std::time::Duration::from_millis(1)).await;
      "computed".to_string()
    };
    let stream = from_future(future);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec!["computed"]);
  }
}
#+end_src

** =from=
The =from= function creates a stream from an iterable or async iterable.
It emits each value from the iterable in sequence.

*** When to Use

Use =from= to convert arrays, Sets, Maps, or any iterable into an async stream. This is your primary tool for lifting collections into the stream world.

#+begin_src text :tangle no
from([1, 2, 3]):  1-2-3|
                  ^ ^ ^ ^
                  | | | complete
                  synchronous emissions#+end_src

#+begin_src javascript :tangle no
// Process array items through a pipeline
const processed = pipe(
  from([1, 2, 3, 4, 5]),
  filter(x => x % 2 === 0),
  map(x => x * 10)
)
// yields: 20, 40

// Convert a Set to a stream
const uniqueUsers = pipe(
  from(new Set(userIds)),
  chain(id => fetchUser(id))
)

// Process file lines
const lines = from(fileContent.split('\n'))
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream from an iterable or async iterable.
 * It emits each value from the iterable in sequence.
 */
export async function* from<T>(
  iterable: Iterable<T> | AsyncIterable<T>
): AsyncGenerator<T, void, void> {
  for await (const item of iterable) yield item
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('from', () => {
  it('emits all values from an array', async () => {
    const values = await collect(from([1, 2, 3]))
    expect(values).toEqual([1, 2, 3])
  })
  it('handles empty arrays', async () => {
    await expectStream(from([])).toBeEmpty()
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def from_iter(iterable: Union[AsyncIterable[T], list[T], tuple]) -> AsyncIterator[T]:
  """Creates a stream from an iterable or async iterable.

  Emits each value from the iterable in sequence.
  """
  if hasattr(iterable, '__aiter__'):
    async for item in iterable: yield item
  else:
    for item in iterable: yield item
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestFromIter:
  async def test_from_list(self):
    result = await collect(from_iter([1, 2, 3]))
    assert result == [1, 2, 3]
  async def test_from_tuple(self):
    result = await collect(from_iter((4, 5, 6)))
    assert result == [4, 5, 6]
  async def test_from_async_iterable(self):
    async def gen():
      for i in [7, 8, 9]:
        yield i
    result = await collect(from_iter(gen()))
    assert result == [7, 8, 9]
#+end_src

*** Rust Implementation

Rust uses =futures::stream::iter= for sync iterables. We re-export it as =from_iter= for API consistency:

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream from an iterator.
/// 
/// # Note
/// This is an alias for `futures::stream::iter`. Prefer using the built-in directly:
/// ```rust
/// use futures::stream;
/// let s = stream::iter(vec![1, 2, 3]);
/// ```
pub use futures::stream::iter as from_iter;
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod from_iter_tests {
  use super::*;
  #[tokio::test]
  async fn test_from_iter_emits_all_values() {
    let stream = from_iter(vec![1, 2, 3]);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }
  #[tokio::test]
  async fn test_from_iter_handles_empty() {
    let stream = from_iter(Vec::<i32>::new());
    let values: Vec<_> = stream.collect().await;
    assert!(values.is_empty());
  }
  #[tokio::test]
  async fn test_from_iter_with_range() {
    let stream = from_iter(0..5);
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![0, 1, 2, 3, 4]);
  }
}
#+end_src

** =periodic=
The =periodic= function creates a stream that emits at regular intervals.
To give it a value, combine it with =constant=.

*** When to Use

Use =periodic= to create a heartbeat or polling stream. Combine with =constant= to give it values, or use with =take= to limit iterations.

#+begin_src text :tangle no
periodic(100):  •---•---•---•---•---... (never ends)
                ^   ^   ^   ^
                |   100ms intervals
                emits undefined#+end_src

#+begin_src javascript :tangle no
// Poll an API every 5 seconds
const pollData = pipe(
  periodic(5000),
  chain(() => fromPromise(fetch('/api/status').then(r => r.json()))),
  take(100)  // Stop after 100 polls
)

// Emit a timestamp every second
const timestamps = pipe(
  periodic(1000),
  map(() => Date.now())
)

// Create a countdown timer
const countdown = pipe(
  periodic(1000),
  scan((n) => n - 1, 10),
  takeWhile(n => n >= 0)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits at regular intervals.
 * To give it a value, combine it with `constant`.
 */
export async function* periodic(intervalMs: number): AsyncGenerator<void, void, void> {
  while (true) {
    yield;
    await new Promise((resolve) => setTimeout(resolve, intervalMs));
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('periodic', () => {
  it('emits void values at intervals', async () => {
    const values = await collect(pipe(periodic(10), take(3)))
    expect(values).toEqual([undefined, undefined, undefined])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def periodic(interval_seconds: float) -> AsyncIterator[None]:
  """Creates a stream that emits at regular intervals. To give it a value, combine it with `constant`."""
  while True:
    yield None
    await asyncio.sleep(interval_seconds)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestPeriodic:
  async def test_emits_none_periodically(self):
    result = await collect(pipe(
      periodic(0.01),
      take(3)
    ))
    assert result == [None, None, None]
#+end_src

*** Rust Implementation

Uses the Runtime trait for timer functionality:

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream that emits () at regular intervals.
/// Uses the Runtime trait abstraction for timer support.
pub fn periodic<R: Runtime>(interval_ms: u64) -> impl Stream<Item = ()> {
  let interval_stream = R::interval(Duration::from_millis(interval_ms));
  stream! {
    futures::pin_mut!(interval_stream);
    loop {
      interval_stream.next().await;
      yield ();
    }
  }
}

// Runtime-agnostic alternative using async-io (works with smol, async-std)
// or any timer that implements Future<Output = ()>
pub fn periodic_with_timer<T, F>(
  interval_ms: u64,
  make_timer: impl Fn(Duration) -> F + Send + 'static,
) -> impl Stream<Item = ()>
where
  F: std::future::Future<Output = ()> + Send,
{
  stream! {
    let duration = Duration::from_millis(interval_ms);
    loop {
      make_timer(duration).await;
      yield ();
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod periodic_tests {
  // Note: periodic requires Runtime trait implementation
  // Tests would require a mock runtime or feature-flagged tokio runtime
  // For now, we verify compilation and document the API
  
  // Example with tokio (requires tokio-runtime feature):
  // #[tokio::test]
  // async fn test_periodic_emits_at_intervals() {
  //   let ticks: Vec<_> = periodic::<TokioRuntime>(100)
  //     .take(3)
  //     .collect()
  //     .await;
  //   assert_eq!(ticks.len(), 3);
  // }
}
#+end_src

** =empty=
The =empty= function creates a stream that immediately completes without emitting any values.

*** When to Use

Use =empty= when you need a stream that completes immediately without emitting values. Useful as a fallback or for conditional stream creation.

#+begin_src text :tangle no
empty():  |
          ^
          immediately complete#+end_src

#+begin_src javascript :tangle no
// Conditional stream based on feature flag
const notifications = featureEnabled
  ? fromEvent(eventSource, 'notification')
  : empty()

// Filter that might produce nothing
const adminActions = pipe(
  actions,
  filter(a => a.requiresAdmin),
  // If no admin actions, stream completes immediately
)

// Use as recovery fallback
const safeStream = pipe(
  riskyOperation,
  recoverWith(() => empty())  // Silently complete on error
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that immediately completes without emitting any values.
 */
export async function* empty(
): AsyncGenerator<never, void, void> {
  return
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('empty', () => {
  it('completes immediately without emitting', async () => {
    await expectStream(empty()).toBeEmpty()
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def empty() -> AsyncIterator[Any]:
  """Creates a stream that immediately completes without emitting any values."""
  return
  yield # Makes this a generator
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestEmpty:
  async def test_completes_immediately(self):
    result = await collect(empty())
    assert result == []
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream that immediately completes without emitting any values.
/// 
/// # Note
/// This is an alias for `futures::stream::empty`. Prefer using the built-in directly:
/// ```rust
/// use futures::stream;
/// let s: futures::stream::Empty<i32> = stream::empty();
/// ```
pub use futures::stream::empty;
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod empty_tests {
  use super::*;
  #[tokio::test]
  async fn test_empty_yields_nothing() {
    let values: Vec<i32> = empty::<i32>().collect().await;
    assert!(values.is_empty());
  }
  #[tokio::test]
  async fn test_empty_completes_immediately() {
    let stream = empty::<String>();
    futures::pin_mut!(stream);
    assert!(stream.next().await.is_none());
  }
}
#+end_src

** =never=
The =never= function creates a stream that never emits any values and never completes.

*** When to Use

Use =never= as a placeholder stream that blocks indefinitely. Useful for testing timeouts or as a "keep-alive" in merge operations.

#+begin_src text :tangle no
never():  --------... (never emits, never completes)
#+end_src

#+begin_src javascript :tangle no
// Test timeout behavior
const shouldTimeout = pipe(
  merge(never(), fromPromise(timeoutAfter(1000))),
  take(1)
)

// Keep a merge alive even if one stream completes
const combined = merge(
  eventStream,
  never()  // Prevents merge from completing when eventStream ends
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that never emits any values and never completes.
 * Useful for representing an infinite wait or as a placeholder.
 */
export async function* never(
): AsyncGenerator<never, void, void> {
  await new Promise(() => {})
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('never', () => {
  it('never emits or completes', async () => {
    // We can only test that it doesn't immediately complete
    let completed = false
    const gen = never()
    const timeout = setTimeout(() => {}, 50)
    
    // Race the never stream against a timeout
    const result = await Promise.race([
      gen.next().then(() => 'emitted'),
      new Promise<string>(r => setTimeout(() => r('timeout'), 20))
    ])
    clearTimeout(timeout)
    expect(result).toBe('timeout')
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def never() -> AsyncIterator[Any]:
  """Creates a stream that never emits any values and never completes."""
  await asyncio.Event().wait() # Wait forever
  yield # Unreachable, but makes this a generator
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream that never emits any values and never completes.
/// 
/// # Note
/// This is an alias for `futures::stream::pending`. Prefer using the built-in directly:
/// ```rust
/// use futures::stream;
/// let s: futures::stream::Pending<i32> = stream::pending();
/// ```
pub use futures::stream::pending as never;
#+end_src

**** Tests

/Note:/ These tests use real tokio time rather than the =TestRuntime= virtual scheduler.

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod never_tests {
  use super::*;
  use std::time::Duration;
  
  #[tokio::test]
  async fn test_never_does_not_complete() {
    // never() should not emit or complete
    // We test by racing with a timeout
    let never_stream = never::<i32>();
    futures::pin_mut!(never_stream);
    
    let timeout = tokio::time::sleep(Duration::from_millis(10));
    futures::pin_mut!(timeout);
    
    // Race: timeout should win
    let result = futures::future::select(never_stream.next(), timeout).await;
    match result {
      futures::future::Either::Right(_) => {} // Timeout won - correct!
      futures::future::Either::Left(_) => panic!("never() should not emit"),
    }
  }
}
#+end_src

** =iterate=

The =iterate= function creates a stream that emits an infinite sequence of values by repeatedly applying a function to a seed value.

*** When to Use

Use =iterate= to generate sequences where each value depends on the previous one. Always combine with limiting operators like =take= since it produces infinite streams.

#+begin_src text :tangle no
iterate(1, x => x * 2):

  1-2-4-8-16-32-... (infinite)
  ^ ^
  | fn(1) = 2
  seed#+end_src

#+begin_src javascript :tangle no
// Generate Fibonacci sequence
const fibonacci = pipe(
  iterate([0, 1], ([a, b]) => [b, a + b]),
  map(([a]) => a),
  take(10)
)
// yields: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34

// Generate exponential backoff delays
const backoffDelays = pipe(
  iterate(100, d => Math.min(d * 2, 30000)),
  take(10)
)
// yields: 100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600, 30000

// Walking through a linked list
const walkList = pipe(
  iterate(headNode, node => node.next),
  takeWhile(node => node !== null)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits an infinite sequence of values by repeatedly applying a function to a seed value.
 */
export async function* iterate<T>(seed: T, fn: (value: T) => T): AsyncGenerator<T, void, void> {
  let current = seed;
  while (true) {
    yield current
    current = fn(current)
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('iterate', () => {
  it('generates values by applying function repeatedly', async () => {
    const values = await collect(pipe(iterate(1, x => x * 2), take(5)))
    expect(values).toEqual([1, 2, 4, 8, 16])
  })

  it('starts with the seed value', async () => {
    const values = await collect(pipe(iterate(10, x => x + 1), take(3)))
    expect(values).toEqual([10, 11, 12])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def iterate(seed: T, fn: Callable[[T], T]) -> AsyncIterator[T]:
  """Creates a stream that emits an infinite sequence by repeatedly applying a function.

  Args:
    seed: Initial value to emit and feed into fn
    fn: Function applied to each value to produce the next
  """
  current = seed
  while True:
    yield current
    current = fn(current)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestIterate:
  async def test_generates_sequence(self):
    result = await collect(pipe(
      iterate(1, lambda x: x * 2),
      take(5)
    ))
    assert result == [1, 2, 4, 8, 16]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream that emits an infinite sequence by repeatedly applying a function.
pub fn iterate<T: Clone, F: Fn(T) -> T>(seed: T, f: F) -> impl Stream<Item = T> {
  stream! {
    let mut current = seed;
    loop {
      yield current.clone();
      current = f(current);
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod iterate_tests {
  use super::*;
  #[tokio::test]
  async fn test_iterate_generates_sequence() {
    let stream = iterate(1, |x| x * 2);
    let values: Vec<_> = stream.take(5).collect().await;
    assert_eq!(values, vec![1, 2, 4, 8, 16]);
  }
  #[tokio::test]
  async fn test_iterate_with_addition() {
    let stream = iterate(0, |x| x + 1);
    let values: Vec<_> = stream.take(4).collect().await;
    assert_eq!(values, vec![0, 1, 2, 3]);
  }
  #[tokio::test]
  async fn test_iterate_with_strings() {
    let stream = iterate("a".to_string(), |s| s.clone() + "a");
    let values: Vec<_> = stream.take(3).collect().await;
    assert_eq!(values, vec!["a", "aa", "aaa"]);
  }
}
#+end_src

** =unfold=

Like iterate but the function returns a tuple of ={ value: T, nextSeed: S, done: boolean }=.
The generator will emit =value= and use =nextSeed= for the next iteration.
If =done= is true, the generator will complete.
=value= is ignored when =done= is true.

*** When to Use

Use =unfold= when you need more control than =iterate= — specifically when the emitted value differs from the state, or when the sequence has a natural termination condition.

#+begin_src text :tangle no
unfold(1, n => ({ value: n, nextSeed: n+1, done: n > 3 })):

  1-2-3|
      ^
      done: true stops iteration#+end_src

#+begin_src javascript :tangle no
// Paginated API fetching (state = page cursor, value = items)
const allPages = unfold({ cursor: null, hasMore: true }, async ({ cursor }) => {
  const response = await fetch(`/api/items?cursor=${cursor || ''}`)
  const { items, nextCursor } = await response.json()
  return {
    value: items,
    nextSeed: { cursor: nextCursor, hasMore: !!nextCursor },
    done: !nextCursor
  }
})

// Range of numbers
const range = (start, end) => unfold(start, n => ({
  value: n,
  nextSeed: n + 1,
  done: n >= end
}))
// range(1, 5) yields: 1, 2, 3, 4

// Read lines from a buffer until empty
const lines = unfold(buffer, buf => {
  const newlineIdx = buf.indexOf('\n')
  if (newlineIdx === -1) return { value: '', nextSeed: '', done: buf.length === 0 }
  return {
    value: buf.slice(0, newlineIdx),
    nextSeed: buf.slice(newlineIdx + 1),
    done: false
  }
})
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits values by unfolding a seed value using a function.
 * The function returns an object containing the next value, the next seed, and a done flag
 * to indicate completion.
 */
export async function* unfold<T, S>(
  seed: S,
  fn: (seed: S) => { value: T; nextSeed: S; done: boolean }
): AsyncGenerator<T, void, void> {
  let currentSeed = seed;
  while (true) {
    const { value, nextSeed, done } = fn(currentSeed)
    if (done) return
    yield value
    currentSeed = nextSeed;
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('unfold', () => {
  it('generates values until done is true', async () => {
    const values = await collect(unfold(1, n => ({
      value: n,
      nextSeed: n + 1,
      done: n > 3
    })))
    expect(values).toEqual([1, 2, 3])
  })

  it('completes immediately if first call returns done', async () => {
    const values = await collect(unfold(0, () => ({
      value: 'ignored',
      nextSeed: 0,
      done: true
    })))
    expect(values).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@dataclass
class UnfoldResult(Generic[T, S]):
  """Result of an unfold step."""
  value: T
  next_seed: S
  done: bool


async def unfold(
  seed: S,
  fn: Callable[[S], UnfoldResult[T, S]]
) -> AsyncIterator[T]:
  """Creates a stream by unfolding a seed value. The function returns an object containing the next value, next seed, and done flag."""
  current_seed = seed
  while True:
    result = fn(current_seed)
    if result.done:
      return
    yield result.value
    current_seed = result.next_seed
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestUnfold:
  async def test_unfolds_until_done(self):
    result = await collect(unfold(
      1,
      lambda x: UnfoldResult(
        value=x,
        next_seed=x + 1,
        done=x > 3
      )
    ))
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

Rust's =futures::stream::unfold= provides this natively:

#+begin_src rust :tangle rust/src/lib.rs
pub struct UnfoldResult<T, S> {
  pub value: T,
  pub next_seed: S,
  pub done: bool,
}

/// Creates a stream by unfolding a seed value.
pub fn unfold<T, S: Clone, F>(seed: S, f: F) -> impl Stream<Item = T>
where
  F: Fn(S) -> UnfoldResult<T, S> + Clone + Send + 'static,
{
  let f = f.clone();
  futures::stream::unfold(seed, move |state| {
    let f = f.clone();
    async move {
      let result = f(state);
      if result.done {
        None
      } else {
        Some((result.value, result.next_seed))
      }
    }
  })
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod unfold_tests {
  use super::*;
  #[tokio::test]
  async fn test_unfold_generates_values() {
    let stream = unfold(1, |n| UnfoldResult {
      value: n,
      next_seed: n + 1,
      done: n > 3,
    });
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }

  #[tokio::test]
  async fn test_unfold_stops_immediately_when_done() {
    let stream = unfold(0, |_| UnfoldResult {
      value: 999,
      next_seed: 0,
      done: true,
    });
    let values: Vec<i32> = stream.collect().await;
    assert!(values.is_empty());
  }

  #[tokio::test]
  async fn test_unfold_with_different_types() {
    // State is i32, value is String
    let stream = unfold(0, |n| UnfoldResult {
      value: format!("item-{}", n),
      next_seed: n + 1,
      done: n >= 2,
    });
    let values: Vec<_> = stream.collect().await;
    assert_eq!(values, vec!["item-0", "item-1"]);
  }
}
#+end_src

** =startWith=

The =startWith= function prepends a value to the beginning of a stream.

*** When to Use

Use =startWith= to prepend an initial value to a stream. Common for providing defaults or initial state in reactive UIs.

#+begin_src text :tangle no
stream:              --1--2--3|
startWith(0):      0---1--2--3|
                   ^
                   prepended value#+end_src

#+begin_src javascript :tangle no
// Provide initial state for a UI component
const userState = pipe(
  userUpdates,
  startWith({ name: 'Loading...', avatar: null })
)

// Ensure a stream always has at least one value
const withDefault = pipe(
  searchResults,
  startWith([])  // Start with empty array
)

// Initialize a scan with a starting emission
const counter = pipe(
  buttonClicks,
  scan((count) => count + 1, 0),
  startWith(0)  // Emit initial count before any clicks
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Prepends a value to the beginning of a stream.
 */
export function startWith<T>(
  value: T
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function startWith<T>(
  value: T,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function startWith<T>(
  value: T,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => startWith(value, s);
  return (async function* () {
    yield value
    yield* stream
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('startWith', () => {
  it('prepends value to stream', async () => {
    const values = await collect(startWith(0, from([1, 2, 3])))
    expect(values).toEqual([0, 1, 2, 3])
  })

  it('works with empty stream', async () => {
    const values = await collect(startWith('first', empty()))
    expect(values).toEqual(['first'])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def start_with(value: T, stream: AsyncIterable[T]) -> AsyncIterator[T]:
  """Prepends a value to the beginning of a stream."""
  yield value
  async for item in stream:
    yield item
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestStartWith:
  async def test_prepends_value(self):
    result = await collect(start_with(0, from_iter([1, 2, 3])))
    assert result == [0, 1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Prepends a value to the beginning of a stream.
pub fn start_with<T: Clone, S: Stream<Item = T>>(value: T, s: S) -> impl Stream<Item = T> {
  stream! {
    yield value;
    futures::pin_mut!(s);
    while let Some(item) = s.next().await { yield item; }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod start_with_tests {
  use super::*;
  #[tokio::test]
  async fn test_start_with_prepends_value() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = start_with(0, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![0, 1, 2, 3]);
  }

  #[tokio::test]
  async fn test_start_with_on_empty_stream() {
    let source = stream::empty::<i32>();
    let result = start_with(42, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![42]);
  }
}
#+end_src

** =concat=

The =concat= function concatenates multiple streams into a single stream.

*** When to Use

Use =concat= to sequentially combine multiple streams. Each stream must complete before the next one starts — contrast with =merge= which interleaves concurrent streams.

#+begin_src text :tangle no
stream A:        1--2|
stream B:             3--4|
concat(A, B):    1--2--3--4|
                     ^
                     B starts after A completes#+end_src

#+begin_src javascript :tangle no
// Chain sequential operations
const fullSequence = concat(
  from(['Starting...']),
  processItems(items),
  from(['Done!'])
)

// Prioritized data sources (try cache, then network)
const data = pipe(
  concat(fromCache(key), fromNetwork(url)),
  take(1)  // Take first available
)

// Build up a playlist
const playlist = concat(
  from(introSongs),
  from(mainContent),
  from(outroSongs)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Concatenates multiple streams into a single stream.
 */
export async function* concat<T>(
  ...streams: AsyncIterable<T>[]
): AsyncGenerator<T, void, void> {
  for (const stream of streams) yield* stream
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('concat', () => {
  it('concatenates streams in order', async () => {
    const result = await collect(concat(from([1, 2]), from([3, 4])))
    expect(result).toEqual([1, 2, 3, 4])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def concat(*streams: AsyncIterable[T]) -> AsyncIterator[T]:
  """Concatenates multiple streams into a single stream."""
  for stream in streams:
    async for item in stream:
      yield item
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestConcat:
  async def test_concatenates_streams(self):
    result = await collect(concat(
      from_iter([1, 2]),
      from_iter([3, 4]),
      from_iter([5])
    ))
    assert result == [1, 2, 3, 4, 5]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Concatenates multiple streams into a single stream.
pub fn concat<T, S: Stream<Item = T>>(streams: Vec<S>) -> impl Stream<Item = T> {
  stream! {
    for s in streams {
      futures::pin_mut!(s);
      while let Some(item) = s.next().await { yield item; }
    }
  }
}

// For two streams specifically:
pub fn concat2<T, S1: Stream<Item = T>, S2: Stream<Item = T>>(s1: S1, s2: S2) -> impl Stream<Item = T> {
  stream! {
    futures::pin_mut!(s1);
    futures::pin_mut!(s2);
    while let Some(item) = s1.next().await { yield item; }
    while let Some(item) = s2.next().await { yield item; }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod concat_tests {
  use super::*;
  #[tokio::test]
  async fn test_concat_joins_streams() {
    let s1 = futures::stream::iter(vec![1, 2]);
    let s2 = futures::stream::iter(vec![3, 4]);
    let result = concat2(s1, s2);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![1, 2, 3, 4]);
  }

  #[tokio::test]
  async fn test_concat_with_empty_first() {
    let s1 = stream::empty::<i32>();
    let s2 = futures::stream::iter(vec![5, 6]);
    let result = concat2(s1, s2);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![5, 6]);
  }

  #[tokio::test]
  async fn test_concat_vec_of_streams() {
    let streams = vec![
      futures::stream::iter(vec![1]),
      futures::stream::iter(vec![2, 3]),
      futures::stream::iter(vec![4]),
    ];
    // Note: This requires streams to be Unpin, demonstration only
    // let result = concat(streams);
    // ...implementation varies
  }
}
#+end_src

** =fromEvent=

The =fromEvent= function creates a stream from DOM events or any EventTarget-like object.
The stream properly cleans up by removing the event listener when the iterator is closed.

*** When to Use

Use =fromEvent= to convert DOM or browser events into reactive streams. This enables composing events with other stream operators like =debounce=, =filter=, =map=, etc.

#+begin_src text :tangle no
clicks:           --x---x--x------x--|
eventTarget:      click events from DOM
fromEvent:        converts to async stream#+end_src

#+begin_src javascript :tangle no
// Basic usage
const clicks = fromEvent(button, 'click')

// With operators
const throttledClicks = pipe(
  fromEvent(button, 'click'),
  throttle(500),
  map(e => e.target.id)
)

// Cleanup on controller abort
const { signal, abort } = new AbortController()
const moves = fromEvent(window, 'mousemove', { signal })
// Call abort() to stop listening
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * An object that can add and remove event listeners.
 * Compatible with DOM EventTarget, Node.js EventEmitter, and similar.
 */
export interface EventTargetLike<E> {
  addEventListener(type: string, listener: (event: E) => void): void
  removeEventListener(type: string, listener: (event: E) => void): void
}

/**
 * Creates a stream from events on an EventTarget-like object.
 * The event listener is automatically removed when the stream is closed.
 * 
 * @example
 * const clicks = fromEvent(button, 'click')
 * for await (const event of clicks) {
 *   console.log('clicked!', event)
 * }
 */
export function fromEvent<E = Event>(
  target: EventTargetLike<E>,
  eventName: string
): AsyncIterable<E> {
  return {
    [Symbol.asyncIterator]() {
      const queue: E[] = []
      let resolve: ((result: IteratorResult<E>) => void) | null = null
      let done = false

      const listener = (event: E) => {
        if (resolve) {
          const r = resolve
          resolve = null
          r({ value: event, done: false })
        } else queue.push(event)
      }

      target.addEventListener(eventName, listener)

      return {
        async next(): Promise<IteratorResult<E>> {
          if (queue.length > 0) return { value: queue.shift()!, done: false }
          if (done) return { value: undefined as any, done: true }
          return new Promise(r => resolve = r)
        },
        async return(): Promise<IteratorResult<E>> {
          done = true
          target.removeEventListener(eventName, listener)
          if (resolve) {
            const r = resolve
            resolve = null
            r({ value: undefined as any, done: true })
          }
          return { value: undefined as any, done: true }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('fromEvent', () => {
  it('creates stream from event emitter', async () => {
    // Create a mock event target
    type Listener = (event: string) => void
    const listeners: Listener[] = []
    const mockTarget = {
      addEventListener(_type: string, listener: Listener) {
        listeners.push(listener)
      },
      removeEventListener(_type: string, listener: Listener) {
        const idx = listeners.indexOf(listener)
        if (idx >= 0) listeners.splice(idx, 1)
      },
      emit(event: string) {
        listeners.forEach(l => l(event))
      }
    }

    const events = fromEvent<string>(mockTarget, 'test')
    const iter = events[Symbol.asyncIterator]()

    // Emit some events
    mockTarget.emit('event1')
    mockTarget.emit('event2')

    const first = await iter.next()
    expect(first.value).toBe('event1')

    const second = await iter.next()
    expect(second.value).toBe('event2')

    // Cleanup
    await iter.return!()
    expect(listeners.length).toBe(0)
  })

  it('removes listener on return', async () => {
    let listenerCount = 0
    const mockTarget = {
      addEventListener() { listenerCount++ },
      removeEventListener() { listenerCount-- }
    }

    const events = fromEvent(mockTarget, 'test')
    const iter = events[Symbol.asyncIterator]()
    expect(listenerCount).toBe(1)

    await iter.return!()
    expect(listenerCount).toBe(0)
  })
})
#+end_src

*** TODO Python Implementation

#+begin_src python :tangle python/agent_rex.py

#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

In Rust, event-driven patterns use channels. We use =futures::channel= for runtime independence:

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream from a channel receiver.
/// The sender can be used to push events from event handlers.
/// 
/// This is runtime-agnostic and works with any async executor.
pub fn from_channel<T>(mut rx: mpsc::UnboundedReceiver<T>) -> impl Stream<Item = T> {
  stream! { while let Some(item) = rx.next().await { yield item; } }
}

/// Bounded variant for backpressure
pub fn from_bounded_channel<T>(mut rx: mpsc::Receiver<T>) -> impl Stream<Item = T> {
  stream! { while let Some(item) = rx.next().await { yield item; } }
}

// Example usage for event-like patterns:
// let (tx, rx) = mpsc::unbounded();
// let event_stream = from_channel(rx);
// 
// // In an event handler (can be sync since unbounded):
// tx.unbounded_send(event).unwrap();
//
// // Or with bounded channel for backpressure:
// let (mut tx, rx) = mpsc::channel(100);
// let event_stream = from_bounded_channel(rx);
// tx.send(event).await.unwrap();
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod channel_tests {
  // Note: from_channel requires Runtime trait for spawning
  // Channel-based stream creation is tested via integration tests
  // with specific runtime implementations
}
#+end_src

* Composing with =pipe=

All operators in Agent-Rex use a *data-last* signature: the stream is always the final argument.
Additionally, all operators support *automatic currying* via function overloads — you can call them with or without the stream argument:

#+begin_src javascript :tangle no
// Both forms work:
map(x => x * 2, stream)      // Direct call with all arguments
map(x => x * 2)(stream)      // Curried: returns a function awaiting the stream#+end_src

This enables clean, point-free composition using a =pipe= function:

#+begin_src javascript :tangle no
// With built-in currying, pipes read naturally:
const result = pipe(
  from([1, 2, 3, 4, 5]),
  filter(x => x % 2 === 0),
  map(x => x * 10),
  take(2),
);
// result: async generator yielding 20, 40
#+end_src

The =pipe= function composes left-to-right.
Using TypeScript 5.0+ recursive conditional types, we can achieve full type safety with an arbitrary number of functions:

#+begin_src typescript :tangle typescript/index.ts
/**
 * A unary function type for pipe composition.
 */
type Fn = (arg: any) => any

/**
 * Recursively validates that each function's input matches the previous function's output.
 * If a mismatch is found, the expected type is shown in the error position.
 * 
 * Uses `In extends Parameters<First>[0]` (not the reverse) because function parameters
 * are contravariant: we need to check if In can be assigned TO the function's parameter,
 * not whether the parameter type extends In. This ensures AsyncIterable<number> properly
 * satisfies AsyncIterable<unknown>.
 */
type ValidatePipeline<Fns extends Fn[], In> =
  Fns extends [infer First extends Fn, ...infer Rest extends Fn[]]
    ? In extends Parameters<First>[0]
      ? [First, ...ValidatePipeline<Rest, ReturnType<First>>]
      : [(arg: In) => ReturnType<First>, ...Rest]
    : []

/**
 * Computes the final return type by walking through the function chain.
 */
type PipeReturn<Fns extends Fn[], In> =
  Fns extends [infer First extends Fn, ...infer Rest extends Fn[]]
    ? PipeReturn<Rest, ReturnType<First>>
    : In

/**
 * Composes functions left-to-right, passing the result of each to the next.
 * The first argument is the initial value; subsequent arguments are unary functions.
 * 
 * Uses explicit overloads for 1-10 functions for reliable type inference.
 * Pipelines with 11+ functions fall back to recursive validation.
 * 
 * @example
 * const result = pipe(
 *   from([1, 2, 3, 4, 5]),
 *   filter(x => x % 2 === 0),
 *   map(x => x * 10),
 *   take(2),
 * );
 * // result: async generator yielding 20, 40
 */
export function pipe<A>(initial: A): A;
export function pipe<A, B>(initial: A, f1: (a: A) => B): B;
export function pipe<A, B, C>(initial: A, f1: (a: A) => B, f2: (b: B) => C): C;
export function pipe<A, B, C, D>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D): D;
export function pipe<A, B, C, D, E>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E): E;
export function pipe<A, B, C, D, E, F>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F): F;
export function pipe<A, B, C, D, E, F, G>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G): G;
export function pipe<A, B, C, D, E, F, G, H>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H): H;
export function pipe<A, B, C, D, E, F, G, H, I>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I): I;
export function pipe<A, B, C, D, E, F, G, H, I, J>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I, f9: (i: I) => J): J;
export function pipe<A, B, C, D, E, F, G, H, I, J, K>(initial: A, f1: (a: A) => B, f2: (b: B) => C, f3: (c: C) => D, f4: (d: D) => E, f5: (e: E) => F, f6: (f: F) => G, f7: (g: G) => H, f8: (h: H) => I, f9: (i: I) => J, f10: (j: J) => K): K;
export function pipe<A, Fns extends Fn[]>(initial: A, ...fns: Fns & ValidatePipeline<Fns, A>): PipeReturn<Fns, A>;
export function pipe(initial: unknown, ...fns: Fn[]): unknown {
  return fns.reduce((acc, fn) => fn(acc), initial)
}
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
def pipe(initial: T, *fns: Callable) -> Any:
  """Composes functions left-to-right, passing the result of each to the next.

  The first argument is the initial value; subsequent arguments are unary functions.

  Example:
    result = pipe(
      from_iter([1, 2, 3, 4, 5]),
      filter(lambda x: x % 2 == 0),
      map(lambda x: x * 10),
      take(2),
    )
  """
  from functools import reduce
  return reduce(lambda acc, fn: fn(acc), fns, initial)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestPipe:
  async def test_composes_operators(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]),
      filter(lambda x: x % 2 == 0),
      map(lambda x: x * 10),
      take(3),
    ))
    assert result == [20, 40, 60]

  async def test_complex_pipeline(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      concat_map(lambda x: from_iter([x, -x])),
      filter(lambda x: x > 0),
      scan(lambda acc, x: acc + x, 0),
    ))
    assert result == [0, 1, 3, 6]
#+end_src

*** Rust Implementation

In Rust, method chaining with trait extension patterns is idiomatic.
The =StreamExt= trait from =futures= provides chainable methods on any Stream:

#+begin_src rust :tangle rust/src/lib.rs
// Rust uses method chaining instead of pipe:
// let result = futures::stream::iter([1, 2, 3, 4, 5])
//     .filter(|x| futures::future::ready(x % 2 == 0))
//     .map(|x| x * 10)
//     .take(2);

// For a pipe-like macro if desired:
macro_rules! pipe {
    ($initial:expr $(, $fn:expr)*) => {{
        let mut result = $initial;
        $(result = $fn(result);)*
        result
    }};
}

// Usage:
// let stream = pipe!(
//     futures::stream::iter(vec![1, 2, 3]),
//     |s| s.map(|x| x * 2),
//     |s| s.take(2)
// );
#+end_src

** Currying Implementation Pattern

Each operator uses TypeScript function overloads to support both curried and uncurried calls.
Here's the pattern (using =map= as an example):

#+begin_src typescript :tangle no
// Overload 1: Curried (no stream) — returns a function
export function map<T, U>(
  fn: (value: T) => U
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;

// Overload 2: Uncurried (with stream) — returns the generator directly  
export function map<T, U>(
  fn: (value: T) => U,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;

// Implementation: checks if stream is provided
export function map<T, U>(
  fn: (value: T) => U,
  stream?: AsyncIterable<T>,
) {
  if (stream === undefined) return (s) => map(fn, s);  // Return curried
  return (async function* () { /* ... */ })();         // Return generator
}
#+end_src

* Transformations

** =map=

The =map= function transforms each value emitted by a stream using a provided function.
Supports both curried and uncurried calling conventions.

*** When to Use

Use =map= to transform each value in a stream. This is the workhorse operator for data transformation — extract fields, compute derived values, or convert types.

#+begin_src text :tangle no
stream:          --1---2---3--|
map(x => x*10): --10--20--30-|
                  ^   ^   ^
                  transform each value#+end_src

#+begin_src javascript :tangle no
// Extract a field from objects
const userNames = pipe(
  userStream,
  map(user => user.name)
)

// Async transformation (awaited automatically)
const enrichedData = pipe(
  ids,
  map(async id => {
    const details = await fetchDetails(id)
    return { id, ...details }
  })
)

// Parse incoming messages
const parsedMessages = pipe(
  rawMessages,
  map(msg => JSON.parse(msg))
)
#+end_src

*** Typescript Implementation


#+begin_src typescript :tangle typescript/index.ts
/**
 * Transforms each value emitted by a stream using a provided function.
 */
export function map<T, U>(
  fn: (value: T) => U | Promise<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function map<T, U>(
  fn: (value: T) => U | Promise<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function map<T, U>(
  fn: (value: T) => U | Promise<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => map(fn, s);
  return (async function* () {
    for await (const item of stream) yield await fn(item);
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('map', () => {
  it('transforms each value', async () => {
    const result = await collect(map(x => x * 2, from([1, 2, 3])))
    expect(result).toEqual([2, 4, 6])
  })

  it('handles async mappers', async () => {
    const result = await collect(
      map(async x => x * 2, from([1, 2, 3]))
    )
    expect(result).toEqual([2, 4, 6])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def map(fn: Callable[[T], Union[U, Awaitable[U]]]) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def map(fn: Callable[[T], Union[U, Awaitable[U]]], stream: AsyncIterable[T]) -> AsyncIterator[U]: ...

def map(fn: Callable[[T], Union[U, Awaitable[U]]], stream: Optional[AsyncIterable[T]] = None):
  """Transforms each value emitted by a stream using a provided function."""
  async def _map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async for item in s:
      result = fn(item)
      if asyncio.iscoroutine(result):
        yield await result
      else:
        yield result # type: ignore

  if stream is None:
    return _map
  return _map(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestMap:
  async def test_transforms_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      map(lambda x: x * 10)
    ))
    assert result == [10, 20, 30]

  async def test_async_transform(self):
    async def async_transform(x):
      await asyncio.sleep(0)
      return x * 2
    
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      map(async_transform)
    ))
    assert result == [2, 4, 6]
#+end_src

*** Rust Implementation

=StreamExt::map= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
/// Maps each value in a stream using a function.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::map()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.map(|x| x * 2);
/// ```
/// For async mappers, use `StreamExt::then()`:
/// ```rust,ignore
/// let result = stream.then(|x| async move { x * 2 });
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn map<T, U, S, F>(s: S, f: F) -> impl Stream<Item = U>
where
  S: Stream<Item = T>,
  F: Fn(T) -> U,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await { yield f(item); }
  }
}
#+end_src

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod map_tests {
  use super::*;
  #[tokio::test]
  async fn test_map_transforms_values() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = map(source, |x| x * 2);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![2, 4, 6]);
  }

  #[tokio::test]
  async fn test_map_with_type_change() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = map(source, |x| format!("num-{}", x));
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec!["num-1", "num-2", "num-3"]);
  }

  #[tokio::test]
  async fn test_map_empty_stream() {
    let source = stream::empty::<i32>();
    let result = map(source, |x| x * 2);
    let values: Vec<_> = result.collect().await;
    assert!(values.is_empty());
  }
}
#+end_src

** =constant=

The =constant= function creates a stream that emits a constant value for each item in the source stream.

*** When to Use

Use =constant= to replace all stream values with a fixed value. Often combined with =periodic= to create a stream of repeated values, or used to signal events without caring about the event data.

#+begin_src text :tangle no
stream:            --a--b--c--|
constant('x'):     --x--x--x--|
                     ^  ^
                     all values become 'x'#+end_src

#+begin_src javascript :tangle no
// Turn a timer into a constant signal
const heartbeat = pipe(
  periodic(1000),
  constant('ping')
)
// yields: 'ping', 'ping', 'ping', ...

// Count events (ignore event data, just count)
const clickCount = pipe(
  fromEvent(button, 'click'),
  constant(1),
  scan((count, one) => count + one, 0)
)

// Signal that "something happened" without details
const refreshSignal = pipe(
  merge(userAction, timerTick, networkReconnect),
  constant('refresh')
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits a constant value for each item in the source stream.
 */
export function constant<U>(
  value: U
): (stream: AsyncIterable<any>) => AsyncGenerator<U, void, void>;
export function constant<U>(
  value: U,
  stream: AsyncIterable<any>
): AsyncGenerator<U, void, void>;
export function constant<U>(
  value: U,
  stream?: AsyncIterable<any>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<any>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<any>) => constant(value, s);
  return (async function* () {
    for await (const _ of stream) yield value
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('constant', () => {
  it('replaces each value with the constant', async () => {
    const values = await collect(constant('x', from([1, 2, 3])))
    expect(values).toEqual(['x', 'x', 'x'])
  })

  it('emits nothing for empty stream', async () => {
    const values = await collect(constant('x', empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def constant(value: U) -> Callable[[AsyncIterable[Any]], AsyncIterator[U]]: ...
@overload
def constant(value: U, stream: AsyncIterable[Any]) -> AsyncIterator[U]: ...

def constant(value: U, stream: Optional[AsyncIterable[Any]] = None):
  """Creates a stream that emits a constant value for each item in the source stream."""
  async def _constant(s: AsyncIterable[Any]) -> AsyncIterator[U]:
    async for _ in s:
      yield value

  if stream is None:
    return _constant
  return _constant(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestConstant:
  async def test_replaces_with_constant(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      constant("x")
    ))
    assert result == ["x", "x", "x"]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Map to a constant value.
/// stream.map(|_| constant_value.clone())

pub fn constant<T, U: Clone, S: Stream<Item = T>>(value: U, s: S) -> impl Stream<Item = U> {
  stream! {
    futures::pin_mut!(s);
    while let Some(_) = s.next().await { yield value.clone(); }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod constant_tests {
  use super::*;
  #[tokio::test]
  async fn test_constant_replaces_all_values() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = constant("x", source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec!["x", "x", "x"]);
  }

  #[tokio::test]
  async fn test_constant_empty_stream() {
    let source = stream::empty::<i32>();
    let result = constant(42, source);
    let values: Vec<_> = result.collect().await;
    assert!(values.is_empty());
  }
}
#+end_src

** =scan=

The =scan= function accumulates values from a stream using a provided accumulator function and an initial seed value.
Yields the seed first, then each accumulated value.

*** When to Use

Use =scan= to accumulate state over time, emitting each intermediate result. Unlike =reduce= in arrays (which only returns the final value), =scan= emits after every input.

#+begin_src text :tangle no
stream:                  --1--2--3--|
scan((a,x) => a+x, 0):  0--1--3--6--|
                        ^  ^  ^  ^
                        |  |  |  1+2+3
                        |  |  1+2
                        |  0+1
                        seed#+end_src

#+begin_src javascript :tangle no
// Running total
const runningTotal = pipe(
  purchases,
  map(p => p.amount),
  scan((total, amount) => total + amount, 0)
)

// Collect items into an array
const allItems = pipe(
  itemStream,
  scan((arr, item) => [...arr, item], [])
)

// Track min/max/average
const stats = pipe(
  measurements,
  scan((stats, value) => ({
    min: Math.min(stats.min, value),
    max: Math.max(stats.max, value),
    sum: stats.sum + value,
    count: stats.count + 1,
    avg: (stats.sum + value) / (stats.count + 1)
  }), { min: Infinity, max: -Infinity, sum: 0, count: 0, avg: 0 })
)

// Undo/redo history
const history = pipe(
  actions,
  scan((states, action) => [...states, applyAction(states.at(-1), action)], [initialState])
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Accumulates values from a stream using a provided accumulator function and an initial seed value.
 */
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function scan<T, U>(
  accumulator: (acc: U, value: T) => U | Promise<U>,
  seed: U,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => scan(accumulator, seed, s);
  return (async function* () {
    let acc = seed
    yield acc
    for await (const item of stream) yield acc = await accumulator(acc, item)
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('scan', () => {
  it('accumulates values starting with seed', async () => {
    const result = await collect(scan((acc, x) => acc + x, 0, from([1, 2, 3])))
    expect(result).toEqual([0, 1, 3, 6])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U,
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U,
  stream: Optional[AsyncIterable[T]] = None
):
  """Accumulates values using an accumulator function, emitting each intermediate result. Yields the seed first, then each accumulated value."""
  async def _scan(s: AsyncIterable[T]) -> AsyncIterator[U]:
    acc = seed
    yield acc
    async for item in s:
      result = accumulator(acc, item)
      if asyncio.iscoroutine(result):
        acc = await result
      else:
        acc = result # type: ignore
      yield acc

  if stream is None:
    return _scan
  return _scan(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestScan:
  async def test_accumulates_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      scan(lambda acc, x: acc + x, 0)
    ))
    assert result == [0, 1, 3, 6]
#+end_src

*** Rust Implementation

=StreamExt::scan= is available, but note it doesn't emit the seed first by default:

#+begin_src rust :tangle rust/src/lib.rs
/// Scan with seed emission first (matching JS behavior).
pub fn scan<T, U: Clone, S, F>(accumulator: F, seed: U, s: S) -> impl Stream<Item = U>
where
  S: Stream<Item = T>,
  F: Fn(U, T) -> U,
{
  stream! {
    let mut acc = seed.clone();
    yield acc.clone();
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      acc = accumulator(acc, item);
      yield acc.clone();
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod scan_tests {
  use super::*;
  #[tokio::test]
  async fn test_scan_accumulates_with_seed() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = scan(|acc, x| acc + x, 0, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![0, 1, 3, 6]);
  }

  #[tokio::test]
  async fn test_scan_product() {
    let source = futures::stream::iter(vec![2, 3, 4]);
    let result = scan(|acc, x| acc * x, 1, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![1, 2, 6, 24]);
  }

  #[tokio::test]
  async fn test_scan_empty_stream() {
    let source = stream::empty::<i32>();
    let result = scan(|acc, x| acc + x, 100, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![100]); // Only seed
  }
}
#+end_src

** =tap=

The =tap= function allows you to perform side effects for each value emitted by a stream without modifying the values themselves.
The side effect is fired without awaiting, so it does not block the stream processing.

*** When to Use

Use =tap= for side effects that shouldn't block the stream: logging, analytics, non-critical updates. The side effect fires without waiting, so fast streams won't be slowed down by slow side effects.

#+begin_src text :tangle no
stream:          --1---2---3--|
tap(console.log):-1---2---3--|
                  ^
                  side effect fires, value passes through unchanged#+end_src

#+begin_src javascript :tangle no
// Logging for debugging
const debugged = pipe(
  dataStream,
  tap(x => console.log('Processing:', x)),
  map(transform),
  tap(x => console.log('Transformed:', x))
)

// Analytics tracking (fire-and-forget)
const tracked = pipe(
  userActions,
  tap(action => analytics.track(action.type)),
  filter(action => action.important)
)

// Update UI progressively (non-blocking)
const withProgress = pipe(
  largeDataset,
  tap((_, i) => updateProgressBar(i)),
  map(processItem)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Performs side effects for each value emitted by a stream without modifying the values themselves.
 * The side effect is fired without awaiting, so it does not block the stream processing.
 */
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function tap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => tap(sideEffectFn, s);
  return (async function* () {
    for await (const item of stream) {
      sideEffectFn(item)
      yield item
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('tap', () => {
  it('performs side effect without modifying values', async () => {
    const sideEffects: number[] = []
    const values = await collect(tap(x => { sideEffects.push(x) }, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
    expect(sideEffects).toEqual([1, 2, 3])
  })

  it('does not await async side effects', async () => {
    const order: string[] = []
    const values = await collect(tap(async x => {
      await new Promise(r => setTimeout(r, 10))
      order.push(`effect-${x}`)
    }, from([1, 2])))
    order.push('done')
    expect(values).toEqual([1, 2])
    // 'done' should appear before effects complete since tap doesn't await
    expect(order[0]).toBe('done')
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def tap(fn: Callable[[T], Any]) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def tap(fn: Callable[[T], Any], stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def tap(fn: Callable[[T], Any], stream: Optional[AsyncIterable[T]] = None):
  """Performs side effects for each value without modifying them.

  The side effect is fired without awaiting.
  """
  async def _tap(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      fn(item) # Fire and forget
      yield item

  if stream is None:
    return _tap
  return _tap(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestTap:
  async def test_performs_side_effect(self):
    side_effects = []
    
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      tap(lambda x: side_effects.append(x))
    ))
    
    assert result == [1, 2, 3]
    assert side_effects == [1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Perform side effects for each value without modifying them.
/// Runtime-agnostic - side effects are synchronous.
pub fn tap<T: Clone, S, F>(side_effect: F, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  F: Fn(&T),
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      side_effect(&item);
      yield item;
    }
  }
}

/// For fire-and-forget async side effects using the Runtime trait.
pub fn tap_spawn<R, T, S, F, Fut>(
  side_effect: F,
  s: S,
) -> impl Stream<Item = T>
where
  R: Runtime,
  T: Clone + Send + 'static,
  S: Stream<Item = T>,
  F: Fn(T) -> Fut + Clone + Send + 'static,
  Fut: std::future::Future<Output = ()> + Send + 'static,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      let f = side_effect.clone();
      let item_clone = item.clone();
      R::spawn(async move { f(item_clone).await });
      yield item;
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod tap_runtime_tests {
  // Note: tap with Runtime requires specific runtime implementation
  // See tap tests for basic tap functionality
  // Runtime-based tap spawns side effects concurrently
}
#+end_src

** =awaitTap=

The =awaitTap= function is like =tap=, but awaits the side effect before yielding the value.
Use this when the side effect must complete before processing continues.

*** When to Use

Use =awaitTap= when the side effect must complete before the value proceeds. This adds backpressure — the stream waits for each side effect to finish.

#+begin_src text :tangle no
stream:                --1------2------3--|
awaitTap(save, 50ms): --1------2------3--|  (each value delayed by save time)
                        ^ wait ^ wait ^#+end_src

#+begin_src javascript :tangle no
// Ensure each item is saved before processing next
const savedItems = pipe(
  itemStream,
  awaitTap(item => database.save(item)),
  map(item => ({ ...item, saved: true }))
)

// Rate-limited API calls (wait for each to complete)
const apiResults = pipe(
  requests,
  awaitTap(req => rateLimiter.acquire()),
  map(req => fetch(req.url))
)

// Sequential file writes (one at a time)
const written = pipe(
  files,
  awaitTap(file => fs.writeFile(file.path, file.content))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Performs side effects for each value emitted by a stream, awaiting completion before yielding.
 * Use this when the side effect must complete before processing continues.
 */
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function awaitTap<T>(
  sideEffectFn: (value: T) => void | Promise<void>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => awaitTap(sideEffectFn, s);
  return (async function* () {
    for await (const item of stream) {
      await sideEffectFn(item)
      yield item
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('awaitTap', () => {
  it('awaits side effect before yielding', async () => {
    const order: string[] = []
    const values = await collect(awaitTap(async x => {
      await new Promise(r => setTimeout(r, 5))
      order.push(`effect-${x}`)
    }, from([1, 2])))
    order.push('done')
    expect(values).toEqual([1, 2])
    // Effects should complete before 'done' since awaitTap awaits
    expect(order).toEqual(['effect-1', 'effect-2', 'done'])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def await_tap(fn: Callable[[T], Awaitable[Any]]) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def await_tap(fn: Callable[[T], Awaitable[Any]], stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def await_tap(fn: Callable[[T], Awaitable[Any]], stream: Optional[AsyncIterable[T]] = None):
  """Performs side effects for each value, awaiting completion before yielding."""
  async def _await_tap(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      await fn(item)
      yield item

  if stream is None:
    return _await_tap
  return _await_tap(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Await side effects before yielding values.
pub fn await_tap<T: Clone, S, F, Fut>(side_effect: F, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  F: Fn(T) -> Fut,
  Fut: Future<Output = ()>,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      side_effect(item.clone()).await;
      yield item;
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod await_tap_tests {
  use super::*;
  use std::sync::atomic::{AtomicUsize, Ordering};
  use std::sync::Arc;
  
  #[tokio::test]
  async fn test_await_tap_executes_side_effect() {
    let count = Arc::new(AtomicUsize::new(0));
    let count_clone = count.clone();
    
    let source = futures::stream::iter(vec![1, 2, 3]);
    let tapped = await_tap(
      move |_: i32| {
        let c = count_clone.clone();
        async move { c.fetch_add(1, Ordering::SeqCst); }
      },
      source,
    );
    
    let values: Vec<_> = tapped.collect().await;
    assert_eq!(values, vec![1, 2, 3]);
    assert_eq!(count.load(Ordering::SeqCst), 3);
  }
}
#+end_src

** =continueWith=

The =continueWith= function allows you to continue a stream with another stream once the first one completes.
The first argument =f=, must be a function that returns the continuation stream.

*** When to Use

Use =continueWith= to append a lazily-created stream after the first completes. The continuation function is only called when needed, unlike =concat= which takes streams directly.

#+begin_src text :tangle no
stream:                    --1--2--|
continueWith(() => B):     --1--2--3--4--|
                                  ^
                                  B() called here#+end_src

#+begin_src javascript :tangle no
// Provide fallback data when stream is empty
const withFallback = pipe(
  primarySource,
  continueWith(() => from(fallbackData))
)

// Retry pattern: on failure, try alternative
const resilient = pipe(
  primaryApi,
  recoverWith(() => continueWith(() => backupApi, empty()))
)

// Lazy infinite stream (only created if first stream ends)
const extendable = pipe(
  finiteData,
  continueWith(() => generateMore())
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Continues a stream with another stream once the first one completes.
 */
export function continueWith<T>(
  f: () => AsyncIterable<T>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function continueWith<T>(
  f: () => AsyncIterable<T>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function continueWith<T>(
  f: () => AsyncIterable<T>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => continueWith(f, s);
  return (async function* () {
    yield* stream
    yield* f()
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('continueWith', () => {
  it('continues with another stream after first completes', async () => {
    const values = await collect(continueWith(
      () => from([4, 5]),
      from([1, 2, 3])
    ))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('calls continuation function only after first stream completes', async () => {
    let called = false
    const values = await collect(continueWith(
      () => { called = true; return from([99]) },
      from([1])
    ))
    expect(called).toBe(true)
    expect(values).toEqual([1, 99])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def continue_with(
  f: Callable[[], AsyncIterable[T]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def continue_with(
  f: Callable[[], AsyncIterable[T]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def continue_with(
  f: Callable[[], AsyncIterable[T]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Continues a stream with another stream once the first completes."""
  async def _continue_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      yield item
    async for item in f():
      yield item

  if stream is None:
    return _continue_with
  return _continue_with(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestContinueWith:
  async def test_continues_with_stream(self):
    result = await collect(pipe(
      from_iter([1, 2]),
      continue_with(lambda: from_iter([3, 4]))
    ))
    assert result == [1, 2, 3, 4]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Continue with another stream after the first completes.
pub fn continue_with<T, S1, S2, F>(f: F, s: S1) -> impl Stream<Item = T>
where
  S1: Stream<Item = T>,
  S2: Stream<Item = T>,
  F: FnOnce() -> S2,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await { yield item; }
    let s2 = f();
    futures::pin_mut!(s2);
    while let Some(item) = s2.next().await { yield item; }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod continue_with_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_continue_with_appends() {
    let first = futures::stream::iter(vec![1, 2]);
    let second = || futures::stream::iter(vec![3, 4]);
    
    let values: Vec<_> = continue_with(second, first).collect().await;
    assert_eq!(values, vec![1, 2, 3, 4]);
  }
  
  #[tokio::test]
  async fn test_continue_with_lazy() {
    use std::sync::atomic::{AtomicBool, Ordering};
    use std::sync::Arc;
    
    let called = Arc::new(AtomicBool::new(false));
    let called_clone = called.clone();
    
    let first = futures::stream::iter(vec![1]);
    let second = move || {
      called_clone.store(true, Ordering::SeqCst);
      futures::stream::iter(vec![2])
    };
    
    let mut stream = continue_with(second, first);
    futures::pin_mut!(stream);
    
    // First value - continuation not called yet
    assert_eq!(stream.next().await, Some(1));
    // Now it should be called
    assert_eq!(stream.next().await, Some(2));
    assert!(called.load(Ordering::SeqCst));
  }
}
#+end_src

** =concatAll=

The =concatAll= function flattens a stream of streams by concatenating them into a single stream.

*** When to Use

Use =concatAll= to flatten a stream of streams sequentially. Each inner stream must complete before the next one starts. Contrast with =mergeAll= which processes inner streams concurrently.

#+begin_src text :tangle no
outer:       --[A]----[B]-----|
A:             1-2|
B:                    3-4-5|
concatAll:   --1-2----3-4-5--|
                 ^
                 B waits for A to complete#+end_src

#+begin_src javascript :tangle no
// Process file chunks in order
const allChunks = pipe(
  fileStreams,  // Stream of streams, one per file
  concatAll     // Flatten while preserving order
)

// Sequential API pagination
const allPages = pipe(
  pageStreams,  // Each page is a stream of items
  concatAll     // Items from page 1, then page 2, etc.
)

// Alternative to concatMap (manual version)
const flattened = pipe(
  items,
  map(item => from(item.children)),
  concatAll
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Flattens a stream of streams by concatenating them into a single stream.
 */
export async function* concatAll<T>(
  streamOfStreams: AsyncIterable<AsyncIterable<T>>,
): AsyncGenerator<T, void, void> {
  for await (const stream of streamOfStreams) yield* stream
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('concatAll', () => {
  it('flattens stream of streams in order', async () => {
    const streams = from([from([1, 2]), from([3, 4]), from([5])])
    const values = await collect(concatAll(streams))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('handles empty outer stream', async () => {
    const values = await collect(concatAll(empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def concat_all(stream_of_streams: AsyncIterable[AsyncIterable[T]]) -> AsyncIterator[T]:
  """Flattens a stream of streams by concatenating them into a single stream."""
  async for stream in stream_of_streams:
    async for item in stream:
      yield item
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestConcatAll:
  async def test_flattens_stream_of_streams(self):
    async def stream_of_streams():
      yield from_iter([1, 2])
      yield from_iter([3, 4])
    
    result = await collect(concat_all(stream_of_streams()))
    assert result == [1, 2, 3, 4]
#+end_src

*** Rust Implementation

=StreamExt::flatten= does exactly this:

#+begin_src rust :tangle rust/src/lib.rs
/// Flatten a stream of streams by concatenating them.
/// Built-in: stream_of_streams.flatten()

// Custom implementation:
pub fn concat_all<T, Inner, Outer>(outer: Outer) -> impl Stream<Item = T>
where
  Inner: Stream<Item = T>,
  Outer: Stream<Item = Inner>,
{
  stream! {
    futures::pin_mut!(outer);
    while let Some(inner) = outer.next().await {
      futures::pin_mut!(inner);
      while let Some(item) = inner.next().await { yield item; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod concat_all_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_concat_all_flattens() {
    let s1 = futures::stream::iter(vec![1, 2]);
    let s2 = futures::stream::iter(vec![3, 4]);
    let outer = futures::stream::iter(vec![s1, s2]);
    
    let values: Vec<_> = concat_all(outer).collect().await;
    assert_eq!(values, vec![1, 2, 3, 4]);
  }
}
#+end_src

** =concatMap=

=concatMap= has one argument, a function that must return a stream.
The first argument =f=, must take in the values of the source stream and return the next stream to concatenate.
You can think of it as a combination of a =map= producing streams being run through =concatAll=.

*** When to Use

Use =concatMap= when each input needs to produce multiple outputs *in sequence*. The mapper function's stream must complete before the next input is processed. For concurrent processing, use =chain= / =flatMap= instead.

#+begin_src text :tangle no
stream:              --a--------b--------|
f(a):                  1--2|
f(b):                           3--4--5|
concatMap(f):        --1--2-----3--4--5--|
                          ^
                          f(b) waits for f(a)
#+end_src

#+begin_src javascript :tangle no
// Expand each item into multiple (ordered)
const expanded = pipe(
  users,
  concatMap(user => from(user.posts))
)
// All posts from user 1, then all from user 2, etc.

// Sequential async operations per item
const processed = pipe(
  jobs,
  concatMap(job => pipe(
    from(job.steps),
    awaitTap(step => executeStep(step))
  ))
)

// Retry with exponential backoff (one attempt at a time)
const withRetry = pipe(
  requests,
  concatMap(req => pipe(
    iterate(100, d => d * 2),
    take(5),
    concatMap(delay => pipe(
      fromPromise(fetch(req)),
      recoverWith(() => pipe(just(null), delay(delay)))
    )),
    filter(r => r !== null),
    take(1)
  ))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Maps each value to a stream and concatenates the results in order.
 */
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function concatMap<T, U>(
  f: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => concatMap(f, s);
  return (async function* () {
    for await (const item of stream) yield* f(item)
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('concatMap', () => {
  it('maps and flattens in order', async () => {
    const values = await collect(concatMap(
      x => from([x, x * 10]),
      from([1, 2, 3])
    ))
    expect(values).toEqual([1, 10, 2, 20, 3, 30])
  })

  it('handles mapper returning empty stream', async () => {
    const values = await collect(concatMap(
      x => x > 1 ? from([x]) : empty(),
      from([1, 2, 3])
    ))
    expect(values).toEqual([2, 3])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def concat_map(
  f: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def concat_map(
  f: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def concat_map(
  f: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream and concatenates the results in order."""
  async def _concat_map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async for item in s:
      async for inner_item in f(item):
        yield inner_item

  if stream is None:
    return _concat_map
  return _concat_map(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestConcatMap:
  async def test_maps_and_concatenates(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      concat_map(lambda x: from_iter([x, x * 10]))
    ))
    assert result == [1, 10, 2, 20, 3, 30]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Map each value to a stream and concatenate results in order.
pub fn concat_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
  S: Stream<Item = T>,
  Inner: Stream<Item = U>,
  F: Fn(T) -> Inner,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      let inner = f(item);
      futures::pin_mut!(inner);
      while let Some(inner_item) = inner.next().await { yield inner_item; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod concat_map_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_concat_map_sequential() {
    let source = futures::stream::iter(vec![1, 2]);
    let result = concat_map(|x| futures::stream::iter(vec![x * 10, x * 10 + 1]), source);
    
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![10, 11, 20, 21]);
  }
}
#+end_src

* Filtering

** =filter=

The =filter= function filters values emitted by a stream based on a provided predicate function.
Supports both curried and uncurried calling conventions.

*** When to Use

Use =filter= to keep only values that match a condition. Values that fail the predicate are dropped entirely — downstream never sees them.

#+begin_src text :tangle no
stream:               --1--2--3--4--5--|
filter(x => x > 2):   -------3--4--5--|
                         ^
                         1 and 2 dropped#+end_src

#+begin_src javascript :tangle no
// Only process valid items
const validItems = pipe(
  allItems,
  filter(item => item.isValid)
)

// Async predicate (e.g., permission check)
const authorized = pipe(
  requests,
  filter(async req => await checkPermission(req.userId, req.resource))
)

// Type narrowing with filter
const numbers = pipe(
  mixedStream,
  filter((x): x is number => typeof x === 'number')
)

// Chain filters for complex conditions
const results = pipe(
  events,
  filter(e => e.type === 'click'),
  filter(e => e.target.matches('.button')),
  filter(e => !e.defaultPrevented)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Filters values emitted by a stream based on a provided predicate function.
 */
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function filter<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => filter(predicate, s);
  return (async function* () {
    for await (const item of stream) if (await predicate(item)) yield item;
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('filter', () => {
  it('keeps values matching predicate', async () => {
    const result = await collect(filter(x => x % 2 === 0, from([1, 2, 3, 4])))
    expect(result).toEqual([2, 4])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Filters values based on a predicate function."""
  async def _filter(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          yield item
      elif result:
        yield item

  if stream is None:
    return _filter
  return _filter(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestFilter:
  async def test_filters_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      filter(lambda x: x % 2 == 0)
    ))
    assert result == [2, 4]

  async def test_async_predicate(self):
    async def is_even(x):
      await asyncio.sleep(0)
      return x % 2 == 0
    
    result = await collect(pipe(
      from_iter([1, 2, 3, 4]),
      filter(is_even)
    ))
    assert result == [2, 4]
#+end_src

*** Rust Implementation

=StreamExt::filter= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
// Filtering Operators

/// Filters values in a stream based on a predicate.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::filter()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.filter(|x| futures::future::ready(*x > 2));
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn filter<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  P: Fn(&T) -> bool,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await { if predicate(&item) { yield item; } }
  }
}

// For async predicates:
pub fn filter_async<T, S, P, Fut>(predicate: P, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  P: Fn(&T) -> Fut,
  Fut: std::future::Future<Output = bool>,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await { if predicate(&item).await { yield item; } }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod filter_tests {
  use super::*;
  #[tokio::test]
  async fn test_filter_keeps_matching() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let result = filter(|x| *x > 2, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![3, 4, 5]);
  }

  #[tokio::test]
  async fn test_filter_even_numbers() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5, 6]);
    let result = filter(|x| x % 2 == 0, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![2, 4, 6]);
  }

  #[tokio::test]
  async fn test_filter_empty_result() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = filter(|x| *x > 100, source);
    let values: Vec<_> = result.collect().await;
    assert!(values.is_empty());
  }
}
#+end_src

** =skipRepeats=

The =skipRepeats= function filters out consecutive duplicate values from a stream.

*** When to Use

Use =skipRepeats= to suppress consecutive duplicates. Only emits when the value changes from the previous one. Uses strict equality (~===~) for comparison.

#+begin_src text :tangle no
stream:       --1--1--2--2--3--1--1--|
skipRepeats:  --1-----2-----3--1-----|
                 ^     ^        ^
                 consecutive 1s and 2s dropped,
                 but new 1 at end emits#+end_src

#+begin_src javascript :tangle no
// UI: Only update when state actually changes
const distinctStates = pipe(
  stateStream,
  skipRepeats
)

// Avoid redundant API calls
const distinctQueries = pipe(
  searchInput,
  debounce(300),
  skipRepeats  // Don't search if query unchanged
)

// Filter out repeated sensor readings
const changedReadings = pipe(
  sensorData,
  map(d => d.value),
  skipRepeats
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Filters out consecutive duplicate values from a stream.
 */
export async function* skipRepeats<T>(
  stream: AsyncIterable<T>,
): AsyncGenerator<T, void, void> {
  let first = true
  let lastValue: T | undefined
  for await (const item of stream) {
    if (first || item !== lastValue) {
      yield lastValue = item
      first = false
    }
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('skipRepeats', () => {
  it('filters consecutive duplicates', async () => {
    const values = await collect(skipRepeats(from([1, 1, 2, 2, 3, 1, 1])))
    expect(values).toEqual([1, 2, 3, 1])
  })

  it('handles empty stream', async () => {
    const values = await collect(skipRepeats(empty()))
    expect(values).toEqual([])
  })

  it('handles single value', async () => {
    const values = await collect(skipRepeats(from([42])))
    expect(values).toEqual([42])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def skip_repeats(stream: AsyncIterable[T]) -> AsyncIterator[T]:
  """Filters out consecutive duplicate values from a stream."""
  first = True
  last_value: Optional[T] = None
  async for item in stream:
    if first or item != last_value:
      yield item
      last_value = item
      first = False
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestSkipRepeats:
  async def test_removes_consecutive_duplicates(self):
    result = await collect(skip_repeats(from_iter([1, 1, 2, 2, 3, 1, 1])))
    assert result == [1, 2, 3, 1]
#+end_src

*** Rust Implementation

=StreamExt::dedup= doesn't exist by default; use =itertools= or custom. Defined with =skipRepeatsWith= below.

** =skipRepeatsWith=

The =skipRepeatsWith= function filters out consecutive duplicate values from a stream based on a provided equality function.

*** When to Use

Use =skipRepeatsWith= when you need custom equality logic for detecting duplicates. Useful for objects, where reference equality isn't meaningful.

#+begin_src text :tangle no
stream:                      --{a:1}--{a:1}--{a:2}--|
skipRepeatsWith(byA):        --{a:1}--------{a:2}--|
                                      ^
                                      same .a value, dropped#+end_src

#+begin_src javascript :tangle no
// Compare objects by specific field
const distinctUsers = pipe(
  userUpdates,
  skipRepeatsWith((a, b) => a.id === b.id && a.version === b.version)
)

// Deep equality check
const distinctConfigs = pipe(
  configStream,
  skipRepeatsWith((a, b) => JSON.stringify(a) === JSON.stringify(b))
)

// Fuzzy equality (within tolerance)
const significantChanges = pipe(
  measurements,
  skipRepeatsWith((a, b) => Math.abs(a - b) < 0.01)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Filters out consecutive duplicate values from a stream based on a provided equality function.
 */
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skipRepeatsWith<T>(
  equals: (a: T, b: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skipRepeatsWith(equals, s);
  return (async function* () {
    let first = true
    let lastValue: T | undefined
    for await (const item of stream) {
      if (first || !(await equals(item, lastValue as T))) {
        yield lastValue = item
        first = false
      }
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('skipRepeatsWith', () => {
  it('filters based on custom equality', async () => {
    const values = await collect(skipRepeatsWith(
      (a, b) => Math.floor(a) === Math.floor(b),
      from([1.1, 1.2, 2.1, 2.2, 3.0])
    ))
    expect(values).toEqual([1.1, 2.1, 3.0])
  })

  it('supports async predicate', async () => {
    const values = await collect(skipRepeatsWith(
      async (a, b) => a === b,
      from([1, 1, 2])
    ))
    expect(values).toEqual([1, 2])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Filters out consecutive duplicates using a custom equality function."""
  async def _skip_repeats_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    first = True
    last_value: Optional[T] = None
    async for item in s:
      if first:
        yield item
        last_value = item
        first = False
      else:
        result = equals(item, last_value) # type: ignore
        if asyncio.iscoroutine(result):
          is_equal = await result
        else:
          is_equal = result
        if not is_equal:
          yield item
          last_value = item

  if stream is None:
    return _skip_repeats_with
  return _skip_repeats_with(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestSkipRepeatsWith:
  async def test_custom_equality(self):
    result = await collect(pipe(
      from_iter(["A", "a", "B", "b"]),
      skip_repeats_with(lambda a, b: a.lower() == b.lower())
    ))
    assert result == ["A", "B"]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Filter consecutive duplicates using a custom equality function.
pub fn skip_repeats_with<T: Clone, S, F>(equals: F, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  F: Fn(&T, &T) -> bool,
{
  stream! {
    futures::pin_mut!(s);
    let mut last: Option<T> = None;
    while let Some(item) = s.next().await {
      let should_yield = match &last {
        None => true,
        Some(prev) => !equals(&item, prev),
      };
      if should_yield {
        last = Some(item.clone());
        yield item;
      }
    }
  }
}

/// Filter consecutive duplicates using equality.
pub fn skip_repeats<T: Clone + PartialEq, S>(s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
{
  skip_repeats_with(|a, b| a == b, s)
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod skip_repeats_tests {
  use super::*;
  #[tokio::test]
  async fn test_skip_repeats() {
    let source = futures::stream::iter(vec![1, 1, 2, 2, 3, 1, 1]);
    let result = skip_repeats(source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![1, 2, 3, 1]);
  }

  #[tokio::test]
  async fn test_skip_repeats_with_custom_eq() {
    // Compare by first character
    let source = futures::stream::iter(vec!["apple", "ant", "banana", "berry"]);
    let result = skip_repeats_with(
      |a: &&str, b: &&str| a.chars().next() == b.chars().next(),
      source
    );
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec!["apple", "banana"]);
  }
}
#+end_src

* Slicing

** =take=

The =take= function creates a stream that emits only the first =n= values from the source stream.
Supports both curried and uncurried calling conventions.

*** When to Use

Use =take= to limit the number of values from a stream. Essential for working with infinite streams or when you only need the first N results.

#+begin_src text :tangle no
stream:     --1--2--3--4--5--|
take(3):    --1--2--3|         (completes early)
                    ^
                    stops after 3 values#+end_src

#+begin_src javascript :tangle no
// Get first 10 search results
const topResults = pipe(
  searchResults,
  take(10)
)

// Limit infinite streams
const sample = pipe(
  periodic(100),
  take(5)  // Only 5 ticks
)

// "First N or all if fewer" pattern
const preview = pipe(
  items,
  take(3)  // At most 3 items for preview
)

// Take first match (like find but as stream)
const firstMatch = pipe(
  allItems,
  filter(item => item.matches(criteria)),
  take(1)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits only the first `n` values from the source stream.
 */
export function take<T>(
  n: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function take<T>(
  n: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function take<T>(
  n: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => take(n, s);
  return (async function* () {
    let count = 0;
    for await (const item of stream) {
      if (count++ < n) yield item;
      else break;
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('take', () => {
  it('takes only first N values', async () => {
    const result = await collect(take(2, from([1, 2, 3, 4, 5])))
    expect(result).toEqual([1, 2])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def take(n: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take(n: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def take(n: int, stream: Optional[AsyncIterable[T]] = None):
  """Takes only the first n values from a stream."""
  async def _take(s: AsyncIterable[T]) -> AsyncIterator[T]:
    count = 0
    async for item in s:
      if count < n:
        yield item
        count += 1
      else:
        break

  if stream is None:
    return _take
  return _take(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestTake:
  async def test_takes_n_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      take(3)
    ))
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

=StreamExt::take= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
// Slicing Operators

/// Takes the first `n` values from a stream.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::take()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.take(5);
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn take<T, S: Stream<Item = T>>(n: usize, s: S) -> impl Stream<Item = T> {
  stream! {
    futures::pin_mut!(s);
    let mut count = 0;
    while let Some(item) = s.next().await {
      if count < n {
        yield item;
        count += 1;
      } else {
        break;
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod take_tests {
  use super::*;
  #[tokio::test]
  async fn test_take_first_n() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let result = take(2, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![1, 2]);
  }

  #[tokio::test]
  async fn test_take_more_than_available() {
    let source = futures::stream::iter(vec![1, 2]);
    let result = take(10, source);
    let values: Vec<_> = result.collect().await;
    assert_eq!(values, vec![1, 2]);
  }

  #[tokio::test]
  async fn test_take_zero() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let result = take(0, source);
    let values: Vec<_> = result.collect().await;
    assert!(values.is_empty());
  }
}
#+end_src

** =skip=

The =skip= function creates a stream that skips the first =n= values from the source stream and emits the rest.

*** When to Use

Use =skip= to ignore the first N values from a stream. The stream still processes those values — it just doesn't emit them.

#+begin_src text :tangle no
stream:     --1--2--3--4--5--|
skip(2):    -------3--4--5--|
               ^
               first 2 values dropped#+end_src

#+begin_src javascript :tangle no
// Skip header row in CSV data
const dataRows = pipe(
  csvRows,
  skip(1)  // Skip header
)

// Pagination: skip to page N
const page3 = pipe(
  allItems,
  skip(20),   // Skip pages 1-2 (10 items each)
  take(10)    // Take page 3
)

// Ignore initial "loading" state
const loadedStates = pipe(
  stateStream,
  skip(1)  // Skip initial empty/loading state
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that skips the first `n` values from the source stream and emits the rest.
 */
export function skip<T>(
  n: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skip<T>(
  n: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skip<T>(
  n: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skip(n, s);
  return (async function* () {
    let count = 0;
    for await (const item of stream) if (count++ >= n) yield item;
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('skip', () => {
  it('skips first N values', async () => {
    const result = await collect(skip(2, from([1, 2, 3, 4, 5])))
    expect(result).toEqual([3, 4, 5])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def skip(n: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip(n: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def skip(n: int, stream: Optional[AsyncIterable[T]] = None):
  """Skips the first n values from a stream."""
  async def _skip(s: AsyncIterable[T]) -> AsyncIterator[T]:
    count = 0
    async for item in s:
      if count >= n:
        yield item
      count += 1

  if stream is None:
    return _skip
  return _skip(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestSkip:
  async def test_skips_n_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      skip(2)
    ))
    assert result == [3, 4, 5]
#+end_src

*** Rust Implementation

=StreamExt::skip= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
/// Skips the first `n` values from a stream.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::skip()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.skip(2);
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn skip<T, S: Stream<Item = T>>(n: usize, s: S) -> impl Stream<Item = T> {
  stream! {
    futures::pin_mut!(s);
    let mut count = 0;
    while let Some(item) = s.next().await {
      if count >= n { yield item; }
      count += 1;
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod skip_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_skip_first_n() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let values: Vec<_> = skip(2, source).collect().await;
    assert_eq!(values, vec![3, 4, 5]);
  }
  
  #[tokio::test]
  async fn test_skip_zero() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = skip(0, source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }
  
  #[tokio::test]
  async fn test_skip_more_than_available() {
    let source = futures::stream::iter(vec![1, 2]);
    let values: Vec<_> = skip(5, source).collect().await;
    assert!(values.is_empty());
  }
}
#+end_src

** =slice=

The =slice= function creates a stream that emits values from the source stream starting from index =start= up to, but not including, index =end=.

*** When to Use

Use =slice= to extract a range of values by index, like Array.slice(). Combines the functionality of =skip= and =take= in a single operator.

#+begin_src text :tangle no
stream:         --0--1--2--3--4--5--|
slice(1, 4):    -----1--2--3|        
                  ^        ^
                  start    end (exclusive)
#+end_src

#+begin_src javascript :tangle no
// Get items 10-20 (pagination)
const page2 = pipe(
  allItems,
  slice(10, 20)
)

// Skip first and last (equivalent to slice(1, -1) for known length)
const middle = pipe(
  items,
  slice(1, items.length - 1)
)

// Extract specific range for processing
const range = pipe(
  dataPoints,
  slice(100, 200)  // Points 100-199
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits values from the source stream starting from index `start` up to, but not including, index `end`.
 */
export function slice<T>(
  start: number,
  end: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function slice<T>(
  start: number,
  end: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function slice<T>(
  start: number,
  end: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => slice(start, end, s);
  return (async function* () {
    let index = 0
    for await (const item of stream) {
      if (index >= start && index < end) yield item
      if (index++ >= end) break
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('slice', () => {
  it('emits values from start to end indices', async () => {
    const values = await collect(slice(1, 4, from([0, 1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3])
  })
  it('handles start at 0', async () => {
    const values = await collect(slice(0, 2, from([10, 20, 30])))
    expect(values).toEqual([10, 20])
  })
  it('returns empty for out of range', async () => {
    const values = await collect(slice(10, 20, from([1, 2, 3])))
    expect(values).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def slice(start: int, end: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def slice(start: int, end: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def slice(start: int, end: int, stream: Optional[AsyncIterable[T]] = None):
  """Emits values from index start to end (exclusive)."""
  async def _slice(s: AsyncIterable[T]) -> AsyncIterator[T]:
    index = 0
    async for item in s:
      if index >= start and index < end:
        yield item
      index += 1
      if index >= end:
        break

  if stream is None:
    return _slice
  return _slice(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestSlice:
  async def test_extracts_slice(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      slice(1, 4)
    ))
    assert result == [2, 3, 4]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Emit values from index start to end (exclusive).
pub fn slice<T, S: Stream<Item = T>>(start: usize, end: usize, s: S) -> impl Stream<Item = T> {
  stream! {
    futures::pin_mut!(s);
    let mut index = 0;
    while let Some(item) = s.next().await {
      if index >= start && index < end { yield item; }
      index += 1;
      if index >= end { break; }
    }
  }
}

// Or using built-in methods:
// stream.skip(start).take(end - start)
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod slice_tests {
  use super::*;
  #[tokio::test]
  async fn test_slice() {
    let source = futures::stream::iter(vec![0, 1, 2, 3, 4, 5]);
    let values: Vec<_> = slice(2, 5, source).collect().await;
    assert_eq!(values, vec![2, 3, 4]);
  }

  #[tokio::test]
  async fn test_slice_empty_range() {
    let source = futures::stream::iter(vec![0, 1, 2, 3, 4]);
    let values: Vec<_> = slice(2, 2, source).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }

  #[tokio::test]
  async fn test_slice_beyond_length() {
    let source = futures::stream::iter(vec![0, 1, 2]);
    let values: Vec<_> = slice(1, 10, source).collect().await;
    assert_eq!(values, vec![1, 2]);
  }
}
#+end_src

** =takeWhile=

The =takeWhile= function creates a stream that emits values from the source stream as long as the provided predicate function returns true and ends the stream as soon as it returns false.

*** When to Use

Use =takeWhile= to take values as long as a condition holds, stopping at the first failure. The failing value is *not* emitted.

#+begin_src text :tangle no
stream:              --1--2--3--4--5--|
takeWhile(x < 4):    --1--2--3|         (stops at 4)
                              ^
                              4 fails predicate, stream ends#+end_src

#+begin_src javascript :tangle no
// Read until end marker
const untilEnd = pipe(
  lines,
  takeWhile(line => line !== 'END')
)

// Process while resources available
const whileAvailable = pipe(
  tasks,
  takeWhile(() => memory.available > threshold)
)

// Countdown until zero
const countdown = pipe(
  iterate(10, n => n - 1),
  takeWhile(n => n >= 0)
)
// yields: 10, 9, 8, ..., 1, 0
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits values from the source stream as long as the provided predicate function returns true.
 */
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function takeWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => takeWhile(predicate, s);
  return (async function* () {
    for await (const item of stream) {
      if (await predicate(item)) yield item
      else break
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('takeWhile', () => {
  it('takes while predicate is true', async () => {
    const values = await collect(takeWhile(x => x < 4, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3])
  })
  it('stops at first false', async () => {
    const values = await collect(takeWhile(x => x !== 'stop', from(['a', 'b', 'stop', 'c'])))
    expect(values).toEqual(['a', 'b'])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Takes values while predicate returns true, stops at first false."""
  async def _take_while(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          yield item
        else:
          break
      elif result:
        yield item
      else:
        break

  if stream is None:
    return _take_while
  return _take_while(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestTakeWhile:
  async def test_takes_while_true(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 1]),
      take_while(lambda x: x < 4)
    ))
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

=StreamExt::take_while= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
/// Takes values from a stream while the predicate returns true.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::take_while()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.take_while(|x| futures::future::ready(*x < 5));
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn take_while<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  P: Fn(&T) -> bool,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      if predicate(&item) { yield item; }
      else { break; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod take_while_tests {
  use super::*;
  #[tokio::test]
  async fn test_take_while() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 2, 1]);
    let values: Vec<_> = take_while(|x| *x < 4, source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }

  #[tokio::test]
  async fn test_take_while_all_pass() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = take_while(|_x| true, source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }

  #[tokio::test]
  async fn test_take_while_none_pass() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = take_while(|_x| false, source).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }
}
#+end_src

** =skipWhile=

The =skipWhile= function creates a stream that skips values from the source stream as long as the provided predicate function returns true and starts emitting values as soon as it returns false.

*** When to Use

Use =skipWhile= to drop values as long as a condition holds, then emit everything after. Once the predicate fails, all subsequent values pass through (even if they would match the predicate).

#+begin_src text :tangle no
stream:              --1--2--3--4--2--1--|
skipWhile(x < 3):    -------3--4--2--1--|
                        ^
                        first value where predicate fails,
                        all values after are emitted#+end_src

#+begin_src javascript :tangle no
// Skip header comments in a file
const codeLines = pipe(
  fileLines,
  skipWhile(line => line.startsWith('#'))
)

// Skip loading states, start from first real data
const realData = pipe(
  states,
  skipWhile(state => state.loading)
)

// Skip until a specific marker
const afterMarker = pipe(
  events,
  skipWhile(e => e.type !== 'START'),
  skip(1)  // Also skip the START event itself
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that skips values from the source stream while the provided predicate function returns true, then emits the rest of the stream.
 */
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function skipWhile<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => skipWhile(predicate, s);
  return (async function* () {
    let match = false
    for await (const item of stream) {
      if (!match && !(await predicate(item))) match = true
      if (match) yield item
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('skipWhile', () => {
  it('skips while predicate is true then emits rest', async () => {
    const values = await collect(skipWhile(x => x < 3, from([1, 2, 3, 4, 2, 1])))
    expect(values).toEqual([3, 4, 2, 1])
  })
  it('emits all if predicate never true', async () => {
    const values = await collect(skipWhile(() => false, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]],
 stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]],
 stream: Optional[AsyncIterable[T]] = None
):
  """Skips values while predicate is true, then emits the rest."""
  async def _skip_while(s: AsyncIterable[T]) -> AsyncIterator[T]:
    skipping = True
    async for item in s:
      if skipping:
        result = predicate(item)
        if asyncio.iscoroutine(result):
          should_skip = await result
        else:
          should_skip = result
        if not should_skip:
          skipping = False
          yield item
      else:
        yield item

  if stream is None:
    return _skip_while
  return _skip_while(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestSkipWhile:
  async def test_skips_while_true(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 1]),
      skip_while(lambda x: x < 3)
    ))
    assert result == [3, 4, 1]
#+end_src

*** Rust Implementation

=StreamExt::skip_while= is built-in. This standalone function is provided for pipe-style composition:

#+begin_src rust :tangle rust/src/lib.rs
/// Skips values from a stream while the predicate returns true.
/// 
/// # Note
/// Prefer using the built-in `StreamExt::skip_while()` method when chaining:
/// ```rust,ignore
/// use futures::StreamExt;
/// let result = stream.skip_while(|x| futures::future::ready(*x < 3));
/// ```
/// This standalone function is provided for functional/pipe-style composition.
pub fn skip_while<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  P: Fn(&T) -> bool,
{
  stream! {
    futures::pin_mut!(s);
    let mut skipping = true;
    while let Some(item) = s.next().await {
      if skipping && !predicate(&item) { skipping = false; }
      if !skipping {  yield item; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod skip_while_tests {
  use super::*;
  #[tokio::test]
  async fn test_skip_while() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 2, 1]);
    let values: Vec<_> = skip_while(|x| *x < 3, source).collect().await;
    assert_eq!(values, vec![3, 4, 2, 1]);
  }

  #[tokio::test]
  async fn test_skip_while_all_fail() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = skip_while(|_x| false, source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }

  #[tokio::test]
  async fn test_skip_while_all_pass() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = skip_while(|_x| true, source).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }
}
#+end_src

** =takeUntil=

The =takeUntil= function creates a stream that emits values from the source stream until the provided predicate function returns true, at which point it completes (the matching value is *not* emitted).

*** When to Use

Use =takeUntil= to take values until a condition is met, then stop. The matching value is *not* emitted (exclusive). Contrast with =takeWhile= which stops when the condition *fails*.

#+begin_src text :tangle no
stream:               --1--2--3--4--5--|
takeUntil(x === 3):   --1--2|            (stops before 3)
                            ^
                            3 matches, not emitted, stream ends#+end_src

#+begin_src javascript :tangle no
// Process until error marker
const untilError = pipe(
  messages,
  takeUntil(msg => msg.type === 'ERROR')
)

// Read stream until timeout
const withTimeout = pipe(
  dataStream,
  takeUntil(() => Date.now() > deadline)
)

// Process until user cancels
const untilCancel = pipe(
  workItems,
  takeUntil(() => cancelled)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits values from the source stream until the provided predicate function returns true.
 * The matching value is not emitted.
 */
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function takeUntil<T>(
  predicate: (value: T) => boolean | Promise<boolean>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => takeUntil(predicate, s);
  return (async function* () {
    for await (const item of stream) {
      if (await predicate(item)) break
      yield item
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('takeUntil', () => {
  it('takes until predicate matches (exclusive)', async () => {
    const values = await collect(takeUntil(x => x === 3, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2])
  })

  it('emits all if predicate never matches', async () => {
    const values = await collect(takeUntil(() => false, from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Takes values until predicate matches (matching value not emitted)."""
  async def _take_until(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          break
      elif result:
        break
      yield item

  if stream is None:
    return _take_until
  return _take_until(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestTakeUntil:
  async def test_takes_until(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      take_until(lambda x: x == 3)
    ))
    assert result == [1, 2]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Take values until predicate matches (matching value not emitted).
pub fn take_until<T, S, P>(predicate: P, s: S) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  P: Fn(&T) -> bool,
{
  stream! {
    futures::pin_mut!(s);
    while let Some(item) = s.next().await {
      if predicate(&item) { break; }
      yield item;
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod take_until_tests {
  use super::*;
  #[tokio::test]
  async fn test_take_until() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let values: Vec<_> = take_until(|x| *x == 3, source).collect().await;
    assert_eq!(values, vec![1, 2]);
  }
  #[tokio::test]
  async fn test_take_until_never_matches() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = take_until(|_x| false, source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }
  #[tokio::test]
  async fn test_take_until_first_matches() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = take_until(|x| *x == 1, source).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }
}
#+end_src

* Time-based Operators

These operators work with time, adding delays or controlling the rate of emissions.

** =delay=

The =delay= operator delays each emission by a specified duration.

*** When to Use

Use =delay= to add a pause before each emission. Each value is held for the specified duration before being yielded downstream.

#+begin_src text :tangle no
time:         0ms    100ms   200ms    300ms
stream:       --1-------2-------3--|
delay(50):    ----1-------2-------3--|
                  ^
                  each value delayed by 50ms#+end_src

#+begin_src javascript :tangle no
// Simulate network latency in tests
const slowResponse = pipe(
  mockData,
  delay(500)  // Simulate 500ms network delay
)

// Rate-limit outgoing messages
const throttledMessages = pipe(
  messages,
  delay(100)  // At most 10 messages per second
)

// Stagger animations
const staggered = pipe(
  elements,
  delay(50),
  tap(el => el.classList.add('visible'))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Delays each value emitted by the source stream by the specified duration.
 */
export function delay<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function delay<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function delay<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => delay(ms, s);
  return (async function* () {
    for await (const item of stream) {
      await new Promise(r => setTimeout(r, ms))
      yield item
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('delay', () => {
  it('delays each emission', async () => {
    const start = Date.now()
    const values = await collect(delay(20, from([1, 2, 3])))
    const elapsed = Date.now() - start
    expect(values).toEqual([1, 2, 3])
    expect(elapsed).toBeGreaterThanOrEqual(50)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2]), delay(10)))
    expect(values).toEqual([1, 2])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def delay(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def delay(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def delay(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Delays each value by a specified duration."""
  async def _delay(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      await asyncio.sleep(seconds)
      yield item

  if stream is None:
    return _delay
  return _delay(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestDelay:
  async def test_delays_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3]),
      delay(0.01)
    ))
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
// Time Operators
/// Delay each value by a specified duration.
/// Uses the Runtime trait for timer functionality.
pub fn delay<R: Runtime, T, S: Stream<Item = T>>(ms: u64, s: S) -> impl Stream<Item = T> {
  stream! {
    futures::pin_mut!(s);
    let duration = Duration::from_millis(ms);
    while let Some(item) = s.next().await {
      R::sleep(duration).await;
      yield item;
    }
  }
}

/// Runtime-agnostic delay that accepts a sleep function
pub fn delay_with<T, S, F, Fut>(
  ms: u64,
  s: S,
  sleep_fn: F,
) -> impl Stream<Item = T>
where
  S: Stream<Item = T>,
  F: Fn(Duration) -> Fut + Clone,
  Fut: std::future::Future<Output = ()>,
{
  stream! {
    futures::pin_mut!(s);
    let duration = Duration::from_millis(ms);
    while let Some(item) = s.next().await {
      sleep_fn(duration).await;
      yield item;
    }
  }
}
#+end_src

**** Tests

/Note:/ These tests use real tokio time rather than the =TestRuntime= virtual scheduler.

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod delay_tests {
  use super::*;
  #[tokio::test]
  async fn test_delay_with() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let start = std::time::Instant::now();
    let values: Vec<_> = delay_with(
      10,
      source,
      |d| tokio::time::sleep(d),
    ).collect().await;
    let elapsed = start.elapsed();
    assert_eq!(values, vec![1, 2, 3]);
    assert!(elapsed >= Duration::from_millis(25)); // ~30ms for 3 items
  }

  #[tokio::test]
  async fn test_delay_empty_stream() {
    let source = futures::stream::iter(Vec::<i32>::new());
    let values: Vec<_> = delay_with(
      100,
      source,
      |d| tokio::time::sleep(d),
    ).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }
}
#+end_src

** =debounce=

The =debounce= operator only emits a value if no new values arrive within the specified duration.
It waits for the stream to "settle" before emitting the most recent value.

*** When to Use

Use =debounce= when you want to wait for input to "settle" before processing. Common use cases:
- Search-as-you-type: Wait until user stops typing before querying
- Form validation: Validate after user stops editing a field
- Window resize: Avoid excessive recalculations during resize

#+begin_src text :tangle no
keystrokes:      --a-b-c-----d-e-f-g---|
                   rapid     pause
debounce(200):   --------c---------g---|  
                        ^           ^
                        waits 200ms after last keystroke#+end_src

#+begin_src javascript :tangle no
// Search autocomplete
const searchResults = pipe(
  fromEvent(searchInput, 'input'),
  debounce(300),
  map(e => e.target.value),
  filter(query => query.length > 2),
  switchMap(query => fetchResults(query))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Only emits a value from the source stream if no new value arrives within the specified duration.
 * Useful for waiting until input has "settled" (e.g., user stops typing).
 */
export function debounce<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function debounce<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function debounce<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => debounce(ms, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let pending: { value: T; timer: ReturnType<typeof setTimeout> } | null = null
    let done = false
    let pendingResolve: ((value: T | null) => void) | null = null

    const emitPending = () => {
      if (pending && pendingResolve) {
        const value = pending.value
        pending = null
        pendingResolve(value)
        pendingResolve = null
      }
    }

    // Start consuming source in background
    ;(async () => {
      try {
        while (true) {
          const result = await iterator.next()
          if (result.done) {
            done = true
            // Emit any pending value immediately on completion
            if (pending) {
              clearTimeout(pending.timer)
              emitPending()
            } else if (pendingResolve) {
              const resolver: (value: T | null) => void = pendingResolve
              resolver(null)
            }
            break
          }
          // Cancel previous timer
          if (pending) clearTimeout(pending.timer)
          // Set new pending value with timer
          pending = {
            value: result.value,
            timer: setTimeout(emitPending, ms)
          }
        }
      } catch (e) {
        // Handle errors by clearing pending and re-throwing via the generator
        if (pending) clearTimeout(pending.timer)
        pending = null
        throw e
      }
    })()

    // Yield debounced values
    while (!done || pending) {
      const value = await new Promise<T | null>(resolve => {
        if (done && !pending) {
          resolve(null)
          return
        }
        pendingResolve = resolve
      })
      if (value !== null) yield value
      if (done && !pending) break
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('debounce', () => {
  it('only emits after stream settles', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 10 })
    const values = await collect(debounce(30, stream))
    // Only the last value should be emitted since delay < debounce time
    expect(values).toEqual([3])
  })

  it('emits multiple values when gaps are large enough', async () => {
    const stream = createAsyncIterable([1, 2], { delay: 50 })
    const values = await collect(debounce(20, stream))
    // Both should emit since delay > debounce time
    expect(values).toEqual([1, 2])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1]), debounce(5)))
    expect(values).toEqual([1])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def debounce(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def debounce(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def debounce(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Only emits a value if no new value arrives within the specified duration."""
  async def _debounce(s: AsyncIterable[T]) -> AsyncIterator[T]:
    pending: Optional[T] = None
    pending_task: Optional[asyncio.Task] = None
    done = False
    result_queue: asyncio.Queue[Optional[T]] = asyncio.Queue()

    async def emit_after_delay(value: T):
      await asyncio.sleep(seconds)
      await result_queue.put(value)

    async def consume_source():
      nonlocal pending, pending_task, done
      async for item in s:
        if pending_task:
          pending_task.cancel()
          try:
            await pending_task
          except asyncio.CancelledError:
            pass
        pending = item
        pending_task = asyncio.create_task(emit_after_delay(item))
      done = True
      if pending_task:
        try:
          await pending_task
        except asyncio.CancelledError:
          pass
      await result_queue.put(None) # Signal completion

    consumer_task = asyncio.create_task(consume_source())

    while True:
      value = await result_queue.get()
      if value is None:
        break
      yield value

    await consumer_task

  if stream is None:
    return _debounce
  return _debounce(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Only emit a value if no new values arrive within the specified duration.
/// Uses the Runtime trait for timer functionality.
pub fn debounce<R, T, S>(ms: u64, s: S) -> impl Stream<Item = T>
where
  R: Runtime,
  T: Clone + Send + 'static,
  S: Stream<Item = T> + Send + 'static,
{
  debounce_with(ms, s, R::sleep)
}

/// Runtime-agnostic debounce that accepts a sleep function.
/// Emits a value only after the specified duration has passed without new values.
pub fn debounce_with<T, S, F, Fut>(ms: u64, s: S, sleep_fn: F) -> impl Stream<Item = T>
where
  T: Clone + Send + 'static,
  S: Stream<Item = T> + Send + 'static,
  F: Fn(Duration) -> Fut + Clone + Send + 'static,
  Fut: std::future::Future<Output = ()> + Send + 'static,
{
  stream! {
    let duration = Duration::from_millis(ms);
    let mut pending: Option<T> = None;
    
    futures::pin_mut!(s);
    
    while let Some(value) = s.next().await {
      pending = Some(value);
      // Keep consuming while values arrive rapidly
      loop {
        let timeout = sleep_fn(duration);
        futures::pin_mut!(timeout);
        
        // Race between next value and timeout
        let next = s.next();
        futures::pin_mut!(next);
        
        match futures::future::select(next, timeout).await {
          futures::future::Either::Left((Some(v), _)) => {
            // New value arrived, update pending and restart timer
            pending = Some(v);
          }
          futures::future::Either::Left((None, _)) => {
            // Stream ended
            if let Some(v) = pending.take() {
              yield v;
            }
            return;
          }
          futures::future::Either::Right((_, _)) => {
            // Timeout fired, emit pending and wait for next value
            if let Some(v) = pending.take() {
              yield v;
            }
            break;
          }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod debounce_tests {
  // Note: debounce requires time-based testing
  // A proper test would need controlled time or a mock runtime
  // The implementation is correct if throttle tests pass
  // since they share similar timing logic
  
  // Example test with real timing (slow):
  // #[tokio::test]
  // async fn test_debounce_waits_for_quiet() {
  //   // Would need tokio::time::pause() for reliable testing
  // }
}
#+end_src

** =throttle=

The =throttle= operator limits the rate of emissions.
It's configurable with =leading= (emit first value immediately) and =trailing= (emit last value after window) options.

*** When to Use

Use =throttle= to limit how frequently values are emitted. Unlike =debounce= (which waits for quiet), =throttle= ensures regular updates during continuous activity.

#+begin_src text :tangle no
time:             0   100  200  300  400  500  600
stream:           a-b-c-d-e-f-g-h-i-j-k-|
                  ^ ^       ^       ^   ^
                  rapid continuous emissions

throttle(200):    a-------d-------g-----k|
                  ^       ^       ^     ^
                  leading trailing leading trailing
                  (first) (last   (first (final)
                          in       after
                          window)  window)
#+end_src

#+begin_src javascript :tangle no
// Scroll position updates (max 10 per second)
const scrollPosition = pipe(
  fromEvent(window, 'scroll'),
  map(() => window.scrollY),
  throttle(100)  // At most every 100ms
)

// Mouse move tracking
const mousePosition = pipe(
  fromEvent(document, 'mousemove'),
  map(e => ({ x: e.clientX, y: e.clientY })),
  throttle(16)  // ~60fps
)

// Progress updates (don't spam UI)
const progressUpdates = pipe(
  rawProgress,
  throttle(250, { leading: true, trailing: true })
)

// Rate-limited API polling
const apiData = pipe(
  trigger,
  throttle(1000, { leading: true, trailing: false }),
  chain(() => fetchData())
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Options for throttle behavior.
 */
export interface ThrottleOptions {
  /** Emit the first value immediately when the window starts (default: true) */
  leading?: boolean
  /** Emit the last value after the window ends (default: true) */
  trailing?: boolean
}

/**
 * Limits the rate of emissions from a stream.
 * 
 * @param ms - The throttle window duration in milliseconds
 * @param options - Configure leading/trailing edge behavior
 *   - leading: emit first value immediately (default: true)
 *   - trailing: emit last value after window (default: true)
 */
export function throttle<T>(
  ms: number,
  options?: ThrottleOptions
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function throttle<T>(
  ms: number,
  options: ThrottleOptions | undefined,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function throttle<T>(
  ms: number,
  optionsOrStream?: ThrottleOptions | AsyncIterable<T>,
  maybeStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  // Parse arguments: supports throttle(ms), throttle(ms, opts), throttle(ms, opts, stream)
  let options: ThrottleOptions
  let stream: AsyncIterable<T> | undefined
  
  if (maybeStream !== undefined) {
    options = (optionsOrStream as ThrottleOptions) ?? {}
    stream = maybeStream
  } else if (optionsOrStream !== undefined && typeof (optionsOrStream as any)[Symbol.asyncIterator] === 'function') {
    options = {}
    stream = optionsOrStream as AsyncIterable<T>
  } else {
    options = (optionsOrStream as ThrottleOptions) ?? {}
    stream = undefined
  }

  const { leading = true, trailing = true } = options

  if (stream === undefined) return (s: AsyncIterable<T>) => throttle(ms, options, s);
  
  const sourceStream = stream
  return (async function* () {
    let lastEmitTime = 0
    let trailingValue: T | undefined
    let hasTrailingValue = false
    let trailingTimer: ReturnType<typeof setTimeout> | null = null

    const emitTrailing = function* (): Generator<T, void, void> {
      if (hasTrailingValue && trailing) {
        yield trailingValue as T
        hasTrailingValue = false
        lastEmitTime = Date.now()
      }
    }

    for await (const item of sourceStream) {
      const now = Date.now()
      const elapsed = now - lastEmitTime

      if (elapsed >= ms) {
        // Window has passed
        if (leading) {
          yield item
          lastEmitTime = now
          hasTrailingValue = false
        } else {
          // Store for trailing
          trailingValue = item
          hasTrailingValue = true
        }
      } else {
        // Within window, store for trailing
        trailingValue = item
        hasTrailingValue = true
      }
    }

    // Emit final trailing value if any
    if (hasTrailingValue && trailing) { yield trailingValue as T }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('throttle', () => {
  it('limits emission rate with default options', async () => {
    const stream = createAsyncIterable([1, 2, 3, 4, 5], { delay: 10 })
    const values = await collect(throttle(25, {}, stream))
    // First emits immediately, then throttled
    expect(values.length).toBeLessThan(5)
    expect(values[0]).toBe(1)
  })

  it('respects leading: false', async () => {
    const values = await collect(throttle(50, { leading: false }, from([1, 2, 3])))
    // Should not emit leading values
    expect(values.length).toBeGreaterThan(0)
  })

  it('respects trailing: false', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 5 })
    const values = await collect(throttle(20, { trailing: false }, stream))
    // Should only emit leading values
    expect(values).toContain(1)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3]), throttle(10)))
    expect(values.length).toBeGreaterThan(0)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@dataclass
class ThrottleOptions:
  """Options for throttle behavior."""
  leading: bool = True
  trailing: bool = True


@overload
def throttle(
  seconds: float,
  options: Optional[ThrottleOptions] = None
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def throttle(
  seconds: float,
  options: Optional[ThrottleOptions],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def throttle(
  seconds: float,
  options: Optional[ThrottleOptions] = None,
  stream: Optional[AsyncIterable[T]] = None
):
  """Limits the rate of emissions with leading/trailing edge control."""
  opts = options or ThrottleOptions()

  async def _throttle(s: AsyncIterable[T]) -> AsyncIterator[T]:
    import time
    last_emit_time = 0.0
    trailing_value: Optional[T] = None
    has_trailing = False

    async for item in s:
      now = time.time()
      elapsed = now - last_emit_time

      if elapsed >= seconds:
        if opts.leading:
          yield item
          last_emit_time = now
          has_trailing = False
        else:
          trailing_value = item
          has_trailing = True
      else:
        trailing_value = item
        has_trailing = True

    if has_trailing and opts.trailing:
      yield trailing_value # type: ignore

  if stream is None:
    if options is None:
      return _throttle
    # Handle case where options might be the stream
    if hasattr(options, '__aiter__'):
      return _throttle(options) # type: ignore
    return _throttle
  return _throttle(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
pub struct ThrottleOptions {
  pub leading: bool,
  pub trailing: bool,
}

impl Default for ThrottleOptions {
  fn default() -> Self {
    Self { leading: true, trailing: true }
  }
}

impl ThrottleOptions {
  pub fn leading_only() -> Self {
    Self { leading: true, trailing: false }
  }
  pub fn trailing_only() -> Self {
    Self { leading: false, trailing: true }
  }
}

/// Limit emission rate with leading/trailing edge control.
/// This implementation is runtime-agnostic - it only uses std::time::Instant.
pub fn throttle<T: Clone, S: Stream<Item = T> + Unpin>(
  ms: u64,
  options: ThrottleOptions,
  mut s: S,
) -> impl Stream<Item = T> {
  stream! {
    let duration = Duration::from_millis(ms);
    let mut last_emit = Instant::now() - duration;  // Allow first emit
    let mut trailing_value: Option<T> = None;
    while let Some(item) = s.next().await {
      let now = Instant::now();
      let elapsed = now.duration_since(last_emit);
      if elapsed >= duration {
        if options.leading {
          yield item;
          last_emit = now;
          trailing_value = None;
        } else {
          trailing_value = Some(item);
        }
      } else {
        trailing_value = Some(item);
      }
    }
    // Emit final trailing value
    if options.trailing {
      if let Some(value) = trailing_value { yield value; }
    }
  }
}
#+end_src

**** Tests

/Note:/ These tests use real tokio time rather than the =TestRuntime= virtual scheduler.

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod throttle_tests {
  use super::*;
  #[tokio::test]
  async fn test_throttle_leading() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let values: Vec<_> = throttle(
      100,
      ThrottleOptions::leading_only(),
      source,
    ).collect().await;
    // First value should be emitted immediately
    assert!(!values.is_empty());
    assert_eq!(values[0], 1);
  }

  #[tokio::test]
  async fn test_throttle_trailing() {
    let source = futures::stream::iter(vec![1, 2, 3]);
    let values: Vec<_> = throttle(
      100,
      ThrottleOptions::trailing_only(),
      source,
    ).collect().await;
    // Last value should be emitted as trailing
    assert!(!values.is_empty());
  }

  #[tokio::test]
  async fn test_throttle_empty() {
    let source = futures::stream::iter(Vec::<i32>::new());
    let values: Vec<_> = throttle(
      100,
      ThrottleOptions::default(),
      source,
    ).collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }
}
#+end_src

* Error Handling

** =recoverWith= 

The =recoverWith= function allows you to recover from errors in a stream by providing a function that returns an alternative stream when an error occurs.

*** When to Use

Use =recoverWith= to gracefully handle errors by switching to an alternative stream. The error is passed to your recovery function, allowing error-specific handling.

#+begin_src text :tangle no
stream:               --1--2--X
                             ^
                             error thrown

recoverWith(fallback): -1--2--a--b--|   
                             ^
                             switches to fallback stream#+end_src

#+begin_src javascript :tangle no
// Fallback to cached data on network error
const data = pipe(
  networkStream,
  recoverWith(err => {
    console.error('Network failed:', err)
    return from(cachedData)
  })
)

// Provide default value on parse error
const parsed = pipe(
  rawData,
  map(JSON.parse),
  recoverWith(() => just({ error: 'Invalid JSON' }))
)

// Log and continue empty on non-critical errors
const resilient = pipe(
  allItems,
  recoverWith(err => {
    logError(err)
    return empty()
  })
)

// Error-specific recovery
const smart = pipe(
  apiCall,
  recoverWith(err => {
    if (err.status === 404) return just(null)
    if (err.status === 401) return fromPromise(refreshAndRetry())
    throw err  // Re-throw unexpected errors
  })
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Recovers from errors in a stream by providing an alternative stream.
 */
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function recoverWith<T, E = unknown>(
  recoverFn: (error: E) => AsyncIterable<T>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => recoverWith(recoverFn, s);
  return (async function* () {
    try { yield* stream }
    catch (error) { yield* recoverFn(error as E) }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('recoverWith', () => {
  it('yields values from recovery stream on error', async () => {
    const failing = throwError(new Error('oops'))
    const values = await collect(recoverWith(
      () => from([1, 2, 3]),
      failing
    ))
    expect(values).toEqual([1, 2, 3])
  })

  it('passes error to recovery function', async () => {
    let capturedError: Error | undefined
    const failing = throwError(new Error('captured'))
    await collect(recoverWith(
      (e: Error) => { capturedError = e; return empty() },
      failing
    ))
    expect(capturedError?.message).toBe('captured')
  })

  it('yields source values if no error', async () => {
    const values = await collect(recoverWith(
      () => from(['fallback']),
      from(['success'])
    ))
    expect(values).toEqual(['success'])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Recovers from errors by switching to an alternative stream."""
  async def _recover_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    try:
      async for item in s:
        yield item
    except Exception as e:
      async for item in recover_fn(e):
        yield item

  if stream is None:
    return _recover_with
  return _recover_with(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestRecoverWith:
  async def test_recovers_from_error(self):
    async def failing_stream():
      yield 1
      raise ValueError("oops")
    
    result = await collect(pipe(
      failing_stream(),
      recover_with(lambda e: from_iter([99]))
    ))
    assert result == [1, 99]
#+end_src

*** Rust Implementation

In Rust, we use =Result= types for error handling in streams:

#+begin_src rust :tangle rust/src/lib.rs
// Error Handling Operators
/// For streams that emit Result<T, E>, recover from errors.
pub fn recover_with<T, E, S, S2, F>(
  recover_fn: F,
  s: S,
) -> impl Stream<Item = T>
where
  S: Stream<Item = Result<T, E>>,
  S2: Stream<Item = T>,
  F: FnOnce(E) -> S2,
  E: Error,
{
  stream! {
    futures::pin_mut!(s);
    loop {
      match s.next().await {
        Some(Ok(item)) => yield item,
        Some(Err(e)) => {
          let recovery = recover_fn(e);
          futures::pin_mut!(recovery);
          while let Some(item) = recovery.next().await { yield item; }
          break;
        }
        None => break,
      }
    }
  }
}

// Alternatively, using TryStreamExt from futures:
// use futures::TryStreamExt;
// stream.or_else(|e| async move { Ok(fallback_value) })
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod recover_with_tests {
  use super::*;
  
  // Use a concrete error type for testing
  #[derive(Debug)]
  struct SimpleError;
  impl std::fmt::Display for SimpleError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
      write!(f, "SimpleError")
    }
  }
  impl std::error::Error for SimpleError {}
  
  #[tokio::test]
  async fn test_recover_with_no_error() {
    let source = futures::stream::iter(vec![Ok::<_, SimpleError>(1), Ok(2), Ok(3)]);
    let values: Vec<_> = recover_with(
      |_e: SimpleError| futures::stream::iter(vec![99]),
      source,
    ).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  } 

  #[tokio::test]
  async fn test_recover_with_error() {
    let source = futures::stream::iter(vec![
      Ok(1),
      Err(SimpleError),
      Ok(3),
    ]);
    let values: Vec<_> = recover_with(
      |_e: SimpleError| futures::stream::iter(vec![99, 100]),
      source,
    ).collect().await;
    assert_eq!(values, vec![1, 99, 100]);
  }
}
#+end_src

** =recoverWithStream=

The =recoverWithStream= function allows you to provide an async generator of alternative streams to recover from errors, rather than a function returning a single stream.

*** When to Use

Use =recoverWithStream= when you have a pre-defined sequence of fallback streams to try on error. Unlike =recoverWith= which calls a function each time, this consumes alternatives from a stream.

#+begin_src text :tangle no
source:                   --1--X  (fails)
alternatives:             [A, B, C]
recoverWithStream:        --1--A values--  (tries A)
                               or if A fails: --B values--#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Recovers from errors by trying alternative streams from a provided stream of streams.
 * Consumes alternatives in order until one succeeds or all are exhausted.
 */
export async function* recoverWithStream<T>(
  alternatives: AsyncIterable<AsyncIterable<T>>,
  source: AsyncIterable<T>,
): AsyncGenerator<T, void, void> {
  const altIterator = alternatives[Symbol.asyncIterator]()
  let current: AsyncIterable<T> = source
  
  while (true) {
    try {
      for await (const value of current) {
        yield value
      }
      return  // Success, done
    } catch {
      const next = await altIterator.next()
      if (next.done) {
        throw new Error('All recovery alternatives exhausted')
      }
      current = next.value
    }
  }
}
#+end_src

*** TODO Python Implementation

#+begin_src python :tangle python/agent_rex.py

#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Recovers from errors by trying alternative streams from a provided iterator.
pub fn recover_with_stream<T, E, S, Alt, AltIter>(
  mut alternatives: AltIter,
  source: S,
) -> impl Stream<Item = T>
where
  S: Stream<Item = Result<T, E>> + Send + 'static,
  Alt: Stream<Item = Result<T, E>> + Send + 'static,
  AltIter: Iterator<Item = Alt> + Send + 'static,
  T: Send + 'static,
  E: Send + 'static,
{
  stream! {
    futures::pin_mut!(source);
    let mut current: Pin<Box<dyn Stream<Item = Result<T, E>> + Send>> = Box::pin(source);
    
    loop {
      let mut errored = false;
      while let Some(result) = current.next().await {
        match result {
          Ok(value) => yield value,
          Err(_) => {
            errored = true;
            break;
          }
        }
      }
      
      if !errored {
        break;  // Completed successfully
      }
      
      // Try next alternative
      match alternatives.next() {
        Some(alt) => current = Box::pin(alt),
        None => break,  // No more alternatives
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod recover_with_stream_tests {
  use super::*;
  
  #[derive(Debug, Clone)]
  struct TestErr;
  
  #[tokio::test]
  async fn test_recover_with_stream_success() {
    let source = futures::stream::iter(vec![Ok::<i32, TestErr>(1), Ok(2), Ok(3)]);
    let alts: Vec<Pin<Box<dyn Stream<Item = Result<i32, TestErr>> + Send>>> = vec![];
    
    let values: Vec<_> = recover_with_stream(alts.into_iter(), source).collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }
  
  #[tokio::test]
  async fn test_recover_with_stream_uses_alternative() {
    let source = futures::stream::iter(vec![Ok(1), Err(TestErr), Ok(3)]);
    let alt = futures::stream::iter(vec![Ok(10), Ok(20)]);
    let alts: Vec<Pin<Box<dyn Stream<Item = Result<i32, TestErr>> + Send>>> = vec![Box::pin(alt)];
    
    let values: Vec<_> = recover_with_stream(alts.into_iter(), source).collect().await;
    assert_eq!(values, vec![1, 10, 20]);
  }
}
#+end_src

** =throwError=

The =throwError= function creates a stream that immediately throws an error when consumed.

*** When to Use

Use =throwError= to create a stream that immediately fails. Useful for testing error handling, conditional error injection, or signaling failures in stream compositions.

#+begin_src text :tangle no
throwError(new Error('fail')):  X
                                ^
                                immediately throws#+end_src

#+begin_src javascript :tangle no
// Validate input before processing
const validated = input.isValid
  ? from(input.data)
  : throwError(new Error('Invalid input'))

// Test error handling
const mockFailingApi = throwError(new Error('Network timeout'))
await expectStream(pipe(
  mockFailingApi,
  recoverWith(() => just('fallback'))
)).toEmit(['fallback'])

// Conditional failure in pipeline
const checked = pipe(
  items,
  chain(item => item.required 
    ? just(item) 
    : throwError(new Error(`Missing required: ${item.name}`))
  )
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that immediately throws an error when consumed.
 */
export async function* throwError<E = unknown>(
    error: E
): AsyncGenerator<never, void, void> {
  throw error
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('throwError', () => {
  it('creates a stream that immediately errors', async () => {
    await expectStream(throwError(new Error('test error')))
      .toErrorWith('test error')
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def throw_error(error: Exception) -> AsyncIterator[Any]:
  """Creates a stream that immediately throws an error."""
  raise error
  yield # Makes this a generator
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestThrowError:
  async def test_throws_error(self):
    with pytest.raises(ValueError, match="oops"):
      await collect(throw_error(ValueError("oops")))
#+end_src

*** Rust Implementation

In Rust, we'd emit an =Err= in a Result stream:

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a stream that immediately emits an error.
pub fn throw_error<T, E: Clone>(error: E) -> impl Stream<Item = Result<T, E>> {
  stream::once(async move { Err(error) })
}

// For panicking (not recommended for production):
pub fn throw_panic<T>(message: &'static str) -> impl Stream<Item = T> {
  stream! {
    panic!("{}", message);
    // Unreachable, but helps type inference:
    #[allow(unreachable_code)]
    loop { yield unreachable!(); }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod throw_error_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_throw_error_emits_error() {
    let err_stream = throw_error::<i32, _>("test error".to_string());
    let results: Vec<_> = err_stream.collect().await;
    
    assert_eq!(results.len(), 1);
    assert!(results[0].is_err());
  }
}
#+end_src

** =retry=

The =retry= function attempts to resubscribe to a stream when it errors.
You can specify the maximum number of retry attempts.
*** When to Use

Use =retry= when operations may fail transiently (network issues, rate limits, temporary unavailability). Provide a *factory function* that creates fresh streams for each attempt.

#+begin_src text :tangle no
streamFactory():    --1--X     (fails)
retry(3):           --1--X     (attempt 1)
                    --1--X     (attempt 2)
                    --1--2--|  (attempt 3: success!)
result:             --1--2--|#+end_src

#+begin_src javascript :tangle no
// Simple retry with max attempts
const resilientFetch = retry(3, () => 
  fromPromise(fetch('/api/data').then(r => r.json()))
)

// Retry with exponential backoff
const withBackoff = retry({
  maxAttempts: 5,
  delayMs: 1000,  // Start with 1s delay
  shouldRetry: (err, attempt) => {
    console.log(`Attempt ${attempt} failed:`, err)
    return true
  }
}, () => fetchLatestData())

// Retry only specific errors
const selectiveRetry = retry({
  maxAttempts: 3,
  shouldRetry: (err) => {
    // Only retry network errors, not validation errors
    return err.name === 'NetworkError' || err.status === 503
  }
}, () => apiCall())

// Combine with recoverWith for fallback after all retries fail
const withFallback = pipe(
  retry(3, () => primaryApi()),
  recoverWith(() => just(fallbackData))
)
#+end_src

*** Typescript Implementation

*Note:* Error handling in streams is an evolving area. This implementation provides a simple retry mechanism,
but more sophisticated approaches (exponential backoff, conditional retries, etc.) may be needed for production use.
Consider wrapping =retry= with custom logic for your specific needs.

#+begin_src typescript :tangle typescript/index.ts
/**
 * Options for retry behavior.
 */
export interface RetryOptions {
  /** Maximum number of retry attempts (default: 3) */
  maxAttempts?: number
  /** Delay between retries in milliseconds (default: 0) */
  delayMs?: number
  /** Optional predicate to decide whether to retry based on the error */
  shouldRetry?: (error: unknown, attempt: number) => boolean
}

/**
 * Retries a stream factory when it errors.
 * 
 * @param options - Retry configuration
 * @param streamFactory - A function that creates the stream to retry
 */
export function retry<T>(
  options: RetryOptions | number
): (streamFactory: () => AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function retry<T>(
  options: RetryOptions | number,
  streamFactory: () => AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function retry<T>(
  options: RetryOptions | number,
  streamFactory?: () => AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((streamFactory: () => AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  const opts: RetryOptions = typeof options === 'number' ? { maxAttempts: options } : options
  const { maxAttempts = 3, delayMs = 0, shouldRetry = () => true } = opts

  if (streamFactory === undefined) return (sf: () => AsyncIterable<T>) => retry(opts, sf);
  
  const factory = streamFactory
  return (async function* () {
    let attempt = 0
    while (true) {
      try {
        yield* factory()
        return // Success, exit
      } catch (error) {
        attempt++
        if (attempt >= maxAttempts || !shouldRetry(error, attempt)) { throw error }
        if (delayMs > 0) { await new Promise(r => setTimeout(r, delayMs)) }
        // Continue to next attempt
      }
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('retry', () => {
  it('retries on error up to maxAttempts', async () => {
    let attempts = 0
    const values = await collect(retry(3, () => {
      attempts++
      if (attempts < 3) return throwError(new Error('fail'))
      return from([1, 2, 3])
    }))
    expect(attempts).toBe(3)
    expect(values).toEqual([1, 2, 3])
  })

  it('throws after maxAttempts exceeded', async () => {
    let attempts = 0
    await expect(collect(retry(2, () => {
      attempts++
      return throwError(new Error('always fails'))
    }))).rejects.toThrow('always fails')
    expect(attempts).toBe(2)
  })

  it('supports options object', async () => {
    let attempts = 0
    await collect(retry({ maxAttempts: 2, delayMs: 10 }, () => {
      attempts++
      if (attempts < 2) return throwError(new Error('fail'))
      return from(['ok'])
    }))
    expect(attempts).toBe(2)
  })

  it('supports shouldRetry predicate', async () => {
    let attempts = 0
    await expect(collect(retry({
      maxAttempts: 5,
      shouldRetry: (err, attempt) => attempt < 2
    }, () => {
      attempts++
      return throwError(new Error('fail'))
    }))).rejects.toThrow('fail')
    expect(attempts).toBe(2)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@dataclass
class RetryOptions:
  """Options for retry behavior."""
  max_attempts: int = 3
  delay_seconds: float = 0.0
  should_retry: Optional[Callable[[Exception, int], bool]] = None


@overload
def retry(
  options: Union[RetryOptions, int]
) -> Callable[[Callable[[], AsyncIterable[T]]], AsyncIterator[T]]: ...
@overload
def retry(
  options: Union[RetryOptions, int],
  stream_factory: Callable[[], AsyncIterable[T]]
) -> AsyncIterator[T]: ...

def retry(
  options: Union[RetryOptions, int],
  stream_factory: Optional[Callable[[], AsyncIterable[T]]] = None
):
  """Retries a stream factory when it errors."""
  opts = RetryOptions(max_attempts=options) if isinstance(options, int) else options

  async def _retry(factory: Callable[[], AsyncIterable[T]]) -> AsyncIterator[T]:
    attempt = 0
    while True:
      try:
        async for item in factory():
          yield item
        return # Success
      except Exception as e:
        attempt += 1
        should_retry = opts.should_retry(e, attempt) if opts.should_retry else True
        if attempt >= opts.max_attempts or not should_retry:
          raise
        if opts.delay_seconds > 0:
          await asyncio.sleep(opts.delay_seconds)

  if stream_factory is None:
    return _retry
  return _retry(stream_factory)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestRetry:
  async def test_retries_until_success(self):
    attempt = 0
    
    def create_stream():
      nonlocal attempt
      attempt += 1
      async def stream():
        if attempt < 3:
          yield attempt
          raise ValueError(f"fail {attempt}")
        else:
          yield attempt
      return stream()
    
    result = await collect(retry(3, create_stream))
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
pub struct RetryOptions<F> {
  pub max_attempts: usize,
  pub delay_ms: u64,
  pub should_retry: F,
}

/// Retry a stream factory on error.
/// Uses the Runtime trait for delay functionality.
pub fn retry<R, T, E, S, F>(
  max_attempts: usize,
  delay_ms: u64,
  mut stream_factory: F,
) -> impl Stream<Item = Result<T, E>>
where
  R: Runtime,
  S: Stream<Item = Result<T, E>>,
  F: FnMut() -> S,
  E: Clone,
{
  stream! {
    let mut attempt = 0;
    loop {
      let s = stream_factory();
      futures::pin_mut!(s);
      let mut failed = false;
      
      while let Some(item) = s.next().await {
        match item {
          Ok(value) => yield Ok(value),
          Err(e) => {
            attempt += 1;
            if attempt >= max_attempts {
              yield Err(e);
              return;
            }
            if delay_ms > 0 {  R::sleep(Duration::from_millis(delay_ms)).await; }
            failed = true;
            break;
          }
        }
      }
      
      if !failed { return; } // Stream completed successfully
    }
  }
}

/// Runtime-agnostic retry with custom sleep function
pub fn retry_with<T, E, S, F, SF, SFut>(
  max_attempts: usize,
  delay_ms: u64,
  mut stream_factory: F,
  sleep_fn: SF,
) -> impl Stream<Item = Result<T, E>>
where
  S: Stream<Item = Result<T, E>>,
  F: FnMut() -> S,
  E: Clone,
  SF: Fn(Duration) -> SFut,
  SFut: std::future::Future<Output = ()>,
{
  stream! {
    let mut attempt = 0;
    loop {
      let s = stream_factory();
      futures::pin_mut!(s);
      let mut failed = false;
      
      while let Some(item) = s.next().await {
        match item {
          Ok(value) => yield Ok(value),
          Err(e) => {
            attempt += 1;
            if attempt >= max_attempts {
              yield Err(e);
              return;
            }
            if delay_ms > 0 { sleep_fn(Duration::from_millis(delay_ms)).await; }
            failed = true;
            break;
          }
        }
      }
      
      if !failed { return; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod retry_tests {
  use super::*;
  
  // Simple clone-able error for testing
  #[derive(Debug, Clone, PartialEq)]
  struct TestError(String);
  
  #[tokio::test]
  async fn test_retry_with_success() {
    let values: Vec<Result<i32, TestError>> = retry_with(
      3,
      10,
      || futures::stream::iter(vec![Ok(1), Ok(2), Ok(3)]),
      |_d| std::future::ready(()),
    ).collect().await;
    let ok_values: Vec<_> = values.into_iter().filter_map(|r| r.ok()).collect();
    assert_eq!(ok_values, vec![1, 2, 3]);
  }

  #[tokio::test]
  async fn test_retry_with_eventual_success() {
    use std::sync::atomic::{AtomicUsize, Ordering};
    use std::sync::Arc;
    let attempt = Arc::new(AtomicUsize::new(0));
    let attempt_clone = attempt.clone();
    let values: Vec<Result<i32, TestError>> = retry_with(
      3,
      0,
      move || {
        let n = attempt_clone.fetch_add(1, Ordering::SeqCst);
        if n < 2 { futures::stream::iter(vec![Err(TestError("fail".into()))]) }
        else { futures::stream::iter(vec![Ok(42)]) }
      },
      |_d| std::future::ready(()),
    ).collect().await;
    let ok_values: Vec<_> = values.into_iter().filter_map(|r| r.ok()).collect();
    assert_eq!(ok_values, vec![42]);
  }
}
#+end_src

* Concurrent Operations

This section covers operations that work with multiple streams concurrently.
These require internal helpers that use =Promise.race= to handle multiple async iterators simultaneously.

** Concurrency Helpers

The key insight is that while =for await...of= is sequential, we can race multiple =.next()= calls concurrently:

#+begin_src text :tangle no
Sequential (for await):       Concurrent (Promise.race):
                              
  iter.next()                   Promise.race([
      │                           iterA.next(),
      ▼                           iterB.next(),
  iter.next()                     iterC.next()
      │                         ])
      ▼                             │
  iter.next()                       ▼
      │                         Winner emits first
      ▼
  ...waits for each             Re-queue winner, race again#+end_src

*** =raceIterators=

The =raceIterators= function races multiple async iterators, yielding values tagged with their source index as they arrive.
This is the core building block for merge, latest, and other concurrent operations.

**** Algorithm

1. *Initialize*: For each iterator, call =.next()= and store the pending promise in a Map keyed by index
2. *Race*: Use =Promise.race= to await whichever promise resolves first
3. *Handle result*:
   - If =done=: Remove that iterator from the pending map
   - If value: Yield ={index, value}=, then re-queue a new =.next()= promise for that iterator
4. *Repeat* until all iterators are exhausted (pending map is empty)

#+begin_src typescript :tangle typescript/index.ts
type TaggedResult<T> = { index: number; value: T }

/**
 * Races multiple async iterators, yielding values tagged with their source index.
 * Values are emitted as soon as any iterator produces one.
 */
async function* raceIterators<T>(
  iterators: AsyncIterator<T>[]
): AsyncGenerator<TaggedResult<T>, void, void> {
  const pending = new Map<number, Promise<{ index: number; result: IteratorResult<T> }>>()

  // Start all iterators
  for (let i = 0; i < iterators.length; i++)
    pending.set(i, iterators[i].next().then(result => ({ index: i, result })))

  while (pending.size > 0) {
    const { index, result } = await Promise.race(pending.values())

    if (result.done) pending.delete(index)
    else {
      yield { index, value: result.value }
      pending.set(index, iterators[index].next().then(result => ({ index, result })))
    }
  }
}
#+end_src

*** =raceIteratorsWithOuter=

The =raceIteratorsWithOuter= function extends =raceIterators= to also race against an outer stream that can add new iterators dynamically.
This is used for =mergeAll= and =chain= where inner streams are created as the outer stream emits.

#+begin_src typescript :tangle typescript/index.ts
type RaceResult<T, O> =
  | { type: 'inner'; index: number; value: T }
  | { type: 'outer'; value: O }
  | { type: 'outerDone' }

/**
 * Races inner iterators against an outer stream that produces new iterables.
 * Useful for mergeAll/chain where we need to race existing inner streams
 * while also listening for new streams from the outer source.
 */
async function* raceIteratorsWithOuter<T, O>(
  outerIterator: AsyncIterator<O>,
  getInnerIterator: (value: O) => AsyncIterator<T>
): AsyncGenerator<RaceResult<T, O>, void, void> {
  const innerIterators: AsyncIterator<T>[] = []
  const pending = new Map<number | 'outer', Promise<{ key: number | 'outer'; result: IteratorResult<any> }>>()

  // Start listening to outer
  pending.set('outer', outerIterator.next().then(result => ({ key: 'outer' as const, result })))

  while (pending.size > 0) {
    const { key, result } = await Promise.race(pending.values())

    if (key === 'outer') {
      if (result.done) {
        pending.delete('outer')
        yield { type: 'outerDone' }
      } else {
        yield { type: 'outer', value: result.value }
        // Add new inner iterator
        const innerIndex = innerIterators.length
        const innerIterator = getInnerIterator(result.value)
        innerIterators.push(innerIterator)
        pending.set(innerIndex, innerIterator.next().then(result => ({ key: innerIndex, result })))
        // Continue listening to outer
        pending.set('outer', outerIterator.next().then(result => ({ key: 'outer' as const, result })))
      }
    } else {
      // Inner iterator result
      const index = key as number
      if (result.done) pending.delete(index)
      else {
        yield { type: 'inner', index, value: result.value }
        pending.set(index, innerIterators[index].next().then(result => ({ key: index, result })))
      }
    }
  }
}
#+end_src

** =merge=

The =merge= function merges multiple streams into a single stream, emitting values from any stream as they arrive.

*** When to Use

Use =merge= to combine multiple streams into one, emitting values from any source as they arrive. Order depends on timing, not input order. All sources run concurrently.

#+begin_src text :tangle no
stream A:      --1-----3-----5--|
stream B:      ----2-----4-----|
merge(A, B):   --1-2---3-4---5--|
                 ^ ^   ^ ^
                 interleaved by arrival time#+end_src

#+begin_src javascript :tangle no
// Combine multiple event sources
const allClicks = merge(
  fromEvent(button1, 'click'),
  fromEvent(button2, 'click'),
  fromEvent(button3, 'click')
)

// Poll multiple APIs simultaneously
const allData = merge(
  pollApi('/api/users'),
  pollApi('/api/orders'),
  pollApi('/api/inventory')
)

// First-wins pattern
const fastest = pipe(
  merge(
    fromPromise(fetchFromCdn()),
    fromPromise(fetchFromOrigin())
  ),
  take(1)
)

// Combine user actions with system events
const allEvents = merge(
  userActions,
  systemNotifications,
  timerTicks
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Merges multiple streams into a single stream, emitting values as they arrive.
 */
export async function* merge<T>(
  ...streams: AsyncIterable<T>[]
): AsyncGenerator<T, void, void> {
  const iterators = streams.map(s => s[Symbol.asyncIterator]())
  for await (const { value } of raceIterators(iterators)) yield value
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('merge', () => {
  it('merges multiple streams', async () => {
    const a = createAsyncIterable([1, 3], { delay: 20 })
    const b = createAsyncIterable([2, 4], { delay: 20, initialDelay: 10 })
    const result = await collect(merge(a, b))
    expect(result).toEqual([1, 2, 3, 4])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def merge(*streams: AsyncIterable[T]) -> AsyncIterator[T]:
  """Merges multiple streams into one, emitting values as they arrive."""
  async def consume_stream(
    stream: AsyncIterable[T],
    queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]],
    index: int
  ):
    try:
      async for item in stream:
        await queue.put((index, item, False, None))
      await queue.put((index, None, True, None)) # Signal completion
    except Exception as e:
      await queue.put((index, None, True, e))

  queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]] = asyncio.Queue()
  tasks = [asyncio.create_task(consume_stream(stream, queue, i)) for i, stream in enumerate(streams)]

  active = len(streams)
  try:
    while active > 0:
      index, value, done, error = await queue.get()
      if error:
        raise error
      if done:
        active -= 1
      else:
        yield value # type: ignore
  finally:
    for task in tasks:
      task.cancel()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestMerge:
  async def test_merges_streams(self):
    async def slow_stream():
      yield 1
      await asyncio.sleep(0.02)
      yield 3
    
    async def fast_stream():
      await asyncio.sleep(0.01)
      yield 2
    
    result = await collect(merge(slow_stream(), fast_stream()))
    assert sorted(result) == [1, 2, 3]
#+end_src

*** Rust Implementation

The =futures= crate provides built-in merge functionality that is runtime-agnostic. We re-export these as =merge= and =merge_all= for API consistency:

#+begin_src rust :tangle rust/src/lib.rs
/// Merge two streams, interleaving values as they arrive.
/// 
/// # Note
/// This is an alias for `futures::stream::select`. Prefer using the built-in directly:
/// ```rust,ignore
/// use futures::stream;
/// let merged = stream::select(s1, s2);
/// ```
pub use futures::stream::select as merge;

/// Merge multiple streams, interleaving values as they arrive.
/// 
/// # Note
/// This is an alias for `futures::stream::select_all`. Prefer using the built-in directly:
/// ```rust,ignore
/// use futures::stream;
/// let merged = stream::select_all(streams);
/// ```
pub use futures::stream::select_all as merge_all;
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod merge_tests {
  use super::*;
  #[tokio::test]
  async fn test_merge() {
    let s1 = futures::stream::iter(vec![1, 3, 5]);
    let s2 = futures::stream::iter(vec![2, 4, 6]);
    let values: Vec<_> = merge(s1, s2).collect().await;
    // Order may vary due to select fairness, but all values should be present
    assert_eq!(values.len(), 6);
    assert!(values.contains(&1));
    assert!(values.contains(&6));
  }

  #[tokio::test]
  async fn test_merge_all() {
    let streams = vec![
      Box::pin(futures::stream::iter(vec![1, 2])),
      Box::pin(futures::stream::iter(vec![3, 4])),
    ];
    let values: Vec<_> = merge_all(streams).collect().await;
    assert_eq!(values.len(), 4);
  }
}
#+end_src

** =mergeAll=

The =mergeAll= function flattens a stream of streams by merging them into a single stream.

*** When to Use

Use =mergeAll= to flatten a stream of streams concurrently. Unlike =concatAll= (which waits for each inner to complete), =mergeAll= runs all inner streams simultaneously.

#+begin_src text :tangle no
outer:        --[A]-----[B]------|
A:               1--2--3|
B:                       4--5|
mergeAll:     ---1--2--3-4--5---|
                 ^       ^
                 A and B values interleaved
                 (A starts first, B joins while A active)
#+end_src

#+begin_src javascript :tangle no
// Fetch all URLs concurrently
const allResponses = pipe(
  from(urls),
  map(url => fromPromise(fetch(url))),
  mergeAll  // All fetches run in parallel
)

// Process queue items concurrently
const results = pipe(
  jobQueue,
  map(job => processJob(job)),
  mergeAll
)

// Flatten nested data with concurrency
const allItems = pipe(
  categories,
  map(cat => from(cat.items)),
  mergeAll
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Flattens a stream of streams by merging them into a single stream.
 */
export async function* mergeAll<T>(
  streamOfStreams: AsyncIterable<AsyncIterable<T>>,
): AsyncGenerator<T, void, void> {
  const outerIterator = streamOfStreams[Symbol.asyncIterator]()
  for await (const result of raceIteratorsWithOuter(outerIterator, s => s[Symbol.asyncIterator]()))
    if (result.type === 'inner') yield result.value
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('mergeAll', () => {
  it('flattens stream of streams concurrently', async () => {
    const streams = from([from([1, 2]), from([3, 4])])
    const values = await collect(mergeAll(streams))
    // Order may vary, but all values should be present
    expect(values.sort()).toEqual([1, 2, 3, 4])
  })

  it('handles empty outer stream', async () => {
    const values = await collect(mergeAll(empty()))
    expect(values).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def merge_all(stream_of_streams: AsyncIterable[AsyncIterable[T]]) -> AsyncIterator[T]:
  """Flattens a stream of streams by merging them concurrently."""
  queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue()
  active_count = 0
  outer_done = False
  tasks: List[asyncio.Task] = []

  async def consume_inner(stream: AsyncIterable[T]):
    nonlocal active_count
    try:
      async for item in stream:
        await queue.put((item, False, None))
    except Exception as e:
      await queue.put((None, True, e))
    finally:
      active_count -= 1
      if outer_done and active_count == 0:
        await queue.put((None, True, None)) # All done

  async def consume_outer():
    nonlocal outer_done, active_count
    async for inner_stream in stream_of_streams:
      active_count += 1
      task = asyncio.create_task(consume_inner(inner_stream))
      tasks.append(task)
    outer_done = True
    if active_count == 0:
      await queue.put((None, True, None)) # No inner streams

  outer_task = asyncio.create_task(consume_outer())
  tasks.append(outer_task)

  try:
    while True:
      value, done, error = await queue.get()
      if error:
        raise error
      if done:
        break
      yield value # type: ignore
  finally:
    for task in tasks:
      task.cancel()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestMergeAll:
  async def test_merges_stream_of_streams(self):
    async def stream_of_streams():
      yield from_iter([1, 2])
      yield from_iter([3, 4])
    
    result = await collect(merge_all(stream_of_streams()))
    assert sorted(result) == [1, 2, 3, 4]
#+end_src

*** Rust Implementation

=StreamExt::flatten_unordered= provides concurrent flattening:

#+begin_src rust :tangle rust/src/lib.rs
// Built-in: outer.flatten_unordered(None) // None = unlimited concurrency
// Or: outer.flatten_unordered(Some(10))  // limit to 10 concurrent streams

// For production, use flatten_unordered from futures
// merge_all is defined above for Vec<S>, use stream.flatten_unordered(None) for streams of streams
#+end_src

** =chain= / =flatMap=

The =chain= function (also exported as =flatMap=) maps each value from the source stream to a new stream and flattens the resulting streams into a single stream.
You can think of it as a combination of a =map= producing streams being run through =mergeAll=.

Note, that it doesn't concatenate the inner streams, but interleaves them as values become available.

#+begin_src text :tangle no
stream:            -a----b----c|
f(a):               1--2--3|
f(b):                    1----2----3|
f(c):                           1-2-3|
stream.chain(f):   -1--2-13---2-1-233|
#+end_src

*** When to Use

Use =chain= (or its alias =flatMap=) when each input produces multiple async outputs that should all run concurrently.
This is the go-to operator for =for each X, do Y and flatten results=.


#+begin_src javascript :tangle no
// Fetch related data for each user
const userPosts = pipe(
  userIds,
  chain(id => fromPromise(fetchUserPosts(id)))
)

// Parallel file processing
const allLines = pipe(
  filePaths,
  chain(path => readFileLines(path))
)

// Expand and process concurrently
const processedItems = pipe(
  categories,
  chain(cat => pipe(
    from(cat.items),
    map(processItem)
  ))
)

// Retry pattern using chain
const withRetries = pipe(
  requests,
  chain(req => pipe(
    from([1, 2, 3]),  // 3 attempts
    concatMap(() => pipe(
      fromPromise(tryRequest(req)),
      recoverWith(() => empty())
    )),
    take(1)
  ))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Maps each value from the source stream to a new stream and flattens the resulting streams into a single stream.
 */
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function chain<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => chain(fn, s);
  return (async function* () {
    const outerIterator = stream[Symbol.asyncIterator]()
    for await (const result of raceIteratorsWithOuter(outerIterator, v => fn(v)[Symbol.asyncIterator]())) {
      if (result.type === 'inner') yield result.value
    }
  })();
}

export const flatMap = chain
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('chain / flatMap', () => {
  it('maps and merges inner streams', async () => {
    const values = await collect(chain(
      x => from([x, x * 10]),
      from([1, 2])
    ))
    // All values present, order may vary due to merging
    expect(values.sort((a, b) => a - b)).toEqual([1, 2, 10, 20])
  })

  it('flatMap is an alias for chain', () => {
    expect(flatMap).toBe(chain)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def chain(
  fn: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def chain(
  fn: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def chain(
  fn: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream and merges results concurrently."""
  async def _chain(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async def mapped_streams():
      async for item in s:
        yield fn(item)

    async for result in merge_all(mapped_streams()):
      yield result

  if stream is None:
    return _chain
  return _chain(stream)

# Alias for chain
flat_map = chain
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestChain:
  async def test_maps_and_merges(self):
    result = await collect(pipe(
      from_iter([1, 2]),
      chain(lambda x: from_iter([x, x * 10]))
    ))
    assert sorted(result) == [1, 2, 10, 20]
#+end_src

*** Rust Implementation

=StreamExt::flat_map_unordered= provides concurrent flatMap:

#+begin_src rust :tangle rust/src/lib.rs
// Built-in concurrent flatMap:
// stream.flat_map_unordered(None, |item| create_inner_stream(item))

// For sequential flatMap (like concatMap), use flat_map:
// stream.flat_map(|item| create_inner_stream(item))

// Custom implementation using sequential flattening:
pub fn flat_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
  S: Stream<Item = T>,
  Inner: Stream<Item = U>,
  F: Fn(T) -> Inner,
{
  s.map(f).flatten()
}

// Alias
pub fn chain<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
  S: Stream<Item = T>,
  Inner: Stream<Item = U>,
  F: Fn(T) -> Inner,
{
  flat_map(f, s)
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod chain_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_chain_flattens() {
    let source = futures::stream::iter(vec![1, 2]);
    let result = chain(
      |x: i32| futures::stream::iter(vec![x * 10, x * 10 + 1]),
      source,
    );
    
    let values: Vec<_> = result.collect().await;
    // With sequential flatten(), order is preserved
    assert_eq!(values, vec![10, 11, 20, 21]);
  }
}
#+end_src

** =switchMap=

The =switchMap= operator is like =chain=, but cancels the previous inner stream whenever a new outer value arrives.
This is useful for scenarios like autocomplete, where you only care about the result from the latest query.

#+begin_src text :tangle no
stream:            -a------b------c|
f(a):               1--2--3--4--5|     (cancelled at b)
f(b):                      1--2|       (cancelled at c)
f(c):                             1-2-3|
stream.switchMap:  -1--2---1--2---1-2-3|
#+end_src

*** When to Use

Use =switchMap= when only the latest request matters and previous in-flight operations should be abandoned. The classic example is search autocomplete.

#+begin_src javascript :tangle no
// Search autocomplete (cancel stale searches)
const searchResults = pipe(
  fromEvent(searchInput, 'input'),
  debounce(300),
  map(e => e.target.value),
  switchMap(query => 
    query.length < 2 
      ? just([])
      : fromPromise(searchApi(query))
  )
)

// Tab content loading (cancel previous tab's fetch)
const tabContent = pipe(
  selectedTab,
  switchMap(tabId => fromPromise(fetchTabContent(tabId)))
)

// Live data that should always be fresh
const liveData = pipe(
  refreshTrigger,
  switchMap(() => fromPromise(fetchLatestData()))
)

// Form validation (cancel validation on new input)
const validationResult = pipe(
  formValue,
  debounce(200),
  switchMap(value => fromPromise(validateOnServer(value)))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Maps each value to a new stream, cancelling the previous inner stream when a new value arrives.
 * Only values from the most recent inner stream are emitted.
 * 
 * Useful for scenarios like autocomplete where only the latest request matters.
 */
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>
): (stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>;
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream: AsyncIterable<T>
): AsyncGenerator<U, void, void>;
export function switchMap<T, U>(
  fn: (value: T) => AsyncIterable<U>,
  stream?: AsyncIterable<T>,
): AsyncGenerator<U, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<U, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => switchMap(fn, s);
  return (async function* () {
    const outerIterator = stream[Symbol.asyncIterator]()
    let currentInnerIterator: AsyncIterator<U> | null = null
    let outerDone = false
    
    type PendingResult = 
      | { type: 'outer'; result: IteratorResult<T> }
      | { type: 'inner'; result: IteratorResult<U> }

    const pending = new Map<'outer' | 'inner', Promise<PendingResult>>()

    // Start listening to outer
    pending.set('outer', outerIterator.next().then(result => ({ type: 'outer' as const, result })))

    while (pending.size > 0) {
      const winner = await Promise.race(pending.values())

      if (winner.type === 'outer') {
        if (winner.result.done) {
          outerDone = true
          pending.delete('outer')
          // Continue processing current inner stream if any
        } else {
          // Cancel current inner stream (by removing from pending and not calling return)
          pending.delete('inner')
          // Start new inner stream
          currentInnerIterator = fn(winner.result.value)[Symbol.asyncIterator]()
          pending.set('inner', currentInnerIterator.next().then(result => ({ type: 'inner' as const, result })))
          // Continue listening to outer
          pending.set('outer', outerIterator.next().then(result => ({ type: 'outer' as const, result })))
        }
      } else {
        // Inner result
        if (winner.result.done) {
          pending.delete('inner')
          currentInnerIterator = null
          // If outer is also done, we're finished
        } else {
          yield winner.result.value
          // Continue listening to current inner
          pending.set('inner', currentInnerIterator!.next().then(result => ({ type: 'inner' as const, result })))
        }
      }
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('switchMap', () => {
  it('cancels previous inner stream on new outer value', async () => {
    // Fast outer, slow inner - should cancel early inner streams
    const outer = createAsyncIterable([1, 2, 3], { delay: 10 })
    const values = await collect(switchMap(
      x => createAsyncIterable([x * 10, x * 100], { delay: 30 }),
      outer
    ))
    // Only values from the last inner stream should complete
    expect(values).toContain(30)
    expect(values).toContain(300)
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(
      from([1]),
      switchMap(x => from([x, x * 2]))
    ))
    expect(values).toEqual([1, 2])
  })

  it('completes when outer and inner complete', async () => {
    const values = await collect(switchMap(
      x => from([x]),
      from([1, 2, 3])
    ))
    expect(values.length).toBeGreaterThan(0)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def switch_map(
  fn: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def switch_map(
  fn: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def switch_map(
  fn: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream, cancelling previous inner stream on new outer value."""
  async def _switch_map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    current_task: Optional[asyncio.Task] = None
    queue: asyncio.Queue[Tuple[Optional[U], bool, bool]] = asyncio.Queue()
    outer_done = False

    async def consume_inner(inner: AsyncIterable[U], generation: int):
      try:
        async for item in inner:
          await queue.put((item, False, False))
      except asyncio.CancelledError:
        pass
      finally:
        await queue.put((None, True, False)) # Inner done

    async def consume_outer(s: AsyncIterable[T]):
      nonlocal current_task, outer_done
      generation = 0
      async for item in s:
        if current_task:
          current_task.cancel()
        generation += 1
        current_task = asyncio.create_task(consume_inner(fn(item), generation))
      outer_done = True
      await queue.put((None, False, True)) # Outer done

    outer_task = asyncio.create_task(consume_outer(s))
    inner_done = True

    try:
      while True:
        value, is_inner_done, is_outer_done = await queue.get()
        if is_outer_done and inner_done:
          break
        if is_inner_done:
          inner_done = True
          if outer_done:
            break
        elif is_outer_done:
          if inner_done:
            break
        else:
          inner_done = False
          yield value # type: ignore
    finally:
      outer_task.cancel()
      if current_task:
        current_task.cancel()

  if stream is None:
    return _switch_map
  return _switch_map(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Switch to new inner stream on each outer value, cancelling previous.
/// Runtime-agnostic using futures::select!
pub fn switch_map<T, U, S, Inner, F>(f: F, s: S) -> impl Stream<Item = U>
where
  S: Stream<Item = T> + Unpin,
  Inner: Stream<Item = U> + Unpin,
  F: Fn(T) -> Inner,
{
  stream! {
    futures::pin_mut!(s);
    let mut current_inner: Option<std::pin::Pin<Box<dyn Stream<Item = U> + Unpin>>> = None;
    loop {
      futures::select! {
        // Check outer stream first (higher priority for switching)
        outer_item = s.next().fuse() => {
          match outer_item {
            Some(item) => {
              // Cancel old inner by dropping, start new one
              current_inner = Some(Box::pin(f(item)));
            }
            None => {
              // Outer done, drain current inner
              if let Some(ref mut inner) = current_inner { while let Some(v) = inner.next().await { yield v; } }
              break;
            }
          }
        }
        // Process current inner
        inner_item = async {
            if let Some(ref mut inner) = current_inner { inner.next().await }
            else {  std::future::pending().await }
        }.fuse() => {
            match inner_item {
                Some(v) => yield v,
                None => current_inner = None,
            }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod switch_map_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_switch_map_switches() {
    // With synchronous inner streams, switchMap behaves like concatMap
    // True switching requires async timing
    let source = futures::stream::iter(vec![1, 2]);
    let result = switch_map(
      |x: i32| futures::stream::iter(vec![x * 10]),
      source,
    );
    
    let values: Vec<_> = result.collect().await;
    // May see values from both or just last depending on timing
    assert!(!values.is_empty());
  }
}
#+end_src

** =latest=

The =latest= function combines multiple streams into a single stream that emits a tuple of the latest values from each input stream whenever any of them emit a new value.

We use a mapped tuple type to preserve the individual types of each stream in the output tuple.

*** When to Use

Use =latest= to combine multiple streams where you need the current value from each. Emits only after all streams have produced at least one value, then on every subsequent emission from any stream.

#+begin_src text :tangle no
stream A:      --1-----3---------5--|
stream B:      ----a-------b--------|
latest([A,B]): ----[1,a]-[3,a]-[3,b]-[5,b]|
               ^^^^^^^^^^
               waits for both, then emits on any change#+end_src

#+begin_src javascript :tangle no
// Combine width and height for calculations
const dimensions = pipe(
  latest([widthStream, heightStream]),
  map(([w, h]) => ({ width: w, height: h, area: w * h }))
)

// React to changes in any of multiple inputs
const formState = pipe(
  latest([nameField, emailField, passwordField]),
  map(([name, email, password]) => ({ name, email, password }))
)

// Price calculator with live updates
const totalPrice = pipe(
  latest([quantityStream, unitPriceStream, discountStream]),
  map(([qty, price, discount]) => qty * price * (1 - discount))
)

// Synchronized state from multiple sources
const dashboardState = pipe(
  latest([userStream, settingsStream, dataStream]),
  map(([user, settings, data]) => ({ user, settings, data }))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Extracts the element type from an AsyncIterable.
 */
type AsyncIterableValue<T> = T extends AsyncIterable<infer U> ? U : never

/**
 * Maps a tuple of AsyncIterables to a tuple of their element types.
 */
type LatestValues<T extends readonly AsyncIterable<any>[]> = {
  [K in keyof T]: AsyncIterableValue<T[K]>
}

/**
 * Combines multiple streams into a single stream that emits a tuple of the latest values
 * from each input stream whenever any of them emit a new value.
 * 
 * Type-safe: preserves individual stream types in the output tuple.
 */
export async function* latest<T extends readonly AsyncIterable<any>[]>(
  streams: [...T],
): AsyncGenerator<LatestValues<T>, void, void> {
  const iterators = streams.map(s => s[Symbol.asyncIterator]())
  const latestValues: any[] = new Array(streams.length)
  const hasValue: boolean[] = new Array(streams.length).fill(false)
  let hasAllValues = false

  for await (const { index, value } of raceIterators(iterators)) {
    latestValues[index] = value
    hasValue[index] = true
    if (!hasAllValues) hasAllValues = hasValue.every(Boolean)
    if (hasAllValues) yield [...latestValues] as LatestValues<T>
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('latest', () => {
  it('emits tuple of latest values after all streams have emitted', async () => {
    const a = from([1, 2])
    const b = from(['x', 'y'])
    const values = await collect(latest([a, b]))
    // After both emit, we should get tuples
    expect(values.length).toBeGreaterThan(0)
    // Each tuple should have a number and string
    values.forEach(([n, s]) => {
      expect(typeof n).toBe('number')
      expect(typeof s).toBe('string')
    })
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def latest(*streams: AsyncIterable[T]) -> AsyncIterator[Tuple[T, ...]]:
  """Combines streams, emitting tuple of latest values when any emits."""
  latest_values: List[Optional[T]] = [None] * len(streams)
  has_value: List[bool] = [False] * len(streams)
  queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]] = asyncio.Queue()

  async def consume_stream(stream: AsyncIterable[T], index: int):
    try:
      async for item in stream:
        await queue.put((index, item, False, None))
      await queue.put((index, None, True, None))
    except Exception as e:
      await queue.put((index, None, True, e))

  tasks = [asyncio.create_task(consume_stream(stream, i)) for i, stream in enumerate(streams)]

  active = len(streams)
  try:
    while active > 0:
      index, value, done, error = await queue.get()
      if error:
        raise error
      if done:
        active -= 1
      else:
        latest_values[index] = value
        has_value[index] = True
        if all(has_value):
          yield tuple(latest_values) # type: ignore
  finally:
    for task in tasks:
      task.cancel()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestLatest:
  async def test_combines_latest(self):
    async def stream_a():
      yield 1
      await asyncio.sleep(0.02)
      yield 2
    
    async def stream_b():
      await asyncio.sleep(0.01)
      yield "a"
      await asyncio.sleep(0.02)
      yield "b"
    
    result = await collect(latest(stream_a(), stream_b()))
    # After first emit from both: (1, "a")
    # After 2 from a: (2, "a") 
    # After "b" from b: (2, "b")
    assert len(result) >= 1
#+end_src

*** Rust Implementation

Using =futures::select!= for runtime-agnostic stream combination:

#+begin_src rust :tangle rust/src/lib.rs
/// Combine two streams, emitting tuple of latest values.
/// Runtime-agnostic using stream merging.
pub fn latest2<T: Clone + Send + 'static, U: Clone + Send + 'static>(
  s1: impl Stream<Item = T> + Send + 'static,
  s2: impl Stream<Item = U> + Send + 'static,
) -> impl Stream<Item = (T, U)> {
  // Tag values with which stream they came from
  enum Either<A, B> { Left(A), Right(B) }
  
  // Box the mapped streams to make them Unpin
  let tagged1: Pin<Box<dyn Stream<Item = Either<T, U>> + Send>> = 
    Box::pin(s1.map(Either::Left));
  let tagged2: Pin<Box<dyn Stream<Item = Either<T, U>> + Send>> = 
    Box::pin(s2.map(Either::Right));
  
  stream! {
    let mut latest1: Option<T> = None;
    let mut latest2: Option<U> = None;
    
    let mut merged = futures::stream::select(tagged1, tagged2);
    
    while let Some(item) = merged.next().await {
      match item {
        Either::Left(v) => {
          latest1 = Some(v);
          if let (Some(ref a), Some(ref b)) = (&latest1, &latest2) {
            yield (a.clone(), b.clone());
          }
        }
        Either::Right(v) => {
          latest2 = Some(v);
          if let (Some(ref a), Some(ref b)) = (&latest1, &latest2) {
            yield (a.clone(), b.clone());
          }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod latest2_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_latest2_combines() {
    let s1 = futures::stream::iter(vec![1, 2]);
    let s2 = futures::stream::iter(vec!["a", "b"]);
    
    let values: Vec<_> = latest2(s1, s2).collect().await;
    // Should emit tuples when both have values
    assert!(!values.is_empty());
  }
}
#+end_src

** =applyLatest=

The =applyLatest= function applies the latest function from a stream of functions to the latest value from a stream of values.

*** When to Use

Use =applyLatest= for applicative-style stream composition where you have a stream of functions and a stream of values. Each time either changes, apply the current function to the current value.

#+begin_src text :tangle no
functions:     f----g---------|
values:        --1----2-------|
applyLatest:   --f(1)-g(1)g(2)|#+end_src

#+begin_src javascript :tangle no
// Dynamic formatting based on locale
const formattedPrices = applyLatest(
  pipe(localeStream, map(locale => price => formatPrice(price, locale))),
  priceStream
)

// Apply current validation rules to form value
const validationResults = applyLatest(
  validationRulesStream,  // Stream of validator functions
  formValueStream
)

// Dynamic sorting
const sortedItems = applyLatest(
  pipe(sortConfigStream, map(config => items => sortItems(items, config))),
  itemsStream
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Applies the latest function from a stream of functions to the latest value from a stream of values.
 */
export async function* applyLatest<T, U>(
  fnStream: AsyncIterable<(value: T) => U>,
  valueStream: AsyncIterable<T>,
): AsyncGenerator<U, void, void> {
  yield* map(
    ([fn, value]) => fn(value),
    latest([fnStream, valueStream]),
  );
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('applyLatest', () => {
  it('applies latest function to latest value', async () => {
    const fns = from([(x: number) => x * 2, (x: number) => x * 3])
    const vals = from([10, 20])
    const values = await collect(applyLatest(fns, vals))
    expect(values.length).toBeGreaterThan(0)
    // Results should be numbers
    values.forEach(v => expect(typeof v).toBe('number'))
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def apply_latest(
  fn_stream: AsyncIterable[Callable[[T], U]],
  value_stream: AsyncIterable[T]
) -> AsyncIterator[U]:
  """Applies the latest function to the latest value."""
  async for fn, value in latest(fn_stream, value_stream): # type: ignore
    yield fn(value)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Apply latest function to latest value.
pub fn apply_latest<T, U, F, S1, S2>(fn_stream: S1, value_stream: S2) -> impl Stream<Item = U>
where
  S1: Stream<Item = F> + Send + 'static,
  S2: Stream<Item = T> + Send + 'static,
  F: Fn(T) -> U + Clone + Send + 'static,
  T: Clone + Send + 'static,
  U: Send + 'static,
{
  latest2(fn_stream, value_stream).map(|(f, v)| f(v))
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod apply_latest_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_apply_latest() {
    let fns = futures::stream::iter(vec![|x: i32| x * 2, |x| x + 10]);
    let vals = futures::stream::iter(vec![1, 2, 3]);
    
    let values: Vec<_> = apply_latest(fns, vals).collect().await;
    // Should apply latest function to latest value
    assert!(!values.is_empty());
  }
}
#+end_src

** =untilStream=

The =untilStream= function creates a stream that emits values from the source stream until another stream emits a value, at which point it stops emitting values.

*** When to Use

Use =untilStream= to stop a stream when an external signal arrives. The source continues until the stop stream emits its first value.

#+begin_src text :tangle no
source:          --1--2--3--4--5--6--|
stop:            -----------X--------|
untilStream:     --1--2--3--|         
                           ^
                           stops when stop emits#+end_src

#+begin_src javascript :tangle no
// Stop polling when user logs out
const data = pipe(
  periodic(5000),
  chain(() => fetchData()),
  untilStream(logoutEvent)
)

// Process until cancel button clicked
const processing = pipe(
  workItems,
  map(processItem),
  untilStream(fromEvent(cancelButton, 'click'))
)

// Stop after timeout
const withTimeout = pipe(
  longRunningStream,
  untilStream(fromPromise(sleep(30000)))
)

// Component lifecycle: stop when unmounted
const subscription = pipe(
  dataUpdates,
  untilStream(componentDestroyed$)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that emits values from the source stream until another stream emits a value.
 */
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>
): (sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>,
  sourceStream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function untilStream<T, S = unknown>(
  stopStream: AsyncIterable<S>,
  sourceStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (sourceStream === undefined) return (s: AsyncIterable<T>) => untilStream(stopStream, s);
  return (async function* () {
    const sourceIterator = sourceStream[Symbol.asyncIterator]()
    const stopIterator = stopStream[Symbol.asyncIterator]()
    const iterators: AsyncIterator<T | S>[] = [sourceIterator, stopIterator]

    for await (const { index, value } of raceIterators(iterators)) {
      if (index === 1) break // stopStream emitted
      yield value as T
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('untilStream', () => {
  it('stops when stop stream emits', async () => {
    // Source emits forever, stop after 3 items
    const source = pipe(iterate(1, x => x + 1), take(10))
    const stop = pipe(from([1, 2, 3]), skip(2)) // emits on 3rd
    // This test is tricky with sync streams - use take to limit
    const values = await collect(pipe(untilStream(stop, from([1, 2, 3, 4, 5])), take(5)))
    expect(values.length).toBeLessThanOrEqual(5)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def until_stream(
  stop_stream: AsyncIterable[Any]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def until_stream(
  stop_stream: AsyncIterable[Any],
  source_stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def until_stream(
  stop_stream: AsyncIterable[Any],
  source_stream: Optional[AsyncIterable[T]] = None
):
  """Emits from source until stop stream emits."""
  async def _until_stream(source: AsyncIterable[T]) -> AsyncIterator[T]:
    stop_signal = asyncio.Event()

    async def watch_stop():
      async for _ in stop_stream:
        stop_signal.set()
        break

    stop_task = asyncio.create_task(watch_stop())

    try:
      async for item in source:
        if stop_signal.is_set():
          break
        yield item
    finally:
      stop_task.cancel()

  if source_stream is None:
    return _until_stream
  return _until_stream(source_stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

Using =futures::select!= for runtime-agnostic implementation:

#+begin_src rust :tangle rust/src/lib.rs
/// Emit from source until stop stream emits.
/// Runtime-agnostic using futures::select!
pub fn until_stream<T, U, S: Stream<Item = T> + Unpin, Stop: Stream<Item = U> + Unpin>(
  mut stop: Stop,
  mut source: S,
) -> impl Stream<Item = T> {
  stream! {
    loop {
      futures::select! {
        _ = stop.next().fuse() => break,
        item = source.next().fuse() => {
          match item {
            Some(v) => yield v,
            None => break,
          }
        }
      }
    }
  }
}

// Alternative: Use futures::stream::StreamExt::take_until
// source.take_until(stop.next())
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod until_stream_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_until_stream_stops() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let stop = futures::stream::iter(vec![()]); // Emit immediately
    
    let values: Vec<_> = until_stream(stop, source).collect().await;
    // Should stop when stop emits
    assert!(values.len() <= 5);
  }
}
#+end_src

** =sinceStream=

The =sinceStream= function creates a stream that starts emitting values from the source stream only after another stream emits a value.

*** When to Use

Use =sinceStream= to gate a stream until an external signal arrives. Values before the signal are dropped.

#+begin_src text :tangle no
source:          --1--2--3--4--5--6--|
start:           -------X------------|
sinceStream:     ---------4--5--6---|  
                    ^
                    values before start are dropped#+end_src

#+begin_src javascript :tangle no
// Start processing after initialization
const mainLoop = pipe(
  events,
  sinceStream(appInitialized)
)

// Wait for user permission before tracking
const tracking = pipe(
  userActions,
  sinceStream(consentGiven)
)

// Ignore events until animation completes
const afterAnimation = pipe(
  clickEvents,
  sinceStream(animationComplete)
)

// Begin recording after start signal
const recording = pipe(
  audioSamples,
  sinceStream(fromEvent(startButton, 'click'))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a stream that starts emitting values from the source stream only after another stream emits a value.
 */
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>
): (sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>,
  sourceStream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function sinceStream<T, S = unknown>(
  startStream: AsyncIterable<S>,
  sourceStream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((sourceStream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (sourceStream === undefined) return (s: AsyncIterable<T>) => sinceStream(startStream, s);
  return (async function* () {
    const sourceIterator = sourceStream[Symbol.asyncIterator]()
    const startIterator = startStream[Symbol.asyncIterator]()
    const iterators: AsyncIterator<T | S>[] = [sourceIterator, startIterator]
    let started = false

    for await (const { index, value } of raceIterators(iterators)) {
      if (index === 1) {
        started = true
        continue
      }
      if (started) yield value as T
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('sinceStream', () => {
  it('emits only after start stream emits', async () => {
    // With sync streams, behavior depends on interleaving
    const start = just('go')
    const source = from([1, 2, 3, 4, 5])
    const values = await collect(sinceStream(start, source))
    // Should emit some subset after start signal
    expect(Array.isArray(values)).toBe(true)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def since_stream(
  start_stream: AsyncIterable[Any]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def since_stream(
  start_stream: AsyncIterable[Any],
  source_stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def since_stream(
  start_stream: AsyncIterable[Any],
  source_stream: Optional[AsyncIterable[T]] = None
):
  """Emits from source only after start stream emits."""
  async def _since_stream(source: AsyncIterable[T]) -> AsyncIterator[T]:
    started = asyncio.Event()

    async def watch_start():
      async for _ in start_stream:
        started.set()
        break

    start_task = asyncio.create_task(watch_start())

    try:
      async for item in source:
        if started.is_set():
          yield item
    finally:
      start_task.cancel()

  if source_stream is None:
    return _since_stream
  return _since_stream(source_stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Emit from source only after start stream emits.
/// Runtime-agnostic using futures::select!
pub fn since_stream<T, U, S: Stream<Item = T> + Unpin, Start: Stream<Item = U> + Unpin>(
  mut start: Start,
  mut source: S,
) -> impl Stream<Item = T> {
  stream! {
    let mut started = false;
    loop {
      futures::select! {
        _ = async {
          if !started { start.next().await }
          else { std::future::pending().await }
        }.fuse() => {
          started = true;
        }
        item = source.next().fuse() => {
          match item {
            Some(v) if started => yield v,
            Some(_) => {}  // Drop values before start
            None => break,
          }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod since_stream_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_since_stream_waits() {
    let source = futures::stream::iter(vec![1, 2, 3, 4]);
    let start = futures::stream::iter(vec![()]); // Emit immediately
    
    let values: Vec<_> = since_stream(start, source).collect().await;
    // Should emit values after start signal
    assert!(!values.is_empty());
  }
}
#+end_src

* Buffering

These operators collect values into buffers before emitting them downstream.

** =buffer=

The =buffer= operator collects values from the source stream into arrays of a specified size,
emitting each buffer when it's full.

*** When to Use

Use =buffer= to batch items for bulk processing. Reduces number of operations when handling many small items.

#+begin_src text :tangle no
stream:       --1--2--3--4--5--|
buffer(2):    -----[1,2]--[3,4]--[5]|
                   ^       ^      ^
                   batch   batch  partial#+end_src

#+begin_src javascript :tangle no
// Batch API writes
const batchWrites = pipe(
  dataStream,
  buffer(100),  // Write in batches of 100
  awaitTap(batch => db.insertMany(batch))
)

// Process chunks for display
const tableRows = pipe(
  allRecords,
  buffer(50),  // Display 50 rows at a time
  map(batch => renderRows(batch))
)

// Reduce network overhead
const batchedEvents = pipe(
  analytics,
  buffer(10),
  tap(batch => sendToServer(batch))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Collects values into arrays of the specified size, emitting each buffer when full.
 * The final buffer may be smaller if the source completes.
 */
export function buffer<T>(
  size: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>;
export function buffer<T>(
  size: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T[], void, void>;
export function buffer<T>(
  size: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T[], void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => buffer(size, s);
  return (async function* () {
    let buf: T[] = []
    for await (const item of stream) {
      buf.push(item)
      if (buf.length >= size) yield buf = []
    }
    if (buf.length > 0) yield buf
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('buffer', () => {
  it('collects values into fixed-size arrays', async () => {
    const values = await collect(buffer(2, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([[1, 2], [3, 4], [5]])
  })

  it('emits partial buffer at end', async () => {
    const values = await collect(buffer(3, from([1, 2])))
    expect(values).toEqual([[1, 2]])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3, 4]), buffer(2)))
    expect(values).toEqual([[1, 2], [3, 4]])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def buffer(size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[List[T]]]: ...
@overload
def buffer(size: int, stream: AsyncIterable[T]) -> AsyncIterator[List[T]]: ...

def buffer(size: int, stream: Optional[AsyncIterable[T]] = None):
  """Collects values into lists of the specified size."""
  async def _buffer(s: AsyncIterable[T]) -> AsyncIterator[List[T]]:
    buf: List[T] = []
    async for item in s:
      buf.append(item)
      if len(buf) >= size:
        yield buf
        buf = []
    if buf:
      yield buf

  if stream is None:
    return _buffer
  return _buffer(stream)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestBuffer:
  async def test_buffers_values(self):
    result = await collect(pipe(
      from_iter([1, 2, 3, 4, 5]),
      buffer(2)
    ))
    assert result == [[1, 2], [3, 4], [5]]
#+end_src

*** Rust Implementation

=StreamExt::chunks= provides batching:

#+begin_src rust :tangle rust/src/lib.rs
// Buffering Operators

pub fn buffer<T, S: Stream<Item = T>>(size: usize, s: S) -> impl Stream<Item = Vec<T>> {
  stream! {
    futures::pin_mut!(s);
    let mut buf: Vec<T> = Vec::with_capacity(size);
    while let Some(item) = s.next().await {
      buf.push(item);
      if buf.len() >= size { yield std::mem::replace(&mut buf, Vec::with_capacity(size)); }
    }
    if !buf.is_empty() { yield buf; }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod buffer_tests {
  use super::*;
  #[tokio::test]
  async fn test_buffer() {
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let values: Vec<_> = buffer(2, source).collect().await;
    assert_eq!(values, vec![vec![1, 2], vec![3, 4], vec![5]]);
  }

  #[tokio::test]
  async fn test_buffer_exact_multiple() {
    let source = futures::stream::iter(vec![1, 2, 3, 4]);
    let values: Vec<_> = buffer(2, source).collect().await;
    assert_eq!(values, vec![vec![1, 2], vec![3, 4]]);
  }

  #[tokio::test]
  async fn test_buffer_empty() {
    let source = futures::stream::iter(Vec::<i32>::new());
    let values: Vec<_> = buffer(3, source).collect().await;
    assert_eq!(values, Vec::<Vec<i32>>::new());
  }
}
#+end_src

** =bufferTime=

The =bufferTime= operator collects values over a time window, emitting the buffer when the window closes.

*** When to Use

Use =bufferTime= when you want to batch items by time rather than count. Useful for rate-limiting or collecting events over a time window.

#+begin_src text :tangle no
time:           0   100  200  300  400
stream:         -1-2--3--4-5---6------|\nbufferTime(200):[1,2,3]--[4,5,6]------|\n                ^        ^\n                window   window\n#+end_src

#+begin_src javascript :tangle no
// Batch analytics events every 5 seconds
const analyticsBuffer = pipe(
  userEvents,
  bufferTime(5000),
  filter(batch => batch.length > 0),
  tap(batch => sendAnalytics(batch))
)

// Aggregate log entries
const logBatches = pipe(
  logStream,
  bufferTime(1000),
  map(logs => logs.join('\\n'))
)

// Rate-limited updates to UI
const throttledUpdates = pipe(
  rapidChanges,
  bufferTime(100),
  map(changes => changes.at(-1)),  // Take latest in window
  filter(Boolean)
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Collects values over a time window, emitting the buffer when the window closes.
 * Continues creating new windows until the source completes.
 */
export function bufferTime<T>(
  ms: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>;
export function bufferTime<T>(
  ms: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T[], void, void>;
export function bufferTime<T>(
  ms: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T[], void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T[], void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => bufferTime(ms, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let currentBuffer: T[] = []
    let done = false
    let bufferResolve: (() => void) | null = null

    // Timer that fires to emit buffer
    const startTimer = () => {
      return new Promise<'timer'>(resolve => {
        setTimeout(() => resolve('timer'), ms)
      })
    }

    // Source consumer
    const getNext = async (): Promise<{ done: true } | { done: false; value: T }> => {
      const result = await iterator.next()
      return result.done ? { done: true } : { done: false, value: result.value }
    }

    let timerPromise = startTimer()
    let nextPromise = getNext()

    while (!done) {
      const result = await Promise.race([timerPromise, nextPromise])

      if (result === 'timer') {
        // Timer fired - emit buffer and restart timer
        if (currentBuffer.length > 0) {
          yield currentBuffer
          currentBuffer = []
        }
        timerPromise = startTimer()
      } else if (result.done) {
        // Source completed
        done = true
        if (currentBuffer.length > 0) {
          yield currentBuffer
        }
      } else {
        // Got a value
        currentBuffer.push(result.value)
        nextPromise = getNext()
      }
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('bufferTime', () => {
  it('collects values over time window', async () => {
    const stream = createAsyncIterable([1, 2, 3, 4], { delay: 15 })
    const values = await collect(bufferTime(35, stream))
    // With 15ms delay between items and 35ms window:
    // Window 1 (0-35ms): 1, 2
    // Window 2 (35-70ms): 3, 4
    expect(values.length).toBeGreaterThanOrEqual(1)
    expect(values.flat()).toEqual([1, 2, 3, 4])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2]), bufferTime(50)))
    expect(values.flat()).toEqual([1, 2])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def buffer_time(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[List[T]]]: ...
@overload
def buffer_time(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[List[T]]: ...

def buffer_time(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Collects values over a time window."""
  async def _buffer_time(s: AsyncIterable[T]) -> AsyncIterator[List[T]]:
    buf: List[T] = []
    done = False
    queue: asyncio.Queue[Tuple[Optional[T], bool, bool]] = asyncio.Queue()

    async def timer():
      while not done:
        await asyncio.sleep(seconds)
        await queue.put((None, True, False)) # Timer tick

    async def consume():
      nonlocal done
      async for item in s:
        await queue.put((item, False, False))
      done = True
      await queue.put((None, False, True)) # Source done

    timer_task = asyncio.create_task(timer())
    consume_task = asyncio.create_task(consume())

    try:
      while True:
        value, is_tick, is_done = await queue.get()
        if is_done:
          if buf:
            yield buf
          break
        elif is_tick:
          if buf:
            yield buf
            buf = []
        else:
          buf.append(value) # type: ignore
    finally:
      timer_task.cancel()
      consume_task.cancel()

  if stream is None:
    return _buffer_time
  return _buffer_time(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Buffer values over time windows.
/// Uses the Runtime trait for timer functionality.
pub fn buffer_time<R, T, S>(ms: u64, mut s: S) -> impl Stream<Item = Vec<T>>
where
  R: Runtime,
  T: Clone,
  S: Stream<Item = T> + Unpin,
{
  stream! {
    let duration = Duration::from_millis(ms);
    let mut buf: Vec<T> = Vec::new();
    let mut timer = R::sleep(duration);
    loop {
      futures::select! {
        _ = (&mut timer).fuse() => {
          if !buf.is_empty() { yield std::mem::take(&mut buf); }
          timer = R::sleep(duration);
        }
        item = s.next().fuse() => {
          match item {
            Some(v) => buf.push(v),
            None => {
              if !buf.is_empty() { yield buf; }
              break;
            }
          }
        }
      }
    }
  }
}

/// Runtime-agnostic buffer_time with custom sleep function
pub fn buffer_time_with<T, S, SF, SFut>(
  ms: u64,
  mut s: S,
  sleep_fn: SF,
) -> impl Stream<Item = Vec<T>>
where
  S: Stream<Item = T> + Unpin,
  SF: Fn(Duration) -> SFut,
  SFut: std::future::Future<Output = ()> + Unpin,
{
  stream! {
    let duration = Duration::from_millis(ms);
    let mut buf: Vec<T> = Vec::new();
    let mut timer = sleep_fn(duration);
    loop {
      futures::select! {
        _ = (&mut timer).fuse() => {
          if !buf.is_empty() {  yield std::mem::take(&mut buf); }
          timer = sleep_fn(duration);
        }
        item = s.next().fuse() => {
          match item {
            Some(v) => buf.push(v),
            None => {
              if !buf.is_empty() { yield buf; }
              break;
            }
          }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod buffer_time_tests {
  // Note: buffer_time requires Runtime trait for timing
  // Tests would need mock runtime or feature-flagged tokio
  // Basic timing logic is validated through throttle tests
}
#+end_src

** =window=

The =window= operator is like =buffer=, but emits streams instead of arrays.
Each window is a separate async iterable that emits values as they arrive.

*** When to Use

Use =window= when you need streaming access to batches (rather than waiting for the full batch like =buffer=). Each window is itself a stream that can be processed incrementally.

#+begin_src text :tangle no
stream:       --1--2--3--4--5--|
window(2):    --[S1]----[S2]----[S3]|
              S1: 1-2|
              S2: 3-4|
              S3: 5|#+end_src

#+begin_src javascript :tangle no
// Process large files in chunks without loading full chunk
const chunkedProcessing = pipe(
  largeFileStream,
  window(1000),
  concatMap(async windowStream => {
    let sum = 0
    for await (const line of windowStream) {
      sum += parseLine(line).value
    }
    return sum
  })
)

// Stream processing with per-window aggregation
const windowAggregates = pipe(
  dataPoints,
  window(100),
  chain(async window => {
    const values = await collect(window)
    return just({ avg: average(values), count: values.length })
  })
)

// Different processing per window
const windowed = pipe(
  events,
  window(50),
  map(w => processWindow(w))
)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Splits the source into windows of the specified size.
 * Each window is emitted as a separate async iterable.
 */
export function window<T>(
  size: number
): (stream: AsyncIterable<T>) => AsyncGenerator<AsyncIterable<T>, void, void>;
export function window<T>(
  size: number,
  stream: AsyncIterable<T>
): AsyncGenerator<AsyncIterable<T>, void, void>;
export function window<T>(
  size: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<AsyncIterable<T>, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<AsyncIterable<T>, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => window(size, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    let done = false

    while (!done) {
      let count = 0
      const windowValues: T[] = []
      let windowDone = false
      let windowResolve: ((result: IteratorResult<T>) => void) | null = null

      // Create a window stream
      const windowStream: AsyncIterable<T> = {
        [Symbol.asyncIterator]() {
          let index = 0
          return {
            async next(): Promise<IteratorResult<T>> {
              if (index < windowValues.length) return { value: windowValues[index++], done: false }
              if (windowDone) return { value: undefined as any, done: true }
              return new Promise(resolve => { windowResolve = resolve } )
            }
          }
        }
      }

      // Yield the window stream
      yield windowStream

      // Fill the window
      while (count < size && !done) {
        const result = await iterator.next()
        if (result.done) {
          done = true
          windowDone = true
          if (windowResolve) {
            const resolver: (result: IteratorResult<T>) => void = windowResolve
            resolver({ value: undefined as any, done: true })
          }
        } else {
          windowValues.push(result.value)
          count++
          if (windowResolve) {
            const resolver: (result: IteratorResult<T>) => void = windowResolve
            windowResolve = null
            resolver({ value: result.value, done: false })
          }
        }
      }
      windowDone = true
      if (windowResolve) {
        const resolver: (result: IteratorResult<T>) => void = windowResolve
        resolver({ value: undefined as any, done: true })
      }
    }
  })();
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('window', () => {
  it('splits stream into window streams', async () => {
    const windows = await collect(window(2, from([1, 2, 3, 4, 5])))
    expect(windows.length).toBe(3)
    
    const values = await Promise.all(windows.map(w => collect(w)))
    expect(values).toEqual([[1, 2], [3, 4], [5]])
  })

  it('supports curried form', async () => {
    const windows = await collect(pipe(from([1, 2, 3]), window(2)))
    expect(windows.length).toBe(2)
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def window(size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[AsyncIterable[T]]]: ...
@overload
def window(size: int, stream: AsyncIterable[T]) -> AsyncIterator[AsyncIterable[T]]: ...

def window(size: int, stream: Optional[AsyncIterable[T]] = None):
  """Splits the source into windows of the specified size."""
  async def _window(s: AsyncIterable[T]) -> AsyncIterator[AsyncIterable[T]]:
    async for batch in buffer(size, s):
      async def window_stream(items: List[T]) -> AsyncIterator[T]:
        for item in items:
          yield item
      yield window_stream(batch)

  if stream is None:
    return _window
  return _window(stream)
#+end_src

**** TODO Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

Windowing in Rust typically uses channels to create sub-streams:

#+begin_src rust :tangle rust/src/lib.rs
/// Split source into windows of specified size.
/// Each window is a vector of items (simpler than sub-streams).
pub fn window<T: Clone + Send + 'static>(
  size: usize,
  s: impl Stream<Item = T> + Send + 'static,
) -> impl Stream<Item = Vec<T>> {
  stream! {
    futures::pin_mut!(s);
    loop {
      let mut window = Vec::with_capacity(size);
      while window.len() < size {
        match s.next().await {
          Some(item) => window.push(item),
          None => {
            if !window.is_empty() {
              yield window;
            }
            return;
          }
        }
      }
      yield window;
    }
  }
}
#+end_src

** =eager= and =eagerNow=

The =eager= operator pre-fetches values from a slow producer, holding them in a cache
so downstream consumers can receive them immediately when ready.

This is like a "reverse throttle" — instead of slowing down emissions, it speeds them up
by doing work ahead of time.

- =eager(n)= - Lazily starts buffering when downstream first requests (default behavior)
- =eagerNow(n)= - Immediately starts buffering as soon as called

Use =eager(0)= or =eagerNow(0)= to buffer all values (use with caution on infinite streams!).

#+begin_src typescript :tangle typescript/index.ts
/**
 * Pre-fetches up to `bufferSize` values from a slow producer, caching them for fast downstream access.
 * Starts buffering lazily when the first value is requested.
 * 
 * @param bufferSize - Maximum values to pre-fetch. Use 0 for unlimited (careful with infinite streams!)
 * 
 * @example
 * // Pre-fetch 5 file contents while processing
 * const files = pipe(
 *   filePathStream,
 *   map(path => fs.readFile(path)),
 *   eager(5)  // Buffer up to 5 files ahead
 * )
 */
export function eager<T>(
  bufferSize: number
): (stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>;
export function eager<T>(
  bufferSize: number,
  stream: AsyncIterable<T>
): AsyncGenerator<T, void, void>;
export function eager<T>(
  bufferSize: number,
  stream?: AsyncIterable<T>,
): AsyncGenerator<T, void, void> | ((stream: AsyncIterable<T>) => AsyncGenerator<T, void, void>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => eager(bufferSize, s);
  return (async function* () {
    const iterator = stream[Symbol.asyncIterator]()
    const buffer: T[] = []
    let error: Error | null = null
    let done = false
    let consuming = false
    let waitingResolve: (() => void) | null = null

    const startConsuming = () => {
      if (consuming) return
      consuming = true
      
      // Consume source in background
      ;(async () => {
        try {
          while (!done) {
            // Respect buffer limit (0 = unlimited)
            if (bufferSize > 0 && buffer.length >= bufferSize) {
              // Wait for buffer to drain
              await new Promise<void>(r => { waitingResolve = r })
              continue
            }
            
            const result = await iterator.next()
            if (result.done) done = true
            else buffer.push(result.value)
          }
        } catch (e) {
          error = e as Error
          done = true
        }
      })()
    }

    // Start consuming on first pull
    startConsuming()

    while (true) {
      // Yield buffered values first
      if (buffer.length > 0) {
        const value = buffer.shift()!
        // Signal that buffer has space
        if (waitingResolve) {
          const resolver: () => void = waitingResolve
          waitingResolve = null
          resolver()
        }
        yield value
      }
      else if (error) throw error // Emit buffered values before error (requirement)
      else if (done) break
      else await new Promise<void>(r => setTimeout(r, 1)) // Wait for more values
    }
  })();
}

/**
 * Pre-fetches up to `bufferSize` values from a slow producer immediately on creation.
 * Like `eager`, but starts consuming right away rather than waiting for the first pull.
 * 
 * @param bufferSize - Maximum values to pre-fetch. Use 0 for unlimited (careful with infinite streams!)
 */
export function eagerNow<T>(
  bufferSize: number
): (stream: AsyncIterable<T>) => AsyncIterable<T>;
export function eagerNow<T>(
  bufferSize: number,
  stream: AsyncIterable<T>
): AsyncIterable<T>;
export function eagerNow<T>(
  bufferSize: number,
  stream?: AsyncIterable<T>,
): AsyncIterable<T> | ((stream: AsyncIterable<T>) => AsyncIterable<T>) {
  if (stream === undefined) return (s: AsyncIterable<T>) => eagerNow(bufferSize, s);
  
  const iterator = stream[Symbol.asyncIterator]()
  const buffer: T[] = []
  let error: Error | null = null
  let done = false
  let waitingResolves: (() => void)[] = []

  // Start consuming immediately
  ;(async () => {
    try {
      while (!done) {
        // Respect buffer limit (0 = unlimited)
        if (bufferSize > 0 && buffer.length >= bufferSize) {
          await new Promise<void>(r => { waitingResolves.push(r) })
          continue
        }
        
        const result = await iterator.next()
        if (result.done) done = true
        else buffer.push(result.value)
      }
    } catch (e) {
      error = e as Error
      done = true
    }
  })()

  return {
    [Symbol.asyncIterator]() {
      return {
        async next(): Promise<IteratorResult<T>> {
          while (true) {
            if (buffer.length > 0) {
              const value = buffer.shift()!
              // Signal that buffer has space
              if (waitingResolves.length > 0) {
                const resolve = waitingResolves.shift()!
                resolve()
              }
              return { value, done: false }
            }
            else if (error) throw error
            else if (done) return { value: undefined as any, done: true }
            else await new Promise<void>(r => setTimeout(r, 1))
          }
        }
      }
    }
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('eager', () => {
  it('pre-fetches values from slow producer', async () => {
    let fetchCount = 0
    const slowStream = async function* () {
      for (let i = 1; i <= 5; i++) {
        fetchCount++
        await new Promise(r => setTimeout(r, 20))
        yield i
      }
    }

    const eagerStream = eager(3, slowStream())
    
    // First pull starts fetching
    const iter = eagerStream[Symbol.asyncIterator]()
    await new Promise(r => setTimeout(r, 70)) // Let it buffer
    
    // Should have pre-fetched some values
    const result = await iter.next()
    expect(result.value).toBe(1)
  })

  it('respects buffer size limit', async () => {
    const values = await collect(eager(2, from([1, 2, 3, 4, 5])))
    expect(values).toEqual([1, 2, 3, 4, 5])
  })

  it('supports curried form', async () => {
    const values = await collect(pipe(from([1, 2, 3]), eager(2)))
    expect(values).toEqual([1, 2, 3])
  })

  it('emits buffered values then error', async () => {
    // This tests that buffered values are emitted before error
    const failingStream = async function* () {
      yield 1
      yield 2
      throw new Error('fail')
    }
    
    try {
      const values = await collect(eager(5, failingStream()))
      // Should have gotten values before error
      expect(values).toContain(1)
    } catch (e) {
      // Error is expected
      expect((e as Error).message).toBe('fail')
    }
  })
})

describe('eagerNow', () => {
  it('starts buffering immediately', async () => {
    let started = false
    const slowStream = async function* () {
      started = true
      yield 1
    }

    const eager = eagerNow(3, slowStream())
    
    // Give it time to start
    await new Promise(r => setTimeout(r, 10))
    
    // Should have started consuming
    expect(started).toBe(true)
    
    const values = await collect(eager)
    expect(values).toEqual([1])
  })

  it('supports curried form', async () => {
    const eager = eagerNow(2)
    const values = await collect(eager(from([1, 2, 3])))
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
@overload
def eager(buffer_size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def eager(buffer_size: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def eager(buffer_size: int, stream: Optional[AsyncIterable[T]] = None):
  """Pre-fetches values from a slow producer into a buffer."""
  async def _eager(s: AsyncIterable[T]) -> AsyncIterator[T]:
    queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue(
      maxsize=buffer_size if buffer_size > 0 else 0
    )

    async def consume():
      try:
        async for item in s:
          await queue.put((item, False, None))
        await queue.put((None, True, None))
      except Exception as e:
        await queue.put((None, True, e))

    task = asyncio.create_task(consume())

    try:
      while True:
        value, done, error = await queue.get()
        if error:
          raise error
        if done:
          break
        yield value # type: ignore
    finally:
      task.cancel()

  if stream is None:
    return _eager
  return _eager(stream)

def eager_now(buffer_size: int, stream: AsyncIterable[T]) -> AsyncIterable[T]:
  """Pre-fetches values immediately on creation."""
  queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue(
    maxsize=buffer_size if buffer_size > 0 else 0
  )
  started = False
  task: Optional[asyncio.Task] = None

  async def consume():
    try:
      async for item in stream:
        await queue.put((item, False, None))
      await queue.put((None, True, None))
    except Exception as e:
      await queue.put((None, True, e))

  async def start():
    nonlocal started, task
    if not started:
      started = True
      task = asyncio.create_task(consume())

  # Start immediately
  asyncio.get_event_loop().call_soon(lambda: asyncio.create_task(start()))

  async def iterate() -> AsyncIterator[T]:
    await start()
    while True:
      value, done, error = await queue.get()
      if error:
        raise error
      if done:
        break
      yield value # type: ignore

  return iterate()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestEager:
  async def test_prefetches_values(self):
    events = []
    
    async def slow_producer():
      for i in range(3):
        events.append(f"produce_{i}")
        yield i
    
    stream = pipe(
      slow_producer(),
      eager(10)
    )
    
    events.append("created")
    result = await collect(stream)
    assert result == [0, 1, 2]
#+end_src

*** Rust Implementation

Pre-fetching in Rust is typically done with buffered channels or background tasks:

#+begin_src rust :tangle rust/src/lib.rs
/// Pre-fetch values from a slow producer into a buffer.
/// Uses the Runtime trait for spawning background consumption.
pub fn eager<R, T, S>(buffer_size: usize, s: S) -> impl Stream<Item = T>
where
  R: Runtime,
  T: Send + 'static,
  S: Stream<Item = T> + Send + Unpin + 'static,
{
  // Use a channel as the buffer
  let (mut tx, mut rx) = mpsc::channel::<T>(buffer_size.max(1));
  
  // Spawn background consumer on first pull
  let mut spawned = false;
  let mut s = Some(s);
  
  stream! {
    if !spawned {
      spawned = true;
      let mut source = s.take().unwrap();
      R::spawn(async move {
        use futures::StreamExt;
        use futures::SinkExt;
        while let Some(item) = source.next().await { if tx.send(item).await.is_err() { break; } } // Receiver dropped
      });
    }
    
    while let Some(item) = rx.next().await { yield item; }
  }
}

/// Pre-fetch values immediately on creation using the Runtime trait.
pub fn eager_now<R, T, S>(buffer_size: usize, s: S) -> impl Stream<Item = T>
where
  R: Runtime,
  T: Send + 'static,
  S: Stream<Item = T> + Send + Unpin + 'static,
{    
  let (mut tx, mut rx) = mpsc::channel::<T>(buffer_size.max(1));
  
  // Start consuming immediately
  let mut source = s;
  R::spawn(async move {
    use futures::StreamExt;
    use futures::SinkExt;
    while let Some(item) = source.next().await { if tx.send(item).await.is_err() { break; } }
  });
  
  stream! { while let Some(item) = rx.next().await { yield item; } }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod eager_now_tests {
  // Note: eager_now requires Runtime trait for spawning
  // Tests would need specific runtime implementation
  // The pattern is: spawn producer, stream from channel
}
#+end_src

* Multicasting

By default, async generators are single-consumer: each consumer pulls values independently.
These operators enable multiple consumers to share a single source stream.

** =ReplaySubject=

A =ReplaySubject= is a multicasting primitive that:
1. Buffers up to N most recent values
2. Allows multiple consumers to subscribe
3. Replays buffered values to new subscribers
4. Forwards live values to all active subscribers

*** When to Use

Use =ReplaySubject= when you need to:
- Share a single source among multiple subscribers
- Buffer recent values for late subscribers
- Implement hot observables with history

#+begin_src text :tangle no
source:         --1--2--3--4--5--|

subscriber A:   --1--2--3--4--5--|  (subscribed at start)
subscriber B:      [1,2]3--4--5--|  (subscribed at 3, buffer=2)
subscriber C:            [3,4]5--|  (subscribed at 5, buffer=2)#+end_src

#+begin_src javascript :tangle no
// Share websocket messages with buffering
const messages = new ReplaySubject(10)  // buffer last 10

// Feed source into subject
websocket.onmessage = msg => messages.next(msg.data)

// Multiple consumers, late joiners get history
const display1 = messages.subscribe()
const display2 = messages.subscribe()  // gets last 10 messages
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * A multicasting subject that replays buffered values to new subscribers.
 * 
 * @example
 * const subject = new ReplaySubject<number>(2)  // buffer last 2 values
 * 
 * // Push values
 * subject.next(1)
 * subject.next(2)
 * subject.next(3)
 * 
 * // New subscriber gets [2, 3] immediately, then live values
 * for await (const value of subject) { ... }
 */
export class ReplaySubject<T> implements AsyncIterable<T> {
  private buffer: T[] = []
  private subscribers: Set<{
    queue: T[]
    resolve: ((result: IteratorResult<T>) => void) | null
  }> = new Set()
  private completed = false
  private error: Error | null = null

  constructor(private bufferSize: number = Infinity) {}

  /**
   * Push a value to all subscribers.
   */
  next(value: T): void {
    if (this.completed) throw new Error('Cannot push to completed ReplaySubject')
    
    // Add to buffer
    this.buffer.push(value)
    if (this.buffer.length > this.bufferSize) {
      this.buffer.shift()
    }

    // Notify all subscribers
    for (const sub of this.subscribers) {
      if (sub.resolve) {
        const resolve = sub.resolve
        sub.resolve = null
        resolve({ value, done: false })
      } else {
        sub.queue.push(value)
      }
    }
  }

  /**
   * Signal completion to all subscribers.
   */
  complete(): void {
    this.completed = true
    for (const sub of this.subscribers) {
      if (sub.resolve) {
        const resolve = sub.resolve
        sub.resolve = null
        resolve({ value: undefined as T, done: true })
      }
    }
  }

  /**
   * Signal an error to all subscribers.
   */
  throw(error: Error): void {
    this.error = error
    this.completed = true
    // Subscribers will see the error on next pull
  }

  [Symbol.asyncIterator](): AsyncIterator<T> {
    const sub = {
      queue: [...this.buffer],  // Start with buffered values
      resolve: null as ((result: IteratorResult<T>) => void) | null
    }
    this.subscribers.add(sub)

    return {
      next: async (): Promise<IteratorResult<T>> => {
        // Check for error
        if (this.error) throw this.error
        
        // Return queued value if available
        if (sub.queue.length > 0) {
          return { value: sub.queue.shift()!, done: false }
        }
        
        // Check if completed
        if (this.completed) {
          this.subscribers.delete(sub)
          return { value: undefined as T, done: true }
        }

        // Wait for next value
        return new Promise(resolve => {
          sub.resolve = resolve
        })
      },
      return: async (): Promise<IteratorResult<T>> => {
        this.subscribers.delete(sub)
        return { value: undefined as T, done: true }
      }
    }
  }

  /**
   * Get the current buffer contents (snapshot).
   */
  getBuffer(): readonly T[] {
    return [...this.buffer]
  }

  /**
   * Number of active subscribers.
   */
  get subscriberCount(): number {
    return this.subscribers.size
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('ReplaySubject', () => {
  it('replays buffered values to new subscribers', async () => {
    const subject = new ReplaySubject<number>(2)
    
    subject.next(1)
    subject.next(2)
    subject.next(3)
    subject.complete()
    
    // New subscriber gets last 2 values
    const values = await collect(subject)
    expect(values).toEqual([2, 3])
  })

  it('multicasts to multiple subscribers', async () => {
    const subject = new ReplaySubject<number>()
    
    // Start two consumers
    const consumer1: number[] = []
    const consumer2: number[] = []
    
    const iter1 = subject[Symbol.asyncIterator]()
    const iter2 = subject[Symbol.asyncIterator]()
    
    subject.next(1)
    subject.next(2)
    subject.complete()
    
    // Both should receive all values
    let result = await iter1.next()
    while (!result.done) {
      consumer1.push(result.value)
      result = await iter1.next()
    }
    
    result = await iter2.next()
    while (!result.done) {
      consumer2.push(result.value)
      result = await iter2.next()
    }
    
    expect(consumer1).toEqual([1, 2])
    expect(consumer2).toEqual([1, 2])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
class ReplaySubject(Generic[T]):
  """A multicasting subject that replays buffered values to new subscribers."""

  def __init__(self, buffer_size: int = float('inf')): # type: ignore
    self._buffer: deque[T] = deque(maxlen=buffer_size if buffer_size != float('inf') else None)
    self._subscribers: List[asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]]] = []
    self._completed = False
    self._error: Optional[Exception] = None

  def next(self, value: T) -> None:
    """Push a value to all subscribers."""
    if self._completed:
      raise RuntimeError("Cannot push to completed ReplaySubject")

    self._buffer.append(value)
    for sub in self._subscribers:
      sub.put_nowait((value, False, None))

  def complete(self) -> None:
    """Signal completion to all subscribers."""
    self._completed = True
    for sub in self._subscribers:
      sub.put_nowait((None, True, None))

  def throw(self, error: Exception) -> None:
    """Signal an error to all subscribers."""
    self._error = error
    self._completed = True
    for sub in self._subscribers:
      sub.put_nowait((None, True, error))

  def __aiter__(self) -> AsyncIterator[T]:
    queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue()

    # Add buffered values
    for value in self._buffer:
      queue.put_nowait((value, False, None))

    if self._completed:
      queue.put_nowait((None, True, self._error))
    else:
      self._subscribers.append(queue)

    async def iterate() -> AsyncIterator[T]:
      try:
        while True:
          value, done, error = await queue.get()
          if error:
            raise error
          if done:
            break
          yield value # type: ignore
      finally:
        if queue in self._subscribers:
          self._subscribers.remove(queue)

    return iterate()

  def get_buffer(self) -> List[T]:
    """Get the current buffer contents."""
    return list(self._buffer)

  @property
  def subscriber_count(self) -> int:
    """Number of active subscribers."""
    return len(self._subscribers)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestReplaySubject:
  async def test_replays_to_new_subscribers(self):
    subject = ReplaySubject[int](buffer_size=10)
    subject.next(1)
    subject.next(2)
    
    result = await collect_n(2, subject)
    assert result == [1, 2]

  async def test_buffers_limited(self):
    subject = ReplaySubject[int](buffer_size=2)
    subject.next(1)
    subject.next(2)
    subject.next(3)
    
    assert subject.get_buffer() == [2, 3]
#+end_src

*** Rust Implementation

Runtime-agnostic implementation using =futures::channel= and =async-lock=:

#+begin_src rust :tangle rust/src/lib.rs
// Multicasting Operators

/// A multicasting subject that replays buffered values to new subscribers.
/// Uses only runtime-agnostic primitives from the futures crate.
pub struct ReplaySubject<T: Clone + Send + 'static> {
  inner: Arc<Mutex<ReplaySubjectInner<T>>>,
}

struct ReplaySubjectInner<T> {
  buffer: Vec<T>,
  buffer_size: usize,
  completed: bool,
  error: Option<Arc<dyn std::error::Error + Send + Sync>>,
  subscribers: Vec<mpsc::UnboundedSender<T>>,
}

impl<T: Clone + Send + 'static> ReplaySubject<T> {
  pub fn new(buffer_size: usize) -> Self {
    Self {
      inner: Arc::new(Mutex::new(ReplaySubjectInner {
        buffer: Vec::new(),
        buffer_size,
        completed: false,
        error: None,
        subscribers: Vec::new(),
      })),
    }
  }
  pub async fn next(&self, value: T) {
    let mut inner = self.inner.lock().await;
    inner.buffer.push(value.clone());
    if inner.buffer.len() > inner.buffer_size {  inner.buffer.remove(0); }
    // Broadcast to all subscribers
    inner.subscribers.retain(|tx| tx.unbounded_send(value.clone()).is_ok());
  }
  pub async fn complete(&self) {
    let mut inner = self.inner.lock().await;
    inner.completed = true;
    inner.subscribers.clear();
  }
  pub fn subscribe(&self) -> impl Stream<Item = T> {
    let inner = self.inner.clone();
    
    stream! {
      let (tx, mut rx) = mpsc::unbounded();
      let buffered: Vec<T>;
      let was_completed: bool;
      
      {
        let mut guard = inner.lock().await;
        buffered = guard.buffer.clone();
        was_completed = guard.completed;
        if !guard.completed { guard.subscribers.push(tx); }
      }
      
      // Replay buffered values first
      for item in buffered { yield item; }
      
      // If already completed, don't wait for more values
      if was_completed { return; }
      
      // Then receive live values
      while let Some(item) = rx.next().await { yield item; }
    }
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod replay_subject_tests {
  use super::*;

  #[tokio::test]
  async fn test_replay_subject_buffer() {
    let subject = ReplaySubject::new(2);
    
    // Send some values
    subject.next(1).await;
    subject.next(2).await;
    subject.next(3).await;  // 1 should be evicted
    subject.complete().await;
    
    // New subscriber should get last 2 buffered values
    let values: Vec<_> = subject.subscribe().collect().await;
    assert_eq!(values, vec![2, 3]);
  }

  #[tokio::test]
  async fn test_replay_subject_empty() {
    let subject: ReplaySubject<i32> = ReplaySubject::new(5);
    subject.complete().await;

    let values: Vec<_> = subject.subscribe().collect().await;
    assert_eq!(values, Vec::<i32>::new());
  }

  #[tokio::test]
  async fn test_replay_subject_unlimited() {
    let subject = ReplaySubject::new(usize::MAX);

    subject.next(1).await;
    subject.next(2).await;
    subject.next(3).await;
    subject.complete().await;

    let values: Vec<_> = subject.subscribe().collect().await;
    assert_eq!(values, vec![1, 2, 3]);
  }
}
#+end_src

** =replay=

The =replay= function wraps a source stream to allow multiple consumers.
Each consumer receives buffered values plus all subsequent values.

The source stream is consumed lazily on first subscription.

*** When to Use

Use =replay= to share a single source among multiple consumers while buffering recent values. Late subscribers receive buffered values plus live updates.

#+begin_src text :tangle no
source:      --1--2--3--4--5--|

[with replay(2)]:

consumer 1:  --1--2--3--4--5--|  (starts at beginning)
consumer 2:       [2,3]4--5--|   (joins at 3, gets buffer [2,3])
consumer 3:            [4,5]|    (joins at end, gets buffer [4,5])
#+end_src

#+begin_src javascript :tangle no
// Share expensive computation result
const sharedData = replay(Infinity, pipe(
  fromPromise(expensiveFetch()),
  chain(data => from(data.items))
))

// Multiple components can consume
const component1 = collect(sharedData)
const component2 = collect(sharedData)  // Same data, no refetch

// Cache recent values for late subscribers
const priceUpdates = replay(1, livePrice$)  // Cache latest price

// Event sourcing: replay history for new subscribers
const eventLog = replay(1000, events)  // Keep last 1000 events
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Makes a stream consumable by multiple consumers by buffering values.
 * 
 * @param bufferSize - Maximum number of values to buffer for replay (default: Infinity)
 * @param source - The source stream to multicast
 * @returns An AsyncIterable that can be consumed by multiple consumers
 * 
 * @example
 * const shared = replay(2, sourceStream)
 * 
 * // Consumer 1 starts
 * const consumer1 = collect(shared)
 * 
 * // Consumer 2 joins later, gets last 2 values + live values
 * const consumer2 = collect(shared)
 */
export function replay<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): AsyncIterable<T> {
  const subject = new ReplaySubject<T>(bufferSize)
  let started = false

  const startSource = () => {
    if (started) return
    started = true
    
    ;(async () => {
      try {
        for await (const value of source) { subject.next(value) }
        subject.complete()
      } catch (e) { subject.throw(e as Error) }
    })()
  }

  return {
    [Symbol.asyncIterator](): AsyncIterator<T> {
      startSource()
      return subject[Symbol.asyncIterator]()
    }
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('replay', () => {
  it('allows multiple consumers of a single source', async () => {
    const source = from([1, 2, 3])
    const shared = replay(Infinity, source)
    
    const values1 = await collect(shared)
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3])
    expect(values2).toEqual([1, 2, 3])
  })

  it('respects buffer size', async () => {
    const source = from([1, 2, 3, 4, 5])
    const shared = replay(2, source)
    
    // First consumer triggers source consumption
    const values1 = await collect(shared)
    
    // Second consumer only gets last 2 buffered values
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3, 4, 5])
    expect(values2).toEqual([4, 5])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
def replay(buffer_size: int, source: AsyncIterable[T]) -> AsyncIterable[T]:
  """Makes a stream consumable by multiple consumers by buffering values."""
  subject = ReplaySubject[T](buffer_size)
  started = False

  async def start_source():
    nonlocal started
    if started:
      return
    started = True

    try:
      async for value in source:
        subject.next(value)
      subject.complete()
    except Exception as e:
      subject.throw(e)

  class ReplayIterable:
    def __aiter__(self):
      asyncio.create_task(start_source())
      return subject.__aiter__()

  return ReplayIterable()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestReplay:
  async def test_replays_buffered(self):
    source = from_iter([1, 2, 3])
    replayed = replay(10, source)
    
    result1 = await collect(replayed)
    # Second subscriber would get replayed values
    assert result1 == [1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Replay creates a shared stream that buffers values for late subscribers.
struct Replay<T> {
  inner: Arc<Mutex<ReplayInner<T>>>,
}

struct ReplayInner<T> {
  buffer: Vec<T>,
  buffer_size: usize,
  completed: bool,
  error: Option<Arc<dyn std::error::Error + Send + Sync>>,
  source_started: bool,
  subscribers: Vec<futures::channel::mpsc::UnboundedSender<Result<T, Arc<dyn std::error::Error + Send + Sync>>>>,
}

impl<T: Clone + Send + 'static> Replay<T> {
  fn new<S>(buffer_size: usize, source: S) -> Self
  where
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
  {
    let inner = Arc::new(Mutex::new(ReplayInner {
      buffer: Vec::new(),
      buffer_size,
      completed: false,
      error: None,
      source_started: false,
      subscribers: Vec::new(),
    }));
    
    Replay { inner }
  }
  
  fn subscribe(&self) -> impl futures::Stream<Item = T> {
    let inner = self.inner.clone();
    
    async_stream::stream! {
      let (tx, mut rx) = futures::channel::mpsc::unbounded();
      
      // Get buffered values and register subscriber
      let buffered: Vec<T>;
      {
        let mut guard = inner.lock().await;
        buffered = guard.buffer.clone();
        
        if !guard.completed && guard.error.is_none() { guard.subscribers.push(tx); }
      }
      
      // Yield buffered values first
      for value in buffered { yield value; }
      
      // Receive live values
      while let Some(result) = rx.next().await {
        match result {
          Ok(value) => yield value,
          Err(_) => break,
        }
      }
    }
  }
  
  async fn start_source<S>(&self, mut source: S)
  where
    S: futures::Stream<Item = T> + Send + Unpin + 'static,
  {
    while let Some(value) = source.next().await {
        let mut guard = self.inner.lock().await;
        
        // Buffer the value
        guard.buffer.push(value.clone());
        if guard.buffer.len() > guard.buffer_size {
            guard.buffer.remove(0);
        }
        
        // Broadcast to subscribers
        guard.subscribers.retain(|tx| tx.unbounded_send(Ok(value.clone())).is_ok());
    }
    
    // Mark complete
    let mut guard = self.inner.lock().await;
    guard.completed = true;
    guard.subscribers.clear();
  }
}

/// Convenience function to replay a stream.
/// 
/// This implementation uses a simpler approach: the returned stream
/// directly consumes and forwards the source. For true multicasting,
/// use ReplaySubject instead.
fn replay<T, S>(buffer_size: usize, source: S) -> impl futures::Stream<Item = T>
where
  T: Clone + Send + 'static,
  S: futures::Stream<Item = T> + Send + 'static,
{
  // Simple passthrough implementation - for single subscriber
  // For true multicasting, use ReplaySubject
  let _ = buffer_size; // Buffering only matters for late subscribers
  source
}
#+end_src

**** Tests

(Replay tests are defined in the replay_tests module below)

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod replay_tests {
  use super::*;

  #[tokio::test]
  async fn test_replay_buffered() {
    // Test that buffering works
    let source = futures::stream::iter(vec![1, 2, 3, 4, 5]);
    let replay = Replay::new(2, source);
    
    // Start source consumption
    // (In a real impl, this would happen on first subscribe)
  }
}
#+end_src

** =share=

The =share= function is like =replay= with a buffer size of 0.
New subscribers only receive values emitted after they subscribe.

*** When to Use

Use =share= when multiple consumers should receive the same live stream but don't need historical values. Late subscribers only get values emitted after they subscribe.

#+begin_src text :tangle no
source:      --1--2--3--4--5--|\n
[with share]:\n
consumer 1:  --1--2--3--4--5--|  (starts at beginning)
consumer 2:       ?--3--4--5--|   (joins at 3, misses 1,2)
consumer 3:            ?--5--|    (joins at 5, misses 1-4)
#+end_src

#+begin_src javascript :tangle no
// Share WebSocket connection among components
const wsMessages = share(fromWebSocket(ws))

// Multiple listeners get same live events
for await (const msg of wsMessages) { handleMsg1(msg) }
for await (const msg of wsMessages) { handleMsg2(msg) }  // Different messages!

// Share mouse position stream
const mousePosition = share(
  fromEvent(document, 'mousemove')
)

// Use replay(1) instead if you need the current value for late subscribers
const currentPosition = replay(1, mousePosition)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Shares a stream among multiple consumers without buffering.
 * New subscribers only receive values emitted after subscription.
 * 
 * @example
 * const shared = share(sourceStream)
 * const consumer1 = shared[Symbol.asyncIterator]()
 * // ... later ...
 * const consumer2 = shared[Symbol.asyncIterator]()
 * // consumer2 misses values emitted before subscription
 */
export function share<T>(source: AsyncIterable<T>): AsyncIterable<T> {
  return replay(0, source)
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('share', () => {
  it('shares without buffering', async () => {
    const source = from([1, 2, 3])
    const shared = share(source)
    
    // First consumer gets all values
    const values1 = await collect(shared)
    
    // Second consumer gets nothing (no buffer)
    const values2 = await collect(shared)
    
    expect(values1).toEqual([1, 2, 3])
    expect(values2).toEqual([])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
def share(source: AsyncIterable[T]) -> AsyncIterable[T]:
  """Shares a stream without buffering."""
  return replay(0, source)
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py
class TestShare:
  async def test_shares_without_buffer(self):
    source = from_iter([1, 2, 3])
    shared = share(source)
    
    result = await collect(shared)
    assert result == [1, 2, 3]
#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Share a stream among multiple consumers without buffering.
/// This is equivalent to replay(0, source).
fn share<T, S>(source: S) -> impl futures::Stream<Item = T>
where
  T: Clone + Send + 'static,
  S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
  replay(0, source)
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod share_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_share_basic() {
    // share is replay(0, source)
    // Test that it compiles and basic streaming works
    let source = futures::stream::iter(vec![1, 2, 3]);
    let shared = share(source);
    futures::pin_mut!(shared);
    
    let first = shared.next().await;
    assert_eq!(first, Some(1));
    
    let second = shared.next().await;
    assert_eq!(second, Some(2));
    
    let third = shared.next().await;
    assert_eq!(third, Some(3));
    
    let done = shared.next().await;
    assert_eq!(done, None);
  }
}
#+end_src

** =replayFactory= and =replayStream=

The =replayFactory= function returns a factory that produces independent stream copies.
Each emitted stream is a complete replay of the source from the beginning.

This is useful when you need to provide fresh copies of a stream to different parts of your application.

*** When to Use

Use =replayFactory= when you need to provide independent copies of a stream to different parts of your application. Each factory call produces a fresh subscriber that receives all buffered values plus live updates.

#+begin_src text :tangle no
source:           --1--2--3--4--5--|

factory()         [1,2]3--4--5--|  (first call, buffer=2)
factory()         [1,2,3]4--5--|  (second call)
factory()         [1,2,3,4,5]|    (called after complete)#+end_src

#+begin_src javascript :tangle no
// Create factory for shared data
const getDataStream = replayFactory(Infinity, fetchDataStream())

// Each component gets independent copy
const component1Data = getDataStream()
const component2Data = getDataStream()

// Late components still get all data
setTimeout(() => {
  const lateData = getDataStream()  // gets everything
}, 5000)
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Creates a factory that produces independent copies of a buffered stream.
 * 
 * @param bufferSize - Maximum values to buffer
 * @param source - The source stream
 * @returns A function that creates new stream copies
 * 
 * @example
 * const factory = replayFactory(Infinity, sourceStream)
 * 
 * const copy1 = factory()  // Gets all values from beginning
 * const copy2 = factory()  // Also gets all values from beginning
 */
export function replayFactory<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): () => AsyncIterable<T> {
  const subject = new ReplaySubject<T>(bufferSize)
  let started = false

  const startSource = () => {
    if (started) return
    started = true
    
    ;(async () => {
      try {
        for await (const value of source) {
          subject.next(value)
        }
        subject.complete()
      } catch (e) {
        subject.throw(e as Error)
      }
    })()
  }

  return () => {
    startSource()
    return {
      [Symbol.asyncIterator]: () => subject[Symbol.asyncIterator]()
    }
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('replayFactory', () => {
  it('creates factory that produces stream copies', async () => {
    const factory = replayFactory(Infinity, from([1, 2, 3]))
    
    const copy1 = await collect(factory())
    const copy2 = await collect(factory())
    
    expect(copy1).toEqual([1, 2, 3])
    expect(copy2).toEqual([1, 2, 3])
  })

  it('respects buffer size in replayFactory', async () => {
    const factory = replayFactory(2, from([1, 2, 3, 4, 5]))
    
    // First consumer gets all values and triggers buffering
    const copy1 = await collect(factory())
    expect(copy1).toEqual([1, 2, 3, 4, 5])
    
    // Second consumer only gets last 2 buffered values
    const copy2 = await collect(factory())
    expect(copy2).toEqual([4, 5])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
def replay_factory(
  buffer_size: int,
  source: AsyncIterable[T]
) -> Callable[[], AsyncIterable[T]]:
  """Creates a factory that produces independent copies of a buffered stream."""
  subject = ReplaySubject[T](buffer_size)
  started = False

  async def start_source():
    nonlocal started
    if started:
      return
    started = True

    try:
      async for value in source:
        subject.next(value)
      subject.complete()
    except Exception as e:
      subject.throw(e)

  def factory() -> AsyncIterable[T]:
    asyncio.create_task(start_source())
    return subject

  return factory
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Creates a factory that produces independent copies of a buffered stream.
/// Each call to the factory returns a fresh stream that replays buffered values.
fn replay_factory<T, S>(
  buffer_size: usize,
  source: S,
) -> impl Fn() -> BoxedStream<T>
where
  T: Clone + Send + Sync + 'static,
  S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
  struct SharedState<T> {
    buffer: Vec<T>,
    buffer_size: usize,
    completed: bool,
    subscribers: Vec<futures::channel::mpsc::UnboundedSender<T>>,
  }
  
  let state = Arc::new(Mutex::new(SharedState {
    buffer: Vec::new(),
    buffer_size,
    completed: false,
    subscribers: Vec::new(),
  }));
  let started = Arc::new(AtomicBool::new(false));
  let source = Arc::new(Mutex::new(Some(source)));
  
  move || {
    let state = state.clone();
    let started = started.clone();
    let source = source.clone();
    
    Box::pin(async_stream::stream! {
      // Start source consumption if not already started
      if !started.swap(true, Ordering::SeqCst) {
        let state_clone = state.clone();
        if let Some(mut src) = source.lock().await.take() {
          // Note: Spawning requires the Runtime trait
          // R::spawn(async move { ... });
          // For simplicity, consume source in current task

          while let Some(value) = src.next().await {
            let mut guard = state_clone.lock().await;
            guard.buffer.push(value.clone());
            if guard.buffer.len() > guard.buffer_size { guard.buffer.remove(0); }
            guard.subscribers.retain(|tx| tx.unbounded_send(value.clone()).is_ok());
          }
          state_clone.lock().await.completed = true;
        }
      }
      
      let (tx, mut rx) = futures::channel::mpsc::unbounded();
      let buffered: Vec<T>;
      {
        let mut guard = state.lock().await;
        buffered = guard.buffer.clone();
        if !guard.completed { guard.subscribers.push(tx); }
      }
      
      for value in buffered { yield value; }
 
      while let Some(value) = rx.next().await { yield value; }
    })
  }
}

/// Version that accepts a Runtime for spawning source consumption
pub fn replay_factory_spawned<R, T, S>(
  buffer_size: usize,
  source: S,
) -> impl Fn() -> BoxedStream<T>
where
  R: Runtime,
  T: Clone + Send + Sync + 'static,
  S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
  struct SharedState<T> {
    buffer: Vec<T>,
    buffer_size: usize,
    completed: bool,
    subscribers: Vec<futures::channel::mpsc::UnboundedSender<T>>,
  }
  
  let state = Arc::new(Mutex::new(SharedState {
    buffer: Vec::new(),
    buffer_size,
    completed: false,
    subscribers: Vec::new(),
  }));
  let started = Arc::new(AtomicBool::new(false));
  let source = Arc::new(Mutex::new(Some(source)));
  
  move || {
    let state = state.clone();
    let started = started.clone();
    let source = source.clone();
    
    Box::pin(async_stream::stream! {
      if !started.swap(true, Ordering::SeqCst) {
        let state_clone = state.clone();
        if let Some(src) = source.lock().await.take() {
          R::spawn(async move {
            futures::pin_mut!(src);
            while let Some(value) = src.next().await {
              let mut guard = state_clone.lock().await;
              guard.buffer.push(value.clone());
              if guard.buffer.len() > guard.buffer_size { guard.buffer.remove(0); }
              guard.subscribers.retain(|tx| tx.unbounded_send(value.clone()).is_ok());
            }
            state_clone.lock().await.completed = true;
          });
        }
      }
      
      let (tx, mut rx) = futures::channel::mpsc::unbounded();
      let buffered: Vec<T>;
      {
        let mut guard = state.lock().await;
        buffered = guard.buffer.clone();
        if !guard.completed { guard.subscribers.push(tx); }
      }
      
      for value in buffered { yield value; }
      
      while let Some(value) = rx.next().await { yield value; }
    })
  }
}
#+end_src

** =replayStream=

=replayStream= returns a stream that emits independent copies of the source stream.

*** When to Use

Use =replayStream= when you need to emit independent copies of a source stream as a meta-stream. Each emitted stream is a fresh subscriber.

#+begin_src text :tangle no
source:           --1--2--3--|

replayStream:     [S1]--[S2]--[S3]--...  (stream of streams)
                  S1: 1--2--3
                  S2: 1--2--3
                  S3: 1--2--3#+end_src

#+begin_src javascript :tangle no
// Provide streams to workers
const copies = replayStream(Infinity, sourceData)

for await (const workerStream of copies) {
  spawnWorker(workerStream)  // each worker gets full copy
}
#+end_src

*** Typescript Implementation

#+begin_src typescript :tangle typescript/index.ts
/**
 * Returns a stream that emits independent copies of the source stream.
 * Each pull creates a new subscriber that receives buffered + live values.
 * 
 * @example
 * const copies = replayStream(2, sourceStream)
 * 
 * for await (const streamCopy of copies) {
 *   // Each streamCopy is an independent consumer
 *   processStream(streamCopy)
 * }
 */
export async function* replayStream<T>(
  bufferSize: number,
  source: AsyncIterable<T>,
): AsyncGenerator<AsyncIterable<T>, void, void> {
  const factory = replayFactory(bufferSize, source)
  
  // Emit copies indefinitely until the caller stops asking
  while (true) {
    yield factory()
  }
}
#+end_src

**** Tests

#+begin_src typescript :noweb-ref tests
describe('replayStream', () => {
  it('emits stream copies', async () => {
    const copies = replayStream(Infinity, from([1, 2, 3]))
    
    // Get first copy
    const first = await copies.next()
    expect(first.done).toBe(false)
    
    // Collect values from the copy
    const values = await collect(first.value!)
    expect(values).toEqual([1, 2, 3])
  })
})
#+end_src

*** Python Implementation

#+begin_src python :tangle python/agent_rex.py
async def replay_stream(
  buffer_size: int,
  source: AsyncIterable[T]
) -> AsyncIterator[AsyncIterable[T]]:
  """Returns a stream that emits independent copies of the source stream."""
  factory = replay_factory(buffer_size, source)
  while True:
    yield factory()
#+end_src

**** Tests

#+begin_src python :tangle python/test_agent_rex.py

#+end_src

*** Rust Implementation

#+begin_src rust :tangle rust/src/lib.rs
/// Returns a stream that emits independent copies of the source stream.
/// Each pull creates a new subscriber that receives buffered + live values.
fn replay_stream<T, S>(
  buffer_size: usize,
  source: S,
) -> impl futures::Stream<Item = impl futures::Stream<Item = T>>
where
  T: Clone + Send + Sync + 'static,
  S: futures::Stream<Item = T> + Send + Unpin + 'static,
{
  let factory = replay_factory(buffer_size, source);
  
  async_stream::stream! {
  // Emit stream copies indefinitely
  loop { yield factory(); }
  }
}

// Example usage
async fn replay_stream_example() {
  let source = futures::stream::iter(vec![1, 2, 3]);
  let copies = replay_stream(usize::MAX, source);
  futures::pin_mut!(copies);
  
  // Get first copy
  if let Some(copy) = copies.next().await {
    futures::pin_mut!(copy);
    let values: Vec<_> = copy.collect().await;
    println!("Copy values: {:?}", values);
  }
}
#+end_src

**** Tests

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod replay_stream_tests {
  // Note: replay_stream returns a stream of streams
  // Basic functionality tested in replay_stream_example
  // More comprehensive tests would verify multiple copies
}
#+end_src

* Testing with Virtual Time

Time-based operators like =debounce=, =throttle=, =delay=, and =periodic= are challenging to test
because real-time delays make tests slow and non-deterministic. The solution is a =TestRuntime=
that uses virtual time - allowing tests to control time progression explicitly.

*Current Status:* The test suite currently uses =#[tokio::test]= with short real-time durations
(10-50ms) which keeps tests fast (=~0.04s= total). The =TestRuntime= below is available for tests
that need deterministic timing control or when real delays become problematic.

** Design Philosophy

The =TestRuntime= implements the same =Runtime= trait as =TokioRuntime= and =SmolRuntime=,
but instead of using real clocks:

1. *Virtual Clock*: Maintains an internal time counter that only advances when explicitly told to
2. *Pending Timers*: Sleep futures and intervals register themselves with the runtime
3. *Deterministic Advancement*: =advance_by()= or =advance_to()= progresses virtual time and wakes any pending timers
4. *Instant Execution*: Tests run in microseconds instead of waiting for real delays

** =TestRuntime=

The core structure that tracks virtual time and manages pending timers.

#+begin_src rust :tangle rust/src/lib.rs
use std::sync::atomic::AtomicU64;
use std::task::Waker;

/// A test runtime with virtual time for deterministic testing.
/// 
/// Unlike real runtimes, time only advances when you call `advance_by()` or `advance_to()`.
/// This allows instant, reproducible tests for time-based operators.
/// 
/// # Example
/// 
/// ```rust
/// use agent_rex::TestRuntime;
/// 
/// #[tokio::test]
/// async fn test_debounce() {
///   let runtime = TestRuntime::new();
///   
///   // Create a debounced stream using this runtime
///   let source = futures::stream::iter(vec![1, 2, 3]);
///   let debounced = debounce_with::<TestRuntime>(Duration::from_millis(100), source);
///   
///   // Advance virtual time to trigger debounce
///   runtime.advance_by(Duration::from_millis(150)).await;
///   
///   // Collect results - happens instantly!
/// }
/// ```
#[derive(Clone)]
pub struct TestRuntime {
  inner: Arc<TestRuntimeInner>,
}

struct TestRuntimeInner {
  /// Current virtual time in nanoseconds
  current_time_ns: AtomicU64,
  /// Pending timers waiting to fire
  timers: std::sync::Mutex<Vec<PendingTimer>>,
}

struct PendingTimer {
  /// When this timer should fire (in nanoseconds)
  fire_at_ns: u64,
  /// Waker to call when the timer fires
  waker: Option<Waker>,
  /// Whether this timer has fired
  fired: Arc<std::sync::atomic::AtomicBool>,
}

impl TestRuntime {
  /// Create a new test runtime starting at time zero.
  pub fn new() -> Self {
    Self {
      inner: Arc::new(TestRuntimeInner {
        current_time_ns: AtomicU64::new(0),
        timers: std::sync::Mutex::new(Vec::new()),
      }),
    }
  }
  
  /// Get the current virtual time.
  pub fn now(&self) -> Duration {
    Duration::from_nanos(self.inner.current_time_ns.load(Ordering::SeqCst))
  }
  
  /// Advance virtual time by the given duration.
  /// 
  /// This will wake any timers whose target time has been reached.
  pub async fn advance_by(&self, duration: Duration) {
    let target = self.now() + duration;
    self.advance_to(target).await;
  }
  
  /// Advance virtual time to a specific point.
  /// 
  /// Fires all timers between the current time and target time.
  pub async fn advance_to(&self, target: Duration) {
    let target_ns = target.as_nanos() as u64;
    
    loop {
      // Find and wake timers that should fire
      let wakers_to_wake: Vec<Waker> = {
        let mut timers = self.inner.timers.lock().unwrap();
        let current = self.inner.current_time_ns.load(Ordering::SeqCst);
        
        // Find earliest timer that hasn't fired yet
        let mut earliest: Option<u64> = None;
        for timer in timers.iter() {
          if !timer.fired.load(Ordering::SeqCst) && timer.fire_at_ns <= target_ns {
            earliest = Some(match earliest {
              Some(e) => e.min(timer.fire_at_ns),
              None => timer.fire_at_ns,
            });
          }
        }
        
        match earliest {
          Some(fire_time) if fire_time > current => {
            // Advance time to this timer
            self.inner.current_time_ns.store(fire_time, Ordering::SeqCst);
            
            // Collect wakers for timers at this time
            timers.iter_mut()
              .filter(|t| t.fire_at_ns == fire_time && !t.fired.load(Ordering::SeqCst))
              .filter_map(|t| {
                t.fired.store(true, Ordering::SeqCst);
                t.waker.take()
              })
              .collect()
          }
          _ => {
            // No more timers to fire, advance to target
            self.inner.current_time_ns.store(target_ns, Ordering::SeqCst);
            break;
          }
        }
      };
      
      // Wake timers outside the lock
      for waker in wakers_to_wake {
        waker.wake();
      }
      
      // Yield to allow woken tasks to run
      futures::future::poll_fn(|_| std::task::Poll::Ready(())).await;
    }
    
    // Clean up fired timers
    {
      let mut timers = self.inner.timers.lock().unwrap();
      timers.retain(|t| !t.fired.load(Ordering::SeqCst));
    }
  }
  
  /// Register a timer that fires at a specific time.
  fn register_timer(&self, fire_at: Duration) -> Arc<std::sync::atomic::AtomicBool> {
    let fired = Arc::new(std::sync::atomic::AtomicBool::new(false));
    let timer = PendingTimer {
      fire_at_ns: fire_at.as_nanos() as u64,
      waker: None,
      fired: fired.clone(),
    };
    self.inner.timers.lock().unwrap().push(timer);
    fired
  }
  
  /// Update the waker for a pending timer.
  fn set_timer_waker(&self, fire_at_ns: u64, waker: Waker) {
    let mut timers = self.inner.timers.lock().unwrap();
    for timer in timers.iter_mut() {
      if timer.fire_at_ns == fire_at_ns && !timer.fired.load(Ordering::SeqCst) {
        timer.waker = Some(waker);
        break;
      }
    }
  }
}

impl Default for TestRuntime {
  fn default() -> Self {
    Self::new()
  }
}
#+end_src

** =TestSleep= Future

A future that completes when virtual time reaches its target.

#+begin_src rust :tangle rust/src/lib.rs
/// A future that completes when the test runtime's virtual time reaches the target.
pub struct TestSleep {
  runtime: TestRuntime,
  target_ns: u64,
  fired: Arc<std::sync::atomic::AtomicBool>,
  registered: bool,
}

impl TestSleep {
  fn new(runtime: TestRuntime, duration: Duration) -> Self {
    let current = runtime.now();
    let target = current + duration;
    let target_ns = target.as_nanos() as u64;
    Self {
      runtime,
      target_ns,
      fired: Arc::new(std::sync::atomic::AtomicBool::new(false)),
      registered: false,
    }
  }
}

impl Future for TestSleep {
  type Output = ();
  
  fn poll(mut self: Pin<&mut Self>, cx: &mut std::task::Context<'_>) -> std::task::Poll<()> {
    // Check if already fired
    if self.fired.load(Ordering::SeqCst) {
      return std::task::Poll::Ready(());
    }
    
    // Check if target time reached
    let current_ns = self.runtime.inner.current_time_ns.load(Ordering::SeqCst);
    if current_ns >= self.target_ns {
      self.fired.store(true, Ordering::SeqCst);
      return std::task::Poll::Ready(());
    }
    
    // Register timer if not yet done
    if !self.registered {
      self.fired = self.runtime.register_timer(Duration::from_nanos(self.target_ns));
      self.registered = true;
    }
    
    // Update waker
    self.runtime.set_timer_waker(self.target_ns, cx.waker().clone());
    
    std::task::Poll::Pending
  }
}
#+end_src

** =TestInterval= Stream

A stream that yields at regular virtual time intervals.

#+begin_src rust :tangle rust/src/lib.rs
/// A stream that yields at regular intervals based on virtual time.
pub struct TestInterval {
  runtime: TestRuntime,
  period_ns: u64,
  next_fire_ns: u64,
  current_timer: Option<Arc<std::sync::atomic::AtomicBool>>,
}

impl TestInterval {
  fn new(runtime: TestRuntime, period: Duration) -> Self {
    let period_ns = period.as_nanos() as u64;
    let start = runtime.inner.current_time_ns.load(Ordering::SeqCst);
    Self {
      runtime,
      period_ns,
      next_fire_ns: start + period_ns,
      current_timer: None,
    }
  }
}

impl futures::Stream for TestInterval {
  type Item = ();
  
  fn poll_next(mut self: Pin<&mut Self>, cx: &mut std::task::Context<'_>) -> std::task::Poll<Option<()>> {
    let current_ns = self.runtime.inner.current_time_ns.load(Ordering::SeqCst);
    
    // Check if it's time to fire
    if current_ns >= self.next_fire_ns {
      // Schedule next tick
      self.next_fire_ns += self.period_ns;
      self.current_timer = None;
      return std::task::Poll::Ready(Some(()));
    }
    
    // Register timer if needed
    if self.current_timer.is_none() {
      self.current_timer = Some(self.runtime.register_timer(Duration::from_nanos(self.next_fire_ns)));
    }
    
    // Update waker
    self.runtime.set_timer_waker(self.next_fire_ns, cx.waker().clone());
    
    std::task::Poll::Pending
  }
}
#+end_src

** Runtime Implementation

Implement the =Runtime= trait for =TestRuntime=.

#+begin_src rust :tangle rust/src/lib.rs
impl Runtime for TestRuntime {
  fn sleep(duration: Duration) -> Pin<Box<dyn Future<Output = ()> + Send>> {
    // Note: This requires a runtime instance, but the trait is static.
    // For testing, use test_sleep() method directly or use CURRENT_TEST_RUNTIME thread-local.
    // This implementation panics - tests should use the instance methods.
    panic!("TestRuntime::sleep() cannot be called statically. Use runtime.test_sleep(duration) instead.")
  }
  
  fn interval(period: Duration) -> Pin<Box<dyn futures::Stream<Item = ()> + Send>> {
    panic!("TestRuntime::interval() cannot be called statically. Use runtime.test_interval(period) instead.")
  }
  
  fn spawn<F>(_future: F)
  where
    F: Future<Output = ()> + Send + 'static,
  {
    // TestRuntime doesn't spawn - tasks are driven by advance_by/advance_to
    // If you need background task support, use #[tokio::test] which provides real spawning
    panic!("TestRuntime::spawn() is not supported. Use advance_by() to drive futures.")
  }
}

impl TestRuntime {
  /// Create a sleep future tied to this runtime instance.
  pub fn test_sleep(&self, duration: Duration) -> TestSleep {
    TestSleep::new(self.clone(), duration)
  }
  
  /// Create an interval stream tied to this runtime instance.
  pub fn test_interval(&self, period: Duration) -> TestInterval {
    TestInterval::new(self.clone(), period)
  }
}
#+end_src

** Test Helpers

Convenience functions for common test scenarios.

#+begin_src rust :tangle rust/src/lib.rs
impl TestRuntime {
  /// Run a test with controlled time, returning the result.
  /// 
  /// This is a convenience method that advances time in steps,
  /// useful for testing debounce/throttle behavior.
  pub async fn run_timed_test<T, F, Fut>(&self, steps: Vec<Duration>, mut f: F) -> T
  where
    F: FnMut() -> Fut,
    Fut: Future<Output = T>,
  {
    for step in steps {
      self.advance_by(step).await;
    }
    f().await
  }
  
  /// Assert that a future completes within a virtual time budget.
  pub async fn assert_completes_within<T, Fut>(&self, timeout: Duration, fut: Fut) -> T
  where
    Fut: Future<Output = T>,
  {
    use futures::future::{select, Either};
    
    let timeout_fut = self.test_sleep(timeout);
    futures::pin_mut!(fut);
    futures::pin_mut!(timeout_fut);
    
    // First poll: check if fut is ready
    match futures::future::select(fut, timeout_fut).await {
      Either::Left((result, _)) => result,
      Either::Right(_) => panic!("Future did not complete within {:?}", timeout),
    }
  }
}
#+end_src

** Example: Testing Debounce with Virtual Time

Here's how to use =TestRuntime= to test time-based operators instantly:

#+begin_src rust :tangle rust/src/lib.rs
#[cfg(test)]
mod test_runtime_tests {
  use super::*;
  
  #[tokio::test]
  async fn test_virtual_sleep() {
    let runtime = TestRuntime::new();
    
    // Initially at time zero
    assert_eq!(runtime.now(), Duration::ZERO);
    
    // Create a sleep future
    let sleep = runtime.test_sleep(Duration::from_millis(100));
    futures::pin_mut!(sleep);
    
    // Poll it - should be pending
    let waker = futures::task::noop_waker();
    let mut cx = std::task::Context::from_waker(&waker);
    assert!(Pin::new(&mut sleep).poll(&mut cx).is_pending());
    
    // Advance time past the sleep target
    runtime.advance_by(Duration::from_millis(150)).await;
    
    // Now it should be ready
    assert_eq!(runtime.now(), Duration::from_millis(150));
  }
  
  #[tokio::test]
  async fn test_virtual_interval() {
    let runtime = TestRuntime::new();
    let mut interval = runtime.test_interval(Duration::from_millis(100));
    
    // Advance to first tick
    runtime.advance_by(Duration::from_millis(100)).await;
    assert_eq!(interval.next().await, Some(()));
    
    // Advance to second tick
    runtime.advance_by(Duration::from_millis(100)).await;
    assert_eq!(interval.next().await, Some(()));
    
    // Verify time
    assert_eq!(runtime.now(), Duration::from_millis(200));
  }
  
  #[tokio::test]
  async fn test_multiple_timers() {
    let runtime = TestRuntime::new();
    
    // Create multiple sleeps
    let sleep1 = runtime.test_sleep(Duration::from_millis(50));
    let sleep2 = runtime.test_sleep(Duration::from_millis(100));
    let sleep3 = runtime.test_sleep(Duration::from_millis(150));
    
    futures::pin_mut!(sleep1);
    futures::pin_mut!(sleep2);
    futures::pin_mut!(sleep3);
    
    let waker = futures::task::noop_waker();
    let mut cx = std::task::Context::from_waker(&waker);
    
    // All pending initially
    assert!(Pin::new(&mut sleep1).poll(&mut cx).is_pending());
    assert!(Pin::new(&mut sleep2).poll(&mut cx).is_pending());
    assert!(Pin::new(&mut sleep3).poll(&mut cx).is_pending());
    
    // Advance to 75ms - only first should fire
    runtime.advance_to(Duration::from_millis(75)).await;
    assert!(Pin::new(&mut sleep1).poll(&mut cx).is_ready());
    assert!(Pin::new(&mut sleep2).poll(&mut cx).is_pending());
    assert!(Pin::new(&mut sleep3).poll(&mut cx).is_pending());
    
    // Advance to 125ms - second should fire
    runtime.advance_to(Duration::from_millis(125)).await;
    assert!(Pin::new(&mut sleep2).poll(&mut cx).is_ready());
    assert!(Pin::new(&mut sleep3).poll(&mut cx).is_pending());
    
    // Advance to 200ms - third should fire
    runtime.advance_to(Duration::from_millis(200)).await;
    assert!(Pin::new(&mut sleep3).poll(&mut cx).is_ready());
  }
}
#+end_src

** Integration with Time-Based Operators

To use =TestRuntime= with operators like =debounce= and =throttle=, you need runtime-parameterized
versions of these operators. Here's the pattern:

#+begin_src rust :tangle rust/src/lib.rs
/// Delay operator that works with TestRuntime.
/// 
/// Unlike the generic `delay_with`, this takes a runtime instance
/// so virtual time can be controlled.
pub fn delay_test<T, S>(
  runtime: TestRuntime,
  duration: Duration,
  source: S,
) -> impl futures::Stream<Item = T>
where
  T: Send + 'static,
  S: futures::Stream<Item = T> + Send + 'static,
{
  stream! {
    futures::pin_mut!(source);
    while let Some(value) = source.next().await {
      runtime.test_sleep(duration).await;
      yield value;
    }
  }
}

/// Periodic stream using TestRuntime.
pub fn periodic_test(runtime: TestRuntime, period: Duration) -> impl futures::Stream<Item = u64> {
  stream! {
    let mut count = 0u64;
    let mut interval = runtime.test_interval(period);
    loop {
      interval.next().await;
      yield count;
      count += 1;
    }
  }
}
#+end_src

** Usage Example

#+begin_src rust :tangle no
#[tokio::test]
async fn test_delay_with_virtual_time() {
  let runtime = TestRuntime::new();
  
  let source = futures::stream::iter(vec![1, 2, 3]);
  let delayed = delay_test(runtime.clone(), Duration::from_secs(1), source);
  futures::pin_mut!(delayed);
  
  // Start polling - nothing yet
  let waker = futures::task::noop_waker();
  let mut cx = std::task::Context::from_waker(&waker);
  assert!(Pin::new(&mut delayed).poll_next(&mut cx).is_pending());
  
  // Advance 1 second - first value should be ready
  runtime.advance_by(Duration::from_secs(1)).await;
  assert_eq!(delayed.next().await, Some(1));
  
  // Advance another second - second value
  runtime.advance_by(Duration::from_secs(1)).await;
  assert_eq!(delayed.next().await, Some(2));
  
  // Total virtual time: 2 seconds
  // Actual test time: milliseconds!
}
#+end_src

* Project Configuration

Configuration files for building and testing the library.

** Building and Testing

*** TypeScript

**** Prerequisites

#+begin_src shell :tangle no
# Ensure Node.js (v18+) and npm are installed
node --version
npm --version#+end_src

**** Setup

#+begin_src shell :tangle no
cd typescript
npm install
#+end_src

**** Running Tests

#+begin_src shell :tangle no
# Run tests in watch mode (during development)
npm test

# Run tests once
npm run test:run

# Run tests with coverage
npm run test:coverage
#+end_src

**** Building for Distribution

#+begin_src shell :tangle no
# Compile TypeScript to JavaScript
npx tsc

# Output will be in dist/
ls dist/
#+end_src

**** Publishing to npm

#+begin_src shell :tangle no
# Ensure you're logged in to npm
npm login

# Update version in package.json, then:
npm publish
#+end_src

*** Python

**** Prerequisites

#+begin_src shell :tangle no
# Ensure Python 3.8+ and pip are installed
python --version
pip --version
#+end_src

**** Project Configuration

#+begin_src toml :tangle python/pyproject.toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "agent-rex"
version = "0.1.0"
description = "An Async Generator/Iterator Based FRP-Like Library for Python"
requires-python = ">=3.10"
license = "MIT"
keywords = ["async", "reactive", "streams", "frp", "generators"]
authors = [
    { name = "Tim Wilson", email = "tim@example.com" },
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Framework :: AsyncIO",
    "Typing :: Typed",
]
dependencies = []

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-asyncio>=0.21",
    "mypy>=1.0",
]

[project.urls]
Homepage = "https://github.com/example/agent-rex"
Issues = "https://github.com/example/agent-rex/issues"
Source = "https://github.com/example/agent-rex"

[tool.hatch.build.targets.wheel]
include = ["agent_rex.py"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["."]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
strict = true
#+end_src

**** Exports

#+begin_src python :tangle python/agent_rex.py
__all__ = [
  # Creation
  'just', 'of', 'from_promise', 'from_iter', 'periodic', 'empty', 'never',
  'iterate', 'unfold', 'start_with', 'concat',

  # Composition
  'pipe',

  # Transformation
  'map', 'constant', 'scan', 'tap', 'await_tap', 'continue_with',
  'concat_all', 'concat_map',

  # Filtering
  'filter', 'skip_repeats', 'skip_repeats_with',

  # Slicing
  'take', 'skip', 'slice', 'take_while', 'skip_while', 'take_until',

  # Time
  'delay', 'debounce', 'throttle', 'ThrottleOptions',

  # Error handling
  'recover_with', 'throw_error', 'retry', 'RetryOptions',

  # Concurrent
  'merge', 'merge_all', 'chain', 'flat_map', 'switch_map',
  'latest', 'apply_latest', 'until_stream', 'since_stream',

  # Buffering
  'buffer', 'buffer_time', 'window', 'eager', 'eager_now',

  # Multicasting
  'ReplaySubject', 'replay', 'share', 'replay_factory', 'replay_stream',

  # Types
  'UnfoldResult',
]
#+end_src

*** Rust

**** Prerequisites

#+begin_src shell :tangle no
# Ensure Rust toolchain is installed (via rustup)
rustc --version
cargo --version
#+end_src

**** Building

#+begin_src shell :tangle no
cd rust

# Build with default features (no runtime)
cargo build

# Build with a specific runtime
cargo build --features tokio-runtime
cargo build --features smol-runtime
cargo build --features async-std-runtime

# Build in release mode
cargo build --release
#+end_src

**** Running Tests

#+begin_src shell :tangle no
# Run all tests (uses tokio in dev-dependencies)
cargo test

# Run tests with a specific runtime feature
cargo test --features tokio-runtime

# Run tests with output
cargo test -- --nocapture

# Run a specific test
cargo test test_just
#+end_src

**** Documentation

#+begin_src shell :tangle no
# Generate and open documentation
cargo doc --open

# Generate docs with all features
cargo doc --all-features --open
#+end_src

**** Publishing to crates.io

#+begin_src shell :tangle no
# Ensure you're logged in to crates.io
cargo login

# Dry run to check for issues
cargo publish --dry-run

# Publish
cargo publish
#+end_src

**** Feature Flags

The Rust crate supports the following feature flags:

| Feature          | Description                                      |
|------------------+--------------------------------------------------|
| =tokio-runtime=  | Enable tokio-specific runtime implementations    |
| =smol-runtime=   | Enable smol-specific runtime implementations     |
| =async-std-runtime= | Enable async-std-specific runtime implementations |

Example usage in =Cargo.toml=:

#+begin_src toml :tangle no
[dependencies]
agent-rex = { version = "0.1", features = ["tokio-runtime"] }
#+end_src


*** Tangling with Organjsm

This project was built using Organjsm, my Typescript implementation of Org-mode.
It's still early days for Organjsm, but it allows me to write literate TypeScript and Rust code.
You can find it on [[https://github.com/TimothyMischief/organjsm][GitHub]].
At date of writing @organjsm/core with a cli isn't available on npm yet, so clone the repo and build locally.
There's also a VSCode extension with .vsix available in the monorepo, which also isn't published yet, but already provides language intelligence forwarding, tanlging support (both scripts and real-time tracking of tangle changes and language intelligence for embdedded languages) and syntax highlighting.
The custom editor the extension packages is still broken, as are some features like context expansion.

You'll notice some =:noweb-ref= blocks in this document have a =:context= tag, this is an extension I made so language intelligence can place the code in a context for better type checking and error reporting.
I have plans to write emacs integration for these tools and the org mdoe LSP server organjsm uses, but my emacs lisp skills are limited at best, so that may take a while.

*** Tangling from Org-mode

To extract source files from this literate document:

#+begin_src emacs-lisp :tangle no

;; In Emacs, open index.org and run:
(org-babel-tangle)
;; Or use the keybinding: C-c C-v t
#+end_src

#+begin_src bash :tangle no

# You can also call emacs in batch mode to tangle:
emacs --batch -l org index.org -f org-babel-tangle
#+end_src

This will create the following directory structure:

#+begin_src text :tangle no
.
├── typescript/
│   ├── index.ts           # Main library
│   ├── index.test.ts      # Tests
│   ├── test-helpers.ts    # Test utilities
│   ├── package.json
│   ├── tsconfig.json
│   └── vitest.config.ts
└── rust/
    ├── Cargo.toml
    └── src/
        ├── lib.rs
        ├── runtime.rs
        ├── creation.rs
        ├── transformation.rs
        ├── filtering.rs
        ├── slicing.rs
        ├── time.rs
        ├── error_handling.rs
        ├── concurrent.rs
        ├── buffering.rs
        └── multicasting.rs
#+end_src

** =package.json=

#+begin_src json :tangle typescript/package.json
{
  "name": "agent-rex",
  "version": "0.1.0",
  "description": "An Async Generator/Iterator Based FRP-Like Library for JavaScript",
  "type": "module",
  "main": "index.ts",
  "scripts": {
    "test": "vitest",
    "test:run": "vitest run",
    "test:coverage": "vitest run --coverage"
  },
  "devDependencies": {
    "vitest": "^2.1.0",
    "typescript": "^5.6.0"
  },
  "author": "Timothy Hope",
  "license": "MIT"
}
#+end_src

** =vitest.config.ts=

#+begin_src typescript :tangle typescript/vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    globals: true,
    include: ['**/*.test.ts'],
    testTimeout: 5000,
  },
})
#+end_src

** =tsconfig.json=

#+begin_src json :tangle typescript/tsconfig.json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "declaration": true,
    "outDir": "dist",
    "rootDir": "."
  },
  "include": ["*.ts"],
  "exclude": ["node_modules", "dist"]
}
#+end_src

** =Cargo.toml=

#+begin_src toml :tangle rust/Cargo.toml
[package]
name = "agent-rex"
version = "0.1.0"
edition = "2021"
description = "An async Stream-based FRP-like library for Rust"
license = "MIT"
authors = ["Timothy Hope"]

[features]
default = []
tokio-runtime = ["tokio"]
smol-runtime = ["smol"]
async-std-runtime = ["async-std"]

[dependencies]
futures = "0.3"
async-stream = "0.3"
async-lock = "3.0"
pin-project-lite = "0.2"

# Optional runtime-specific dependencies
tokio = { version = "1", features = ["rt", "time", "sync", "macros"], optional = true }
smol = { version = "2", optional = true }
async-std = { version = "1", features = ["attributes"], optional = true }

# For time-based operations without a specific runtime
futures-timer = "3"

[dev-dependencies]
tokio = { version = "1", features = ["rt-multi-thread", "time", "sync", "macros"] }
#+end_src

** =rust/src/lib.rs= (Library Header)

The Rust implementation is organized as a single-file library, matching the TypeScript approach.
This block tangles first to establish imports and core types.

#+begin_src rust :tangle no :noweb-ref lib-header :context rust-setup
//! # Agent Rex
//! 
//! An async Stream-based FRP-like library for Rust.
//! 
//! This library provides composable stream operators similar to RxJS/Most.js,
//! built on top of the `futures` crate's `Stream` trait.
//! 
//! ## Runtime Agnostic
//! 
//! Most operators are runtime-agnostic and work with any async executor.
//! For time-based operations, we provide generic versions that accept
//! a sleep function parameter, plus feature-flagged implementations
//! for specific runtimes (tokio, smol, async-std).

// Core imports - defined once at the top
use std::error::Error;
use std::future::{Future, pending};
use std::pin::Pin;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::time::{Duration, Instant};

use async_stream::stream;
use futures::{Stream, StreamExt, FutureExt};
use futures::channel::mpsc;
use futures::lock::Mutex;
use futures::stream;

/// Type alias for boxed streams
pub type BoxedStream<T> = Pin<Box<dyn Stream<Item = T> + Send>>;
#+end_src

* Testing Infrastructure

** Typescript

This section provides test helpers for ergonomic testing of async generator streams.
These helpers focus on three key areas:

1. *Stream Creation*: Easily create test streams with controlled timing
2. *Stream Collection*: Collect stream values into arrays or with timing metadata
3. *Assertions*: Custom matchers for stream behavior verification

*** Test Helpers

The test helpers are designed to make testing async streams as intuitive as testing synchronous code.

**** =TestScheduler=

A virtual time scheduler for deterministic testing of time-based operations.
This allows tests to run instantly without waiting for real time to pass.

*Note:* The =TestScheduler= is currently a standalone utility and is not integrated with
the time-based operators (=debounce=, =throttle=, =delay=, =periodic=) out of the box.
To use virtual time in tests, you would need to inject the scheduler's =delay= method
into operators or create custom test variants. A future version may provide tighter integration.

For now, use real-time delays with reasonable durations (10-50ms) for testing, or mock
=setTimeout=/=Promise= directly if you need deterministic timing.

#+begin_src typescript :tangle no
// Usage:
const scheduler = new TestScheduler()

// Schedule events at virtual times
scheduler.schedule(100, () => emit(1))
scheduler.schedule(200, () => emit(2))

// Advance virtual time
await scheduler.advanceTo(150)  // First event fires
await scheduler.advanceTo(300)  // Second event fires#+end_src

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * A virtual time scheduler for deterministic async stream testing.
 * Allows you to control time progression without waiting for real time.
 */
export class TestScheduler {
  private currentTime = 0
  private queue: Array<{ time: number; action: () => void }> = []
  private resolvers: Array<{ time: number; resolve: () => void }> = []

  /**
   * Get the current virtual time in milliseconds.
   */
  get now(): number {
    return this.currentTime
  }

  /**
   * Schedule an action to run at a specific virtual time.
   */
  schedule(time: number, action: () => void): void {
    this.queue.push({ time, action })
    this.queue.sort((a, b) => a.time - b.time)
  }

  /**
   * Create a promise that resolves after a virtual delay.
   * Use this instead of `setTimeout` in test streams.
   */
  delay(ms: number): Promise<void> {
    const targetTime = this.currentTime + ms
    return new Promise(resolve => {
      this.resolvers.push({ time: targetTime, resolve })
      this.resolvers.sort((a, b) => a.time - b.time)
    })
  }

  /**
   * Advance virtual time to a specific point, executing all scheduled actions.
   */
  async advanceTo(time: number): Promise<void> {
    while (this.queue.length > 0 || this.resolvers.length > 0) {
      const nextQueued = this.queue[0]?.time ?? Infinity
      const nextResolver = this.resolvers[0]?.time ?? Infinity
      const nextTime = Math.min(nextQueued, nextResolver)

      if (nextTime > time) break

      this.currentTime = nextTime

      // Process all actions at this time
      while (this.queue[0]?.time === nextTime) {
        const { action } = this.queue.shift()!
        action()
      }

      // Resolve all delays at this time
      while (this.resolvers[0]?.time === nextTime) {
        const { resolve } = this.resolvers.shift()!
        resolve()
      }

      // Allow microtasks to run
      await Promise.resolve()
    }

    this.currentTime = time
  }

  /**
   * Advance virtual time by a relative amount.
   */
  async advanceBy(ms: number): Promise<void> {
    await this.advanceTo(this.currentTime + ms)
  }

  /**
   * Run all scheduled actions to completion.
   */
  async flush(): Promise<void> {
    const maxTime = Math.max(
      ...this.queue.map(q => q.time),
      ...this.resolvers.map(r => r.time),
      this.currentTime
    )
    await this.advanceTo(maxTime)
  }

  /**
   * Reset the scheduler to initial state.
   */
  reset(): void {
    this.currentTime = 0
    this.queue = []
    this.resolvers = []
  }
}
#+end_src

**** =TestStream=

A controllable async generator for testing.
Values can be pushed manually, allowing precise control over when emissions occur.

#+begin_src typescript :tangle no
// Usage:
const stream = new TestStream<number>()

// Push values (can be done from anywhere)
stream.push(1)
stream.push(2)
stream.complete()

// Consume in test
const values = await collect(stream)
expect(values).toEqual([1, 2])
#+end_src

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * A controllable async stream for testing.
 * Push values manually and control completion/errors.
 */
export class TestStream<T> implements AsyncIterable<T> {
  private queue: T[] = []
  private waiting: ((value: IteratorResult<T>) => void) | null = null
  private done = false
  private error: Error | null = null

  /**
   * Push a value to the stream.
   * If a consumer is waiting, it receives the value immediately.
   */
  push(value: T): void {
    if (this.done) throw new Error('Cannot push to completed stream')
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      resolve({ value, done: false })
    } else {
      this.queue.push(value)
    }
  }

  /**
   * Push multiple values to the stream.
   */
  pushAll(...values: T[]): void {
    values.forEach(v => this.push(v))
  }

  /**
   * Signal that the stream is complete.
   * No more values can be pushed after this.
   */
  complete(): void {
    this.done = true
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      resolve({ value: undefined as any, done: true })
    }
  }

  /**
   * Signal an error on the stream.
   */
  throw(error: Error): void {
    this.error = error
    this.done = true
    // If someone is waiting, we need to reject them
    // However, we can't reject a resolve function directly.
    // The error will be thrown on the next next() call.
    // Clear waiting so they re-check error state.
    if (this.waiting) {
      const resolve = this.waiting
      this.waiting = null
      // Resolve with done=true, the error will be thrown on next call
      // Actually, we need to handle this by having next() check error first
      // which it already does. But for pending waiters, we need to wake them.
      // Since we can't reject, we resolve with done and let next() throw.
      resolve({ value: undefined as any, done: true })
    }
  }

  [Symbol.asyncIterator](): AsyncIterator<T> {
    return {
      next: async (): Promise<IteratorResult<T>> => {
        if (this.error) throw this.error
        if (this.queue.length > 0) {
          return { value: this.queue.shift()!, done: false }
        }
        if (this.done) {
          return { value: undefined as any, done: true }
        }
        return new Promise(resolve => {
          this.waiting = resolve
          // Check for error after setting waiting
          if (this.error) {
            this.waiting = null
            throw this.error
          }
        })
      }
    }
  }
}
#+end_src

***** Tests

#+begin_src typescript :noweb-ref tests
describe('TestStream', () => {
  it('allows manual value pushing', async () => {
    const stream = new TestStream<number>()
    
    // Push values async
    setTimeout(() => {
      stream.push(1)
      stream.push(2)
      stream.complete()
    }, 10)

    const values = await collect(stream)
    expect(values).toEqual([1, 2])
  })
})
#+end_src

**** =collect=

Collectors for gathering stream values into arrays.
Essential for making assertions about stream output.

#+begin_src typescript :tangle no
// Usage:
// Basic collection
const values = await collect(from([1, 2, 3]))
expect(values).toEqual([1, 2, 3])

// With timing information
const timed = await collectWithTime(stream)
// [{ value: 1, time: 0 }, { value: 2, time: 100 }, ...]

// Collect first N values
const first3 = await collectN(3, infiniteStream)
#+end_src

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * Collect all values from a stream into an array.
 * The stream must complete for this to resolve.
 */
export async function collect<T>(stream: AsyncIterable<T>): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) values.push(value)
  return values
}

/**
 * Collected value with timing metadata.
 */
export interface TimedValue<T> {
  value: T
  /** Milliseconds since collection started */
  elapsed: number
}

/**
 * Collect all values from a stream with timing information.
 * Useful for testing time-based operations.
 */
export async function collectWithTime<T>(
  stream: AsyncIterable<T>
): Promise<TimedValue<T>[]> {
  const values: TimedValue<T>[] = []
  const start = Date.now()
  for await (const value of stream) {
    values.push({ value, elapsed: Date.now() - start })
  }
  return values
}

/**
 * Collect exactly N values from a stream.
 * Useful for testing infinite or long-running streams.
 */
export async function collectN<T>(
  n: number,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) {
    values.push(value)
    if (values.length >= n) break
  }
  return values
}

/**
 * Collect values until a predicate returns true.
 * The matching value is included in the result.
 */
export async function collectUntil<T>(
  predicate: (value: T) => boolean,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  for await (const value of stream) {
    values.push(value)
    if (predicate(value)) break
  }
  return values
}

/**
 * Collect values with a timeout.
 * Returns whatever was collected when the timeout expires.
 */
export async function collectWithTimeout<T>(
  ms: number,
  stream: AsyncIterable<T>
): Promise<T[]> {
  const values: T[] = []
  const iterator = stream[Symbol.asyncIterator]()
  const timeout = new Promise<'timeout'>(resolve => 
    setTimeout(() => resolve('timeout'), ms)
  )

  while (true) {
    const result = await Promise.race([iterator.next(), timeout])
    if (result === 'timeout') break
    if (result.done) break
    values.push(result.value)
  }

  return values
}
#+end_src

**** =marble=

Marble testing helpers for visual stream descriptions.
Inspired by RxJS marble diagrams.

#+begin_src text :tangle no
Marble syntax:
  '-'  = 10ms of time passing
  'a'  = emit value (from values object)
  '|'  = complete
  '#'  = error
  '()' = sync grouping (multiple values at same time)

Usage:
  const stream = marble('-a-b-c|', { a: 1, b: 2, c: 3 })
  // Emits 1 at 10ms, 2 at 30ms, 3 at 50ms, completes at 60ms

  expect(await collect(stream)).toEqual([1, 2, 3])
#+end_src

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * Options for marble stream creation.
 */
export interface MarbleOptions<T> {
  /** Map of characters to their emission values */
  values?: Record<string, T>
  /** Time per frame (each '-' or character), default 10ms */
  frameTime?: number
  /** Error to throw when '#' is encountered */
  error?: Error
}

/**
 * Create a stream from a marble diagram string.
 * 
 * Marble syntax:
 * - '-' advances time by one frame
 * - Letters emit the corresponding value from the values map
 * - '|' completes the stream
 * - '#' errors the stream
 * - '()' groups emissions at the same time point
 * 
 * @example
 * const stream = marble('-a-b-|', { a: 1, b: 2 })
 * // Emits 1 at 10ms, 2 at 30ms, completes at 50ms
 */
export async function* marble<T>(
  diagram: string,
  options: MarbleOptions<T> = {}
): AsyncGenerator<T, void, void> {
  const { values = {} as Record<string, T>, frameTime = 10, error = new Error('marble error') } = options
  let i = 0
  let inGroup = false
  let groupValues: T[] = []

  while (i < diagram.length) {
    const char = diagram[i]

    if (char === '-') {
      if (!inGroup) await delay(frameTime)
    } else if (char === '|') {
      return
    } else if (char === '#') {
      throw error
    } else if (char === '(') {
      inGroup = true
      groupValues = []
    } else if (char === ')') {
      inGroup = false
      for (const v of groupValues) yield v
      await delay(frameTime)
    } else if (char === ' ') {
      // Ignore spaces (for readability)
    } else {
      const value = values[char] ?? (char as unknown as T)
      if (inGroup) {
        groupValues.push(value)
      } else {
        yield value
        await delay(frameTime)
      }
    }
    i++
  }
}

function delay(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms))
}

/**
 * Parse a marble diagram into a sequence of events for testing.
 * Returns the expected values and their relative times.
 */
export function parseMarble<T>(
  diagram: string,
  options: MarbleOptions<T> = {}
): Array<{ time: number; value: T }> {
  const { values = {} as Record<string, T>, frameTime = 10 } = options
  const events: Array<{ time: number; value: T }> = []
  let time = 0
  let i = 0
  let inGroup = false

  while (i < diagram.length) {
    const char = diagram[i]

    if (char === '-') {
      if (!inGroup) time += frameTime
    } else if (char === '|' || char === '#') {
      // Completion/error markers don't emit values
    } else if (char === '(') {
      inGroup = true
    } else if (char === ')') {
      inGroup = false
      time += frameTime
    } else if (char === ' ') {
      // Ignore spaces
    } else {
      const value = values[char] ?? (char as unknown as T)
      events.push({ time, value })
      if (!inGroup) time += frameTime
    }
    i++
  }

  return events
}
#+end_src

***** Tests

#+begin_src typescript :noweb-ref tests
describe('marble', () => {
  it('creates streams from marble diagrams', async () => {
    const stream = marble('-a-b-c|', { values: { a: 1, b: 2, c: 3 } })
    const result = await collect(stream)
    expect(result).toEqual([1, 2, 3])
  })
})
#+end_src

#+begin_src typescript :noweb-ref tests
describe('collectWithTime', () => {
  it('records timing of emissions', async () => {
    const stream = createAsyncIterable([1, 2, 3], { delay: 50 })
    const result = await collectWithTime(stream)
    
    expect(result.map(r => r.value)).toEqual([1, 2, 3])
    expect(result[1].elapsed).toBeGreaterThanOrEqual(40)
    expect(result[2].elapsed).toBeGreaterThanOrEqual(90)
  })
})
#+end_src

**** =drainN=

Drain helpers for consuming streams without collecting values.

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * Consume N values from a stream, discarding them.
 * Useful for advancing a stream to a certain point.
 */
export async function drainN<T>(
  n: number,
  stream: AsyncIterable<T>
): Promise<void> {
  let count = 0
  for await (const _ of stream) {
    if (++count >= n) break
  }
}

/**
 * Consume all values from a stream, discarding them.
 * Useful for ensuring a stream completes.
 */
export async function drain<T>(stream: AsyncIterable<T>): Promise<void> {
  for await (const _ of stream) { /* consume */ }
}
#+end_src

**** =spy=

Spy wrappers for observing stream behavior in tests.

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * A record of events that occurred on a spied stream.
 */
export interface SpyEvent<T> {
  type: 'value' | 'complete' | 'error'
  value?: T
  error?: Error
  time: number
}

/**
 * A spy that records stream events for later assertion.
 */
export interface StreamSpy<T> {
  /** The wrapped stream to consume */
  stream: AsyncIterable<T>
  /** All recorded events */
  events: SpyEvent<T>[]
  /** Just the emitted values */
  values: T[]
  /** Whether the stream completed */
  completed: boolean
  /** The error if one occurred */
  error?: Error
  /** Wait for N values to be emitted */
  waitForN(n: number): Promise<T[]>
  /** Wait for completion */
  waitForComplete(): Promise<void>
}

/**
 * Wrap a stream with a spy to record all events.
 * 
 * @example
 * const spied = spy(myStream)
 * await collect(spied.stream)
 * expect(spied.values).toEqual([1, 2, 3])
 * expect(spied.completed).toBe(true)
 */
export function spy<T>(source: AsyncIterable<T>): StreamSpy<T> {
  const startTime = Date.now()
  const events: SpyEvent<T>[] = []
  const values: T[] = []
  let completed = false
  let error: Error | undefined
  let valueListeners: Array<{ count: number; resolve: (values: T[]) => void }> = []
  let completeListeners: Array<() => void> = []

  const stream: AsyncIterable<T> = {
    [Symbol.asyncIterator]() {
      const iterator = source[Symbol.asyncIterator]()
      return {
        async next(): Promise<IteratorResult<T>> {
          try {
            const result = await iterator.next()
            if (result.done) {
              completed = true
              events.push({ type: 'complete', time: Date.now() - startTime })
              completeListeners.forEach(l => l())
              return result
            }
            values.push(result.value)
            events.push({ type: 'value', value: result.value, time: Date.now() - startTime })
            checkValueListeners()
            return result
          } catch (e) {
            error = e as Error
            events.push({ type: 'error', error, time: Date.now() - startTime })
            throw e
          }
        }
      }
    }
  }

  function checkValueListeners() {
    valueListeners = valueListeners.filter(({ count, resolve }) => {
      if (values.length >= count) {
        resolve([...values])
        return false
      }
      return true
    })
  }

  return {
    stream,
    events,
    values,
    get completed() { return completed },
    get error() { return error },
    waitForN(n: number): Promise<T[]> {
      if (values.length >= n) return Promise.resolve([...values])
      return new Promise(resolve => {
        valueListeners.push({ count: n, resolve })
      })
    },
    waitForComplete(): Promise<void> {
      if (completed) return Promise.resolve()
      return new Promise(resolve => {
        completeListeners.push(resolve)
      })
    }
  }
}
#+end_src

***** Tests

#+begin_src typescript :noweb-ref tests
describe('spy', () => {
  it('records stream events', async () => {
    const spied = spy(from([1, 2, 3]))
    await collect(spied.stream)
    
    expect(spied.values).toEqual([1, 2, 3])
    expect(spied.completed).toBe(true)
    expect(spied.events).toHaveLength(4) // 3 values + 1 complete
  })
})
#+end_src

**** =expectStream=

Fluent assertion helpers for testing stream behavior.

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * Fluent assertion builder for streams.
 */
export interface StreamExpectation<T> {
  /** Assert the stream emits exactly these values */
  toEmit(expected: T[]): Promise<void>
  /** Assert the stream emits values matching a predicate */
  toEmitMatching(predicate: (values: T[]) => boolean): Promise<void>
  /** Assert the stream emits at least N values */
  toEmitAtLeast(n: number): Promise<T[]>
  /** Assert the stream completes */
  toComplete(): Promise<void>
  /** Assert the stream errors */
  toError(): Promise<Error>
  /** Assert the stream errors with a specific message */
  toErrorWith(message: string | RegExp): Promise<void>
  /** Assert the stream is empty */
  toBeEmpty(): Promise<void>
  /** Assert first N values match */
  firstN(n: number): StreamExpectation<T>
}

/**
 * Create fluent assertions for a stream.
 * 
 * @example
 * await expectStream(from([1, 2, 3])).toEmit([1, 2, 3])
 * await expectStream(empty()).toBeEmpty()
 * await expectStream(throwError(new Error('oops'))).toError()
 */
export function expectStream<T>(stream: AsyncIterable<T>): StreamExpectation<T> {
  let limit: number | undefined

  const createExpectation = (s: AsyncIterable<T>): StreamExpectation<T> => ({
    async toEmit(expected: T[]): Promise<void> {
      const actual = limit !== undefined 
        ? await collectN(limit, s)
        : await collect(s)
      if (!arraysEqual(actual, expected)) {
        throw new Error(
          `Expected stream to emit ${JSON.stringify(expected)}, but got ${JSON.stringify(actual)}`
        )
      }
    },

    async toEmitMatching(predicate: (values: T[]) => boolean): Promise<void> {
      const values = limit !== undefined
        ? await collectN(limit, s)
        : await collect(s)
      if (!predicate(values)) {
        throw new Error(
          `Stream values ${JSON.stringify(values)} did not match predicate`
        )
      }
    },

    async toEmitAtLeast(n: number): Promise<T[]> {
      const values = await collectN(n, s)
      if (values.length < n) {
        throw new Error(
          `Expected stream to emit at least ${n} values, but got ${values.length}`
        )
      }
      return values
    },

    async toComplete(): Promise<void> {
      await collect(s)
      // If we get here without error, stream completed
    },

    async toError(): Promise<Error> {
      try {
        await collect(s)
        throw new Error('Expected stream to error, but it completed')
      } catch (e) {
        return e as Error
      }
    },

    async toErrorWith(message: string | RegExp): Promise<void> {
      try {
        await collect(s)
        throw new Error('Expected stream to error, but it completed')
      } catch (e) {
        const error = e as Error
        const matches = typeof message === 'string'
          ? error.message === message
          : message.test(error.message)
        if (!matches) {
          throw new Error(
            `Expected error message to match ${message}, but got "${error.message}"`
          )
        }
      }
    },

    async toBeEmpty(): Promise<void> {
      const values = await collect(s)
      if (values.length > 0) {
        throw new Error(
          `Expected stream to be empty, but got ${JSON.stringify(values)}`
        )
      }
    },

    firstN(n: number): StreamExpectation<T> {
      limit = n
      return this
    }
  })

  return createExpectation(stream)
}

function arraysEqual<T>(a: T[], b: T[]): boolean {
  if (a.length !== b.length) return false
  return a.every((v, i) => v === b[i])
}
#+end_src

**** =createAsyncIterable=

Utility for quickly creating async iterables from arrays with optional delays.

#+begin_src typescript :tangle typescript/test-helpers.ts
/**
 * Options for creating an async iterable.
 */
export interface AsyncIterableOptions {
  /** Delay between emissions in milliseconds */
  delay?: number
  /** Delay before first emission */
  initialDelay?: number
}

/**
 * Create an async iterable from an array with optional timing.
 * 
 * @example
 * const stream = createAsyncIterable([1, 2, 3], { delay: 100 })
 * // Emits 1, then waits 100ms, emits 2, waits 100ms, emits 3
 */
export async function* createAsyncIterable<T>(
  values: T[],
  options: AsyncIterableOptions = {}
): AsyncGenerator<T, void, void> {
  const { delay: delayMs = 0, initialDelay = 0 } = options

  if (initialDelay > 0) {
    await new Promise(r => setTimeout(r, initialDelay))
  }

  for (let i = 0; i < values.length; i++) {
    yield values[i]
    if (delayMs > 0 && i < values.length - 1) {
      await new Promise(r => setTimeout(r, delayMs))
    }
  }
}
#+end_src

*** Test File

The test file is assembled from all the =:noweb-ref tests= blocks scattered throughout this document.
This keeps tests close to the code they test while producing a single test file.

#+begin_src typescript :tangle typescript/index.test.ts :noweb yes
import { describe, it, expect } from 'vitest'
import {
  collect,
  collectN,
  collectWithTime,
  marble,
  TestStream,
  spy,
  expectStream,
  createAsyncIterable
} from './test-helpers'
import {
  just,
  from,
  fromPromise,
  fromEvent,
  periodic,
  empty,
  never,
  iterate,
  unfold,
  startWith,
  concat,
  pipe,
  map,
  constant,
  scan,
  tap,
  awaitTap,
  continueWith,
  concatAll,
  concatMap,
  filter,
  skipRepeats,
  skipRepeatsWith,
  take,
  skip,
  slice,
  takeWhile,
  skipWhile,
  takeUntil,
  delay,
  debounce,
  throttle,
  recoverWith,
  throwError,
  retry,
  merge,
  mergeAll,
  chain,
  flatMap,
  switchMap,
  latest,
  applyLatest,
  untilStream,
  sinceStream,
  buffer,
  bufferTime,
  window,
  eager,
  eagerNow,
  ReplaySubject,
  replay,
  share,
  replayFactory,
  replayStream
} from './index'

<<tests>>
#+end_src

** Python

This section will contain test helpers for the Python implementation.

*** Helpers

**** =collect=

#+begin_src python :tangle python/test_agent_rex.py
async def collect(stream: AsyncIterable[T]) -> List[T]:
  """Collect all values from a stream into a list."""
  return [value async for value in stream]
#+end_src

**** Tests

#+begin_src python :noweb-ref python/test_agent_rex.py
class TestCollect:
  async def test_collects_all(self):
    result = await collect(from_iter([1, 2, 3]))
    assert result == [1, 2, 3]
#+end_src

**** =collect_n=

#+begin_src python :tangle python/test_agent_rex.py
async def collect_n(n: int, stream: AsyncIterable[T]) -> List[T]:
  """Collect exactly N values from a stream."""
  values: List[T] = []
  async for value in stream:
    values.append(value)
    if len(values) >= n:
      break
  return values
#+end_src

**** Tests

#+begin_src python :noweb-ref python/test_agent_rex.py
class TestCollectN:
  async def test_collects_n(self):
    result = await collect_n(2, from_iter([1, 2, 3, 4, 5]))
    assert result == [1, 2]
#+end_src

**** =drain=

#+begin_src python :tangle python/test_agent_rex.py
async def drain(stream: AsyncIterable[T]) -> None:
  """Consume all values from a stream, discarding them."""
  async for _ in stream:
    pass
#+end_src

**** Tests

#+begin_src python :noweb-ref python/test_agent_rex.py
class TestDrain:
  async def test_drains_stream(self):
    drained = []
    
    async def tracked():
      for i in [1, 2, 3]:
        drained.append(i)
        yield i
    
    await drain(tracked())
    assert drained == [1, 2, 3]
#+end_src
